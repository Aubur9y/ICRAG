[
  {
    "user_input": "What is the primary goal of climate models?",
    "retrieved_contexts": [
      "[{'id': 1753902300206271, 'score': 0.7422223, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}, {'id': 1753902703503123, 'score': 0.7336924, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753902300429530, 'score': 0.7251019, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902299806645, 'score': 0.7190526, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902702944729, 'score': 0.7155869, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753902702922525, 'score': 0.7153083, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_0', 'type': 'pdf', 'content': 'Are climate models any good or useful at all?\\nhttps://www.gfdl.noaa.gov/visualizations-hurricanes/\\nData or model?\\nCommon misconceptions about modeling1.The goal of modeling is to reproduce data2.If a model doesn’t fit the data, the model is useless (…and modeler also)3.Since modelers don’t measure anything, they don’t know anything about data or care about them4.Measurement(s) of “X” can be used to better constrain climate models5.Process “W” is not explicitly implemented in the model,hence the ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 0}}, {'id': 1753903424509295, 'score': 0.70976686, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753901956917450, 'score': 0.7050539, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753901957112878, 'score': 0.700469, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_0', 'type': 'pdf', 'content': 'https://svs.gsfc.nasa.gov/30701Climate data and modelsEDSML MSc –Imperial College London –Environmental dataYves Plancherel-https://www.linkedin.com/in/yves-plancherel/\\nWhy discuss climate data and climate models?\\n1. Understand common data format and databasestructures specific to representative fields of environmental science2. Demonstrate technical competency in handling common data types routinely encountered in the environmental sciences and identify relevant open-source data repositories3. ', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 0}}, {'id': 1753903424368210, 'score': 0.69417286, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_2_md', 'type': 'markdown', 'content': \"<a id='lectures'></a>\\n# Lecture on relevance of climate science, climate models and climate modelling\\n\\n\\n(see Powerpoint presentations)\\n\\n1. 01v1_Why_climate_data.pptx/pdf\\n2. 02v1_Building_climate_models.pptx/pdf\\n3. 03v1_Common_issues.pptx/pdf\\n   \\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 2}}]",
      "[{'id': 1753903424142956, 'score': 0.72457063, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_4_md', 'type': 'markdown', 'content': \"<a id='ESMValTool'></a>\\n\\n# Python environments to consider for working with climate data \\n\\n* ## Earth System Model Evaluation Tool (ESMValTool)\\n![esmvaltool](img/ESMValTool-logo-2.png)\\n\\nThis week, it should be possible to simply install packages as needed...\\n\\nHowever, if you anticipate possible future needs, you may want to invest a bit of effort to setup a specific python environment to work with climate data. If so, a good place to start is the `ESMValTool` project. \\n\\n\\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) is  a community-led, open source, set of software tools (build on python 3) developed to improve diagnosing and understanding climate models. While the focus has been on climate models, not observations, one cannot quantify model biases without also comparing the model results with observations. [ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) therefore also has some capability to analyze and manipulate large datasets. \\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) can work offline, but as the amount of climate data is so large, it is mostly designed to work with data centers that provide local access to the vast amount of data. One such initiative is the Earth System Grid Federation ([ESGF](https://esgf.llnl.gov)). ESMValTool provides functionality to work on HPC systems.\\n\\nWe will not use ESMValTool here specifically, but it will install other convenient tools and you may be curious to investigate ESMValTool capabilities on your own anyways. It is now used routinely for climate modelling research. \\n\\nAdditional information and help can be found at https://www.esmvaltoolorg, and on the [ESMValGroup](https://github.com/ESMValGroup) github page. The [ESMValTool tutorial](https://esmvalgroup.github.io/ESMValTool_Tutorial/) is a great resource to get started. \\n\\n\\n### OPTIONAL: Installing ESMValTool (NB: this often fails for students - installing this is not required for the course)\\n[Installation instructions](https://docs.esmvaltool.org/en/latest/quickstart/installation.html) differ by operating system and it is very much an experimental, in development, tool - keep this in mind! \\n\\n[Notes:ESMValTool 2.0 requires a Unix(-like) operating system and Python 3.7+. (Python 3.7, 3.8 and 3.9 are supported). On my laptop (Macbook pro 13'' M1 2020 with OS Monterey 12.0.1), I installed it in Nov 2021 with Python 3.9.7. ...but I installed it when 'conda' was still an installation option. ESMValTool developer have  changed installation methods to `mamba` recently. Do refer to online/official instructions). You will now be required to also [install `mamba`](https://docs.esmvaltool.org/en/latest/quickstart/installation.html#mamba-installation) first (...yet another package/dependency manager).] \\n\\nESMValTool can also work with Julia, R, NCL. Do check installation instructions for these extensions. \\n\\n[back to contents](##Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 4}}, {'id': 1753901956917450, 'score': 0.6973579, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902702944729, 'score': 0.68787485, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753903424509295, 'score': 0.68661326, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753902299806645, 'score': 0.68657863, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753903424228032, 'score': 0.68461996, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_43_md', 'type': 'markdown', 'content': '### The CDS Toolbox\\n\\nAn extention to the CDS API is the [CDS Toolbox](https://cds.climate.copernicus.eu/toolbox/doc/index.html). The Toolbox is a programming interface. It is free and available to everyone. It links raw data to an online computing facility, thereby removing the computing barrier for users worldwide. The Toolbox allows users to develop python scripts for the CDS and to run them online. The users than then simply download the maps, graph or secondary data without needing to incur the costs associated with storing and maintaining the large climate data archive locally, nor is it required to invest in a powerful computer. \\n\\n\\nThe Toolbox works hand-in-hand with the CDS API. \\n\\nThat is, one can issue commmands to the Toolbox via the CDS API, or develop a python script that does certain things, and then use the CDS API functionality to send it to CDS for evaluation, only to download the finished product locally. \\n\\nExamples of how to proceed are given [here](https://confluence.ecmwf.int/display/COPSRV/Call+a+service+with+the+CDS+API). \\n\\nNote, it is also possible to use the CDS Toolbox to plot data from other services (i.e. not originally stored on CDS), using the `remote` function instead of the `service` function. This is possible thanks to protocols such as OPeNDAP. Here is an example using data from UNIDATA. \\n\\nFor illustration of how the Toolbox can be used, the following piece of code, run locally, after the CDS API is properly configured and assuming one is connected to the internet, will produce, and then download to our `output/` directory, a map of global temperature on January 1st 2021 at 14:00.', 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 43}}, {'id': 1753903424804905, 'score': 0.6742742, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_42_code', 'type': 'code', 'content': \"#!/usr/bin/env python\\nimport cdsapi\\n \\nc = cdsapi.Client()\\n \\nc.retrieve(\\n    'reanalysis-era5-pressure-levels',\\n    {\\n        'product_type': 'reanalysis',\\n        'variable': 'temperature',\\n        'pressure_level': '1000',\\n        'year': '2021',\\n        'month': '01',\\n        'day': '01',\\n        'time': '12:00',\\n        'format': 'netcdf',                         # NetCDF\\n        'area'          : [60., -11., 34., 35.],    # Default area is global; provide [North, West, South, East] limits to select an area (here selecting Europe)\\n        'grid'          : [1.0, 1.0],               #  Default atmospheric resolution is 0.25 x 0.25; provie [Latitude/longitude] grid resolution to interpolate data to something else.           \\n    },\\n    'output/ERAtest_subarea_1deg1deg.nc')           # Output file. Adapt as you wish.\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 42}}, {'id': 1753902300472417, 'score': 0.67371166, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902702794239, 'score': 0.6733844, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902300429530, 'score': 0.6723703, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}]",
      "[{'id': 1753902702944729, 'score': 0.7197881, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753901956917450, 'score': 0.7193265, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902703503123, 'score': 0.70972264, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753902300429530, 'score': 0.69963825, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902299806645, 'score': 0.6994355, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753903424509295, 'score': 0.69155085, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753902702794239, 'score': 0.6834239, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902300206271, 'score': 0.6820358, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}, {'id': 1753903424142956, 'score': 0.6818946, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_4_md', 'type': 'markdown', 'content': \"<a id='ESMValTool'></a>\\n\\n# Python environments to consider for working with climate data \\n\\n* ## Earth System Model Evaluation Tool (ESMValTool)\\n![esmvaltool](img/ESMValTool-logo-2.png)\\n\\nThis week, it should be possible to simply install packages as needed...\\n\\nHowever, if you anticipate possible future needs, you may want to invest a bit of effort to setup a specific python environment to work with climate data. If so, a good place to start is the `ESMValTool` project. \\n\\n\\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) is  a community-led, open source, set of software tools (build on python 3) developed to improve diagnosing and understanding climate models. While the focus has been on climate models, not observations, one cannot quantify model biases without also comparing the model results with observations. [ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) therefore also has some capability to analyze and manipulate large datasets. \\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) can work offline, but as the amount of climate data is so large, it is mostly designed to work with data centers that provide local access to the vast amount of data. One such initiative is the Earth System Grid Federation ([ESGF](https://esgf.llnl.gov)). ESMValTool provides functionality to work on HPC systems.\\n\\nWe will not use ESMValTool here specifically, but it will install other convenient tools and you may be curious to investigate ESMValTool capabilities on your own anyways. It is now used routinely for climate modelling research. \\n\\nAdditional information and help can be found at https://www.esmvaltoolorg, and on the [ESMValGroup](https://github.com/ESMValGroup) github page. The [ESMValTool tutorial](https://esmvalgroup.github.io/ESMValTool_Tutorial/) is a great resource to get started. \\n\\n\\n### OPTIONAL: Installing ESMValTool (NB: this often fails for students - installing this is not required for the course)\\n[Installation instructions](https://docs.esmvaltool.org/en/latest/quickstart/installation.html) differ by operating system and it is very much an experimental, in development, tool - keep this in mind! \\n\\n[Notes:ESMValTool 2.0 requires a Unix(-like) operating system and Python 3.7+. (Python 3.7, 3.8 and 3.9 are supported). On my laptop (Macbook pro 13'' M1 2020 with OS Monterey 12.0.1), I installed it in Nov 2021 with Python 3.9.7. ...but I installed it when 'conda' was still an installation option. ESMValTool developer have  changed installation methods to `mamba` recently. Do refer to online/official instructions). You will now be required to also [install `mamba`](https://docs.esmvaltool.org/en/latest/quickstart/installation.html#mamba-installation) first (...yet another package/dependency manager).] \\n\\nESMValTool can also work with Julia, R, NCL. Do check installation instructions for these extensions. \\n\\n[back to contents](##Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 4}}, {'id': 1753902702662417, 'score': 0.6815091, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_10', 'type': 'pdf', 'content': 'ls that are ‘fitted’ to data•Some model parameters are tuned to fit–Question is what to fit/how? (Data assimilation, 4DVAR)–Provide best gridded high-resolution spatio-temporal product available … but:•they are still model results–Fitting a bad/wrong model still is a bad results•they only exist for the period when data exist–so cannot be used for forecasting–But extremely useful to understand past/current climate patterns/variability\\nAre models ever “right”?•Since models are incomplete by constr', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 10}}]",
      "[{'id': 1753902300429530, 'score': 0.7039552, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753903424509295, 'score': 0.68088263, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753902300206271, 'score': 0.6788614, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}, {'id': 1753902702697836, 'score': 0.6735083, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_5', 'type': 'pdf', 'content': 'ent become stronger (strong exchange, although on shorter spatial scales, e.g.air-sea heat fluxes)•Better agreement with the way data are collected (i.e.what observations mean)–Averaging over space/time and variabilityhttps://www.gfdl.noaa.gov/climate-modeling/\\nGulf Stream\\nLabrador Sea~100km cells~10km cells\\nOcean resolution: 2 casesresolving eddies (the ocean’ storms)\\nFigure 6.1. Surface-Current Speed in Two Simulations of the Southern Ocean in Low-and High-Resolution Ocean Models.[From Fig. 6 ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 5}}, {'id': 1753902702794239, 'score': 0.6617123, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902703274403, 'score': 0.65954727, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753902703457059, 'score': 0.65866035, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_6', 'type': 'pdf', 'content': 'in R. Hallbergand A. Gnanadesikam2006:The role of eddies in determining the structure and response of the wind-driven Southern Hemisphere overturning: Results from the modeling eddies in the Southern Ocean (MESO) project. J. Physical Oceanography, 36, 2232–2252. Reproduced by permission of the American Meteorological Society (AMS).]\\nAtmospheric resolution: 3 casesWhat are implications for interpretation, decision/policy making?\\nCaliforniaCalifornia\\nCaliforniaCalifornia\\nThe atmosphere matters …a ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 6}}, {'id': 1753901956917450, 'score': 0.65564084, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753903424262111, 'score': 0.6537523, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_38_md', 'type': 'markdown', 'content': \"<a id='reanalysis'></a>\\n\\n# Reanalysis products\\n\\n![C3S](img/c3s-logo.png)\\n![ECMWF](img/logo-ecmwf.png) \\n\\n[*ERA5 provides hourly estimates of a large number of atmospheric, land and oceanic climate variables. The data cover the Earth on a 30km grid and resolve the atmosphere using 137 levels from the surface up to a height of 80km. ERA5 includes information about uncertainties for all variables at reduced spatial and temporal resolutions.Quality-assured monthly updates of ERA5 (1979 to present) are published within 3 months of real time. Preliminary daily updates of the dataset are available to users within 5 days of real time.*](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5)\\n\\n[ERA5](https://confluence.ecmwf.int/display/CKB/ERA5) is a [family of datasets](https://confluence.ecmwf.int/display/CKB/The+family+of+ERA5+datasets). It currently comprises ERA5, ERA5.1 and ERA5-Land. ERA5 is the fifth generation ECMWF atmospheric reanalysis of the global climate covering the period from January 1950 to present. ERA5 is produced by the Copernicus Climate Change Service ([C3S](https://confluence.ecmwf.int/pages/viewpage.action?pageId=151530614)) at the European Center for Medium-Range Weather Forecasts ([ECMWF](https://www.ecmwf.int)) and made available via the [Climate Change Service](https://climate.copernicus.eu). \\n\\nImportantly, ERA5 is a [**reanalysis product**](https://www.youtube.com/watch?v=FAGobvUGl24), meaning a **model that assimilates data**. A model of the climate (weather) is run, and adjusted (following certain laws of physics and constraints) to fit [as many observations](https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation#ERA5:datadocumentation-Observations) as possible using a technique called 4D-var. One must realize that, even if assimimated prodcuts such as ERA5 are often used 'in lieu' of observations, they are **\\\\*not\\\\*** observations: they are a model product, but a product that is made to look as much like the data as possible given computational, mathematical, physical limitations of the model. \\n\\nERA5 is one of various [reanalysis products](https://reanalyses.org) available globally. Another well-known produce is the [NCEP/NCAR Reanalysis product](https://en.wikipedia.org/wiki/NCEP/NCAR_Reanalysis). [MERRA-2](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/), produced by NASA, is another. \\n\\nThe article by [Hersbach et al. 2020](https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.3803) discusses the ERA global Reanalysis prodcuct in more detail.\\n\\nWhile observations are only available in specific locations and at specific times, the reanalysis product provides a clever way to dynamically interpolate between these observations. ERA5 also comes as a gridded product, making it very convenient to use. In the model-world, one can access a complete/global picture every time-step, with a spatial resolution as high as computational limits allow. I re-emphasize that this is not the same as observations! ... but it is as close to observations as we can get if one is trying to work with a spatially and temporall interpolated product. \\n\\n**Grid geometry depends on data format**: Note that the grid geometry of the output data of ERA5 [depends on the format the data that are being downloaded](https://confluence.ecmwf.int/display/CKB/ERA5%3A+What+is+the+spatial+reference). Native GRIB format data are delivered on the model's native grid geometry (this is not a regular lat/lon grid!). On the other hand, data in NetCDF format are automatically interpolated and regridded to a regular lat/lon grid. While this is not very important for most application, one must remember that interpolated data in the NetCDF files are not the same as the original model output and this could have implication for the conservation properties of some variables. It can be easier/convenient to work with data interpolated on a regular lat/lon grid, however.  \\n\\n**Grid definition and wrap-around**: The gridded ERA5 archive is provided on a [-90;+90] latitude grid and a [0;+360] longitude grid, with decimal degrees, referenced to the Greenwich Prime Meridian. While latitude is generally not an issue, care must be taken when working with longitude as one must remember that 0 and 360 are the same point. One must account for the wrap-around issue: although the first column and last column of a datasets on the [0;+360] grid are far away from each other in terms of index, these points are geographically very close. Some software can automatically deal with this wrap-around and convert to [-180;+180] or other system as required, but this should not be taken for granted. \\n\\n\\n[back to contents](#Contents)\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 38}}, {'id': 1753902702944729, 'score': 0.6521675, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}]",
      "[{'id': 1753902300429530, 'score': 0.74656, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902300206271, 'score': 0.7378002, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}, {'id': 1753902702794239, 'score': 0.7190503, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902702944729, 'score': 0.7150937, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753901956917450, 'score': 0.71477616, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902703503123, 'score': 0.71407413, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753902299806645, 'score': 0.71206874, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753903424509295, 'score': 0.7105104, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753901957112878, 'score': 0.7093944, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_0', 'type': 'pdf', 'content': 'https://svs.gsfc.nasa.gov/30701Climate data and modelsEDSML MSc –Imperial College London –Environmental dataYves Plancherel-https://www.linkedin.com/in/yves-plancherel/\\nWhy discuss climate data and climate models?\\n1. Understand common data format and databasestructures specific to representative fields of environmental science2. Demonstrate technical competency in handling common data types routinely encountered in the environmental sciences and identify relevant open-source data repositories3. ', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 0}}, {'id': 1753902300472417, 'score': 0.70463103, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}]"
    ],
    "response": "The provided text appears to be a collection of notes and excerpts from various sources related to climate modeling and data. The topics covered include:\n\n1. Climate models: Their purpose, components, and challenges.\n2. Data formats: NetCDF, NCO, CDO, and other file formats used in climate science.\n3. Metadata: Importance and conventions for climate data.\n4. Reanalysis products: ERA5 and other reanalysis datasets.\n5. Climate services: UKCP18 and other initiatives related to climate data and modeling.\n\nThe notes also touch on the challenges of climate modeling, such as:\n\n1. Complexity of atmospheric physics\n2. Limited understanding of cloud formation and microphysics\n3. Difficulty in predicting rain events and magnitude\n\nSome quotes and references are included, such as:\n\n* \"Climate models... cannot model the effect of 'Z' on climate as 'W' has or may have an (unquantified) effect of the 'Z'...\"\n* \"All models are 'wrong' and 'incomplete'...\"\n\nOverall, the text provides a general overview of climate modeling and data, highlighting the challenges and complexities involved in this field.",
    "reference": "To simulate and predict climate systems using mathematical representations of physical processes.",
    "iteration_scores": [
      {
        "iteration": 1,
        "decomposition": 8.0,
        "retrieval": 6.4,
        "generation": 15.2,
        "total": 9.866666666666667
      }
    ]
  },
  {
    "user_input": "Explain why climate data is essential in environmental science.",
    "retrieved_contexts": [
      "[{'id': 1753901957112878, 'score': 0.731357, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_0', 'type': 'pdf', 'content': 'https://svs.gsfc.nasa.gov/30701Climate data and modelsEDSML MSc –Imperial College London –Environmental dataYves Plancherel-https://www.linkedin.com/in/yves-plancherel/\\nWhy discuss climate data and climate models?\\n1. Understand common data format and databasestructures specific to representative fields of environmental science2. Demonstrate technical competency in handling common data types routinely encountered in the environmental sciences and identify relevant open-source data repositories3. ', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 0}}, {'id': 1753901956989969, 'score': 0.7292218, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_2', 'type': 'pdf', 'content': ' as well as errors stemming from the analytical procedure itself (e.g.calibration of analysis using synthetic data/models).Learning objectives of the Environmental Data module•Growing/important field –with likely career opportunities•Great playground to deliver learning objectives\\nUsing climate models: quantification/forecasting(impacts, adaptation, mitigation)\\nhttps://www.noaa.gov/education/resource-collections/climate/climate-change-impacts\\nUsing climate models: designscenarios(explore policy,', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 2}}, {'id': 1753903424243022, 'score': 0.7186252, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_10_md', 'type': 'markdown', 'content': \" * ### The Climate and Forecast (CF) Metadata Conventions (prominent in climate science)\\n \\nGiven the amount of data produced keeps increasing, data libraries are being developed. As in any library, certain sets of rules are required so that the data can be found later. Metadata are obviously a good way to ensure data can be catalogued and found by various search systems.\\n\\nMultiple types of conventions exist (see for example this [list of netCDF conventions from Unidata](https://www.unidata.ucar.edu/software/netcdf/conventions.html)). Ensuring that data files are produced in a way that follows conventions about content, vocabulary used and layout, allows for batch processing, easy extraction and automation! It is extremely useful (but should not prevent innovation).\\n\\nCEDA, as it focuses on climate and environmental data, relies extensively on the [Climate and Forecast (CF) Conventions](http://cfconventions.org). The CF Conventions are probably the most popular in climate science (it underpins the modelling effort of the IPCC). A detailed description of the latest release of the CF Conventions for netCDF can be found [here](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.9/cf-conventions.html). \\n\\nThe CF Conventions were designed specifically for the netCDF format but they can be applied widely. The netCDF format enables creation of self-describing datasets by design. CF Conventions aim to ensure that  files contain sufficient metadata that they are self-describing in the sense that each variable in the file has an associated description of what it represents, including physical units if appropriate, and that each value can be located in space (relative to earth-based coordinates) and time. (Absence of such information in early (historical) datasets has hindered climate change science for decades - how does one measure change, if one cannot locate the observations in time and space?)\\n\\nOne example of CF Conventions is to provide a list of **standard_names** for certain commonly-used variables. The [CF standard name table] (http://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html) will show what the names are and describe what they represent. \\n\\nTo illustrate, imagine you work with data at the earth surface and label your variable 'temperature'. What did you mean exactly? Surface temperature of the ocean/land, or air temperature? etc. CF conventions ensure that climate scientists name common variables in the same way. \\n\\nA [python package](https://pypi.org/project/cfunits/) called `cfunits` provides an interface to the CF Convention. This is useful to combine and compare variables and convert various units. By relying on a package, fewer user-errors are made.   \\n\\nThe CF Conventions are not fixed, they are evolving depending on needs and scientific progress. Although conventions are decided by a committee of experts, anyone can propose a change to the convention by engaging in the [discussion forum](https://cfconventions.org/discussion.html).\\n\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 10}}, {'id': 1753903424142956, 'score': 0.71623445, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_4_md', 'type': 'markdown', 'content': \"<a id='ESMValTool'></a>\\n\\n# Python environments to consider for working with climate data \\n\\n* ## Earth System Model Evaluation Tool (ESMValTool)\\n![esmvaltool](img/ESMValTool-logo-2.png)\\n\\nThis week, it should be possible to simply install packages as needed...\\n\\nHowever, if you anticipate possible future needs, you may want to invest a bit of effort to setup a specific python environment to work with climate data. If so, a good place to start is the `ESMValTool` project. \\n\\n\\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) is  a community-led, open source, set of software tools (build on python 3) developed to improve diagnosing and understanding climate models. While the focus has been on climate models, not observations, one cannot quantify model biases without also comparing the model results with observations. [ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) therefore also has some capability to analyze and manipulate large datasets. \\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) can work offline, but as the amount of climate data is so large, it is mostly designed to work with data centers that provide local access to the vast amount of data. One such initiative is the Earth System Grid Federation ([ESGF](https://esgf.llnl.gov)). ESMValTool provides functionality to work on HPC systems.\\n\\nWe will not use ESMValTool here specifically, but it will install other convenient tools and you may be curious to investigate ESMValTool capabilities on your own anyways. It is now used routinely for climate modelling research. \\n\\nAdditional information and help can be found at https://www.esmvaltoolorg, and on the [ESMValGroup](https://github.com/ESMValGroup) github page. The [ESMValTool tutorial](https://esmvalgroup.github.io/ESMValTool_Tutorial/) is a great resource to get started. \\n\\n\\n### OPTIONAL: Installing ESMValTool (NB: this often fails for students - installing this is not required for the course)\\n[Installation instructions](https://docs.esmvaltool.org/en/latest/quickstart/installation.html) differ by operating system and it is very much an experimental, in development, tool - keep this in mind! \\n\\n[Notes:ESMValTool 2.0 requires a Unix(-like) operating system and Python 3.7+. (Python 3.7, 3.8 and 3.9 are supported). On my laptop (Macbook pro 13'' M1 2020 with OS Monterey 12.0.1), I installed it in Nov 2021 with Python 3.9.7. ...but I installed it when 'conda' was still an installation option. ESMValTool developer have  changed installation methods to `mamba` recently. Do refer to online/official instructions). You will now be required to also [install `mamba`](https://docs.esmvaltool.org/en/latest/quickstart/installation.html#mamba-installation) first (...yet another package/dependency manager).] \\n\\nESMValTool can also work with Julia, R, NCL. Do check installation instructions for these extensions. \\n\\n[back to contents](##Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 4}}, {'id': 1753903424143550, 'score': 0.7127701, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_11_md', 'type': 'markdown', 'content': \"<a id='NetCDF'></a>\\n\\n## Network Common Data Form (NetCDF)\\n\\n[NetCDF](https://www.unidata.ucar.edu/software/netcdf/) is one of the most common data format used to store climate data. NetCDF files allow the user to insert metadata in the data file by design, ensuring the data file is self-describing (amongst other properties).\\n\\n*NetCDF is a set of software libraries and machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.* \\n\\nThe netCDF format, which is a type of HDF format, is attractive because it is:\\n\\n* Self-Describing. A netCDF file includes information about the data it contains and metadata.\\n* Portable. A netCDF file can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\\n* Scalable. Small subsets of large datasets in various formats may be accessed efficiently through netCDF interfaces, even from remote servers.\\n* Appendable. Data may be appended to a properly structured netCDF file without copying the dataset or redefining its structure.\\n* Sharable. One writer and multiple readers may simultaneously access the same netCDF file.\\n* Archivable. Access to all earlier forms of netCDF data will be supported by current and future versions of the software.\\n\\n\\nThe NetCDF project is maintained by the Unidata program at the University Corporation for Atmospheric Research ([UCAR](https://www.ucar.edu)). [UCAR](https://www.ucar.edu) also manages [NCAR](https://ncar.ucar.edu), one of the first center to have developped climate models and is today one of the gold-standard on the topic. \\n\\nNCAR also developed [NCL](https://www.ncl.ucar.edu), an interpreted programming language designed specifically for scientific data analysis and visualization (we will not use NCL here, but the python package `ESMValTool` has build-in support for it). \\n\\n[NCAR](https://ncar.ucar.edu) has also developped the [climate data guide](https://climatedataguide.ucar.edu), a tool to search and access >200 data sets specific to the ocean, land and the atmosphere. (Some of these data may or may not also be found on CEDA.) \\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 11}}, {'id': 1753903424509295, 'score': 0.70583075, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753901956917450, 'score': 0.6952955, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753903424959234, 'score': 0.6943283, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_9_md', 'type': 'markdown', 'content': '<a id=\\'Metadata\\'></a>\\n\\n## The importance of Metadata\\n[Metadata](https://help.ceda.ac.uk/article/4428-metadata-basics) **relate to all the information necessary to interpret, understand and use a given dataset. Metadata are not the data themselves, but are required to provide context and therefore inform the data analysis.** \\n\\nThere are two types of metadata, \"**discover metadata**\", which can be used to locate the dataset in a search, and \"**detailed metadata**\", which contain the information necessary to use the data (ideally) without having to ask the data provider for more information (even if one of the key piece of information should be the data provider information and contact detail!).\\n\\nThere is no upper limit as to what information should be included in the metadata, but typical metadata comprise information about when and where the observations, or the file, where produced, how they were produced (which instrument, technique, algorithm were used), information about the experiment the data come from, maybe some information about data accuracy (if not provided as seperate data in the file), information about who produced the data or the file, including contact information, or appropriate reference(s), and, if relevant, additional information about the research context, i.e. which project is associated with these data (this could help the user understand if more data from this group/project exist or can be expected). If the data represent a subset of a larger dataset, this should also be mentioned. \\n\\nAnother key pieces of information that the metadata should provide are a description of the variables in the file, with variable **names**, and the **units** of these variables. \\n\\nIf the data in the file represent a processed version of other raw data, then one should add information about these raw data as well, their provenance, references, and the transformation that was made, etc. One should be able to track the chain of information all the way to the orginal observations (or model output). \\n\\nIf the data represent gridded variables, then the nature of the grid on which these data are defined should also be explained. \\n\\nSimilarly, if the position, or some other features of the data, depend on a reference system, that reference system should be given. This will be discussed in more depth during the introduction to geostatistics lecture. \\n\\nIn the case of climate models (or other models, if relevant), the metadata should also include information about the model itself, the model name, version, the length of the integration, maybe a brief description of the spin-up, boundary conditions, initial conditions used to produce the simulation. \\n\\nObviously the information that will be included in the metadata vary substantially. You should learn (and will discover - mostly through shear frustration when key information is missing!) what constitute useful metadata in your field of work. \\n\\nMetadata can be included in the file itself (if the file format allows it), as separate files, or in the form of some other documents. When sourcing data, always make a note of where the data come from. This is especially true if getting data online as it is very easy to download data and then forget where they come from. Detailed note-taking is part of the job of the data analyst (and that of any scientist!). \\n\\nWhen metadata is included in the file directly, this typically comes as a header, or in a specified location in the file. The netCDF format has rules for how/where to include metadata, which is one of the reason why netCDF data are particularly useful and popular in climate science. \\n\\n\\n[back to contents](#Contents)\\n\\n---', 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 9}}, {'id': 1753903424357433, 'score': 0.6891075, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_5_md', 'type': 'markdown', 'content': \"<a id='climatedata'></a>\\n\\n# Working with climate data and climate models\\n\\n### Earth System Grid Federation (ESGF)\\n\\n![esgf](img/ESGF_logo.png)\\n\\n\\n[ESGF](https://esgf.llnl.gov) is an open-source platform that provides distributed access to peta/exa-scale scientific data, **globally**. \\n\\nIt is an interagency and international effort led by the US Department of Energy (DOE), co-funded by National Aeronautics and Space Administration (NASA), National Oceanic and Atmospheric Administration (NOAA), the US National Science Foundation (NSF), and other international partners, such as the Max Planck Institute for Meteorology (MPI-M) German Climate Computing Centre (DKRZ), the Australian National University (ANU) National Computational Infrastructure (NCI), Institut Pierre-Simon Laplace (IPSL), and the **Centre for Environmental Data Analysis ([CEDA](https://www.ceda.ac.uk))** in the UK.\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 5}}, {'id': 1753903424623019, 'score': 0.6882224, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_37_md', 'type': 'markdown', 'content': \"### Climate Data Operators (CDO)\\nThe Climate Data Operators ([CDO](https://code.mpimet.mpg.de/projects/cdo)) software is a collection of >600 operators for standard processing of climate and forecast model data. They are slighly less memory/speed efficient than NCO, but they do more (>600 vs 12!). CDO support the main data formats used in the field, such as GRIB and netCDF. \\n\\nThey too can be daisy-chained for specific applications. There are [many recipes available](https://code.mpimet.mpg.de/projects/cdo/embedded/cdo_eca.pdf) to calculate various climate indices and diagnostics, what makes them very attractive to evaluate gridded climate data or climate model output.\\n\\nThe [CDO user guide](https://code.mpimet.mpg.de/projects/cdo/embedded/index.html) provides details instructions and examples. \\n\\n[They are also very useful, but we don't have time to discuss them in detail here. You are encouraged to practice with CDO on your own time]\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 37}}]",
      "[{'id': 1753901957112878, 'score': 0.7499693, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_0', 'type': 'pdf', 'content': 'https://svs.gsfc.nasa.gov/30701Climate data and modelsEDSML MSc –Imperial College London –Environmental dataYves Plancherel-https://www.linkedin.com/in/yves-plancherel/\\nWhy discuss climate data and climate models?\\n1. Understand common data format and databasestructures specific to representative fields of environmental science2. Demonstrate technical competency in handling common data types routinely encountered in the environmental sciences and identify relevant open-source data repositories3. ', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 0}}, {'id': 1753901956989969, 'score': 0.7235369, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_2', 'type': 'pdf', 'content': ' as well as errors stemming from the analytical procedure itself (e.g.calibration of analysis using synthetic data/models).Learning objectives of the Environmental Data module•Growing/important field –with likely career opportunities•Great playground to deliver learning objectives\\nUsing climate models: quantification/forecasting(impacts, adaptation, mitigation)\\nhttps://www.noaa.gov/education/resource-collections/climate/climate-change-impacts\\nUsing climate models: designscenarios(explore policy,', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 2}}, {'id': 1753903424959234, 'score': 0.71132314, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_9_md', 'type': 'markdown', 'content': '<a id=\\'Metadata\\'></a>\\n\\n## The importance of Metadata\\n[Metadata](https://help.ceda.ac.uk/article/4428-metadata-basics) **relate to all the information necessary to interpret, understand and use a given dataset. Metadata are not the data themselves, but are required to provide context and therefore inform the data analysis.** \\n\\nThere are two types of metadata, \"**discover metadata**\", which can be used to locate the dataset in a search, and \"**detailed metadata**\", which contain the information necessary to use the data (ideally) without having to ask the data provider for more information (even if one of the key piece of information should be the data provider information and contact detail!).\\n\\nThere is no upper limit as to what information should be included in the metadata, but typical metadata comprise information about when and where the observations, or the file, where produced, how they were produced (which instrument, technique, algorithm were used), information about the experiment the data come from, maybe some information about data accuracy (if not provided as seperate data in the file), information about who produced the data or the file, including contact information, or appropriate reference(s), and, if relevant, additional information about the research context, i.e. which project is associated with these data (this could help the user understand if more data from this group/project exist or can be expected). If the data represent a subset of a larger dataset, this should also be mentioned. \\n\\nAnother key pieces of information that the metadata should provide are a description of the variables in the file, with variable **names**, and the **units** of these variables. \\n\\nIf the data in the file represent a processed version of other raw data, then one should add information about these raw data as well, their provenance, references, and the transformation that was made, etc. One should be able to track the chain of information all the way to the orginal observations (or model output). \\n\\nIf the data represent gridded variables, then the nature of the grid on which these data are defined should also be explained. \\n\\nSimilarly, if the position, or some other features of the data, depend on a reference system, that reference system should be given. This will be discussed in more depth during the introduction to geostatistics lecture. \\n\\nIn the case of climate models (or other models, if relevant), the metadata should also include information about the model itself, the model name, version, the length of the integration, maybe a brief description of the spin-up, boundary conditions, initial conditions used to produce the simulation. \\n\\nObviously the information that will be included in the metadata vary substantially. You should learn (and will discover - mostly through shear frustration when key information is missing!) what constitute useful metadata in your field of work. \\n\\nMetadata can be included in the file itself (if the file format allows it), as separate files, or in the form of some other documents. When sourcing data, always make a note of where the data come from. This is especially true if getting data online as it is very easy to download data and then forget where they come from. Detailed note-taking is part of the job of the data analyst (and that of any scientist!). \\n\\nWhen metadata is included in the file directly, this typically comes as a header, or in a specified location in the file. The netCDF format has rules for how/where to include metadata, which is one of the reason why netCDF data are particularly useful and popular in climate science. \\n\\n\\n[back to contents](#Contents)\\n\\n---', 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 9}}, {'id': 1753903424243022, 'score': 0.7048563, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_10_md', 'type': 'markdown', 'content': \" * ### The Climate and Forecast (CF) Metadata Conventions (prominent in climate science)\\n \\nGiven the amount of data produced keeps increasing, data libraries are being developed. As in any library, certain sets of rules are required so that the data can be found later. Metadata are obviously a good way to ensure data can be catalogued and found by various search systems.\\n\\nMultiple types of conventions exist (see for example this [list of netCDF conventions from Unidata](https://www.unidata.ucar.edu/software/netcdf/conventions.html)). Ensuring that data files are produced in a way that follows conventions about content, vocabulary used and layout, allows for batch processing, easy extraction and automation! It is extremely useful (but should not prevent innovation).\\n\\nCEDA, as it focuses on climate and environmental data, relies extensively on the [Climate and Forecast (CF) Conventions](http://cfconventions.org). The CF Conventions are probably the most popular in climate science (it underpins the modelling effort of the IPCC). A detailed description of the latest release of the CF Conventions for netCDF can be found [here](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.9/cf-conventions.html). \\n\\nThe CF Conventions were designed specifically for the netCDF format but they can be applied widely. The netCDF format enables creation of self-describing datasets by design. CF Conventions aim to ensure that  files contain sufficient metadata that they are self-describing in the sense that each variable in the file has an associated description of what it represents, including physical units if appropriate, and that each value can be located in space (relative to earth-based coordinates) and time. (Absence of such information in early (historical) datasets has hindered climate change science for decades - how does one measure change, if one cannot locate the observations in time and space?)\\n\\nOne example of CF Conventions is to provide a list of **standard_names** for certain commonly-used variables. The [CF standard name table] (http://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html) will show what the names are and describe what they represent. \\n\\nTo illustrate, imagine you work with data at the earth surface and label your variable 'temperature'. What did you mean exactly? Surface temperature of the ocean/land, or air temperature? etc. CF conventions ensure that climate scientists name common variables in the same way. \\n\\nA [python package](https://pypi.org/project/cfunits/) called `cfunits` provides an interface to the CF Convention. This is useful to combine and compare variables and convert various units. By relying on a package, fewer user-errors are made.   \\n\\nThe CF Conventions are not fixed, they are evolving depending on needs and scientific progress. Although conventions are decided by a committee of experts, anyone can propose a change to the convention by engaging in the [discussion forum](https://cfconventions.org/discussion.html).\\n\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 10}}, {'id': 1753903424104630, 'score': 0.6988854, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_0_md', 'type': 'markdown', 'content': '---\\n\\n# <center> Environmental Data </center>\\n\\n---\\n\\n## Course objectives and philosophy\\nLet\\'s start by recalling what the learning objective of the Environmental Data modules are:\\n\\n1. Understand common data format and database structures specific to representative fields of environmental science\\n2. Demonstrate technical competency in handling common data types routinely encountered in the environmental sciences and identify relevant open-source data repositories\\n3. Identify and design suitable data analysis strategies that consider data types, data distribution constraints, strength, benefits and limitations of statistical and modelling tools and environmental dynamics.\\n4. Understand the limitation of available data and data analysis products. Understand sources of errors and demonstrate ability to comprehensively characterize uncertainties and interpret results in the context of these uncertainties, including measurement errors, environmental uncertainties as well as errors stemming from the analytical procedure itself (e.g. calibration of analysis using synthetic data/models).\\n\\nYou\\'ll note that these objectives address a progression of skills. The first focus on technical competency (understanding common data format and an ability to manipulate these data). The last two go deeper than technical competency - these aim to develop a data analysis workflow. In real-life situations, some of that workflow will be informed by intuition, and the best workflow will depend on context (e.g. time, infrastructure available) and on the objectives of a study. \\n\\nIntuition will come with experience, and therefore, also from failure! This course is an opportunity to try, sometimes fail ... and therefore learn! (That is the luxury of being a student!) With that in mind, some of the coursework presented here will be purposefully \"vague\". This is not meant to be annoying, it is designed to push you to seek and explore possible solutions (solutions are rarely unique) and express your creativity as an analyst. \\n\\n**Important**: Data analysis is a key component of the scientific method and therefore cannot exist without `hypothesis testing`. Approach every part of the data analysis workflow as a test, an experiment. Each experiment should be motivated by a hypothesis (a goal), will involve applying a methodology, will produce results pertinent to the hypothesis/goal, and will require a critique of these results with regards to their ability to address the hypothesis/goal before drawing a conclusion (it is ok for conclusions to come with caveats and uncertainties if the analysis warrants limits of interpretation).  \\n\\n**Warning**: Data analysis can also be a bit of  \"rabbit hole\"! There will always be nicer, cooler, better things to do. Sometimes, good is good enough though. Whatever you do, never lose sight of the overall objectives of a study. This needs to be delivered in priority.\\n\\n## This segment of the module\\nIn this module, content will be delivered using a mixture of\\npowerpoint lectures, jupyter notebooks and practical exercises.\\n\\nWarning: other directories, containing figures, images, animations or data are also provided. \\nHowever, cliamte data can be very large, and github has a low limit for these. \\nA dropbox link with data also exist: https://www.dropbox.com/sh/fxcmtbz4o3tacz1/AABjQbeyg27zDh1chZxRDFcpa?dl=0\\n\\n### Github repository: `environmental_data_week1`\\n\\n\\n## We will focus and use climate data.\\nThis segment of the module will focus on 2D, 3D and 4D data. To illustrate techniques and learn some useful skills, we will use data around the theme of climate and climate change. As part of this, we will learn how to access and use climate data and output from global climate models. \\n\\nThe science of climate is beyond the scope of this course, but although we will focus on data analysis, it is my hope that you will develop an appreciation and better understanding of climate science in the process. \\n___', 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 0}}, {'id': 1753903424509295, 'score': 0.69829834, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753903424357433, 'score': 0.69370383, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_5_md', 'type': 'markdown', 'content': \"<a id='climatedata'></a>\\n\\n# Working with climate data and climate models\\n\\n### Earth System Grid Federation (ESGF)\\n\\n![esgf](img/ESGF_logo.png)\\n\\n\\n[ESGF](https://esgf.llnl.gov) is an open-source platform that provides distributed access to peta/exa-scale scientific data, **globally**. \\n\\nIt is an interagency and international effort led by the US Department of Energy (DOE), co-funded by National Aeronautics and Space Administration (NASA), National Oceanic and Atmospheric Administration (NOAA), the US National Science Foundation (NSF), and other international partners, such as the Max Planck Institute for Meteorology (MPI-M) German Climate Computing Centre (DKRZ), the Australian National University (ANU) National Computational Infrastructure (NCI), Institut Pierre-Simon Laplace (IPSL), and the **Centre for Environmental Data Analysis ([CEDA](https://www.ceda.ac.uk))** in the UK.\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 5}}, {'id': 1753902702794239, 'score': 0.69046533, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753903424143550, 'score': 0.6893438, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_11_md', 'type': 'markdown', 'content': \"<a id='NetCDF'></a>\\n\\n## Network Common Data Form (NetCDF)\\n\\n[NetCDF](https://www.unidata.ucar.edu/software/netcdf/) is one of the most common data format used to store climate data. NetCDF files allow the user to insert metadata in the data file by design, ensuring the data file is self-describing (amongst other properties).\\n\\n*NetCDF is a set of software libraries and machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.* \\n\\nThe netCDF format, which is a type of HDF format, is attractive because it is:\\n\\n* Self-Describing. A netCDF file includes information about the data it contains and metadata.\\n* Portable. A netCDF file can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\\n* Scalable. Small subsets of large datasets in various formats may be accessed efficiently through netCDF interfaces, even from remote servers.\\n* Appendable. Data may be appended to a properly structured netCDF file without copying the dataset or redefining its structure.\\n* Sharable. One writer and multiple readers may simultaneously access the same netCDF file.\\n* Archivable. Access to all earlier forms of netCDF data will be supported by current and future versions of the software.\\n\\n\\nThe NetCDF project is maintained by the Unidata program at the University Corporation for Atmospheric Research ([UCAR](https://www.ucar.edu)). [UCAR](https://www.ucar.edu) also manages [NCAR](https://ncar.ucar.edu), one of the first center to have developped climate models and is today one of the gold-standard on the topic. \\n\\nNCAR also developed [NCL](https://www.ncl.ucar.edu), an interpreted programming language designed specifically for scientific data analysis and visualization (we will not use NCL here, but the python package `ESMValTool` has build-in support for it). \\n\\n[NCAR](https://ncar.ucar.edu) has also developped the [climate data guide](https://climatedataguide.ucar.edu), a tool to search and access >200 data sets specific to the ocean, land and the atmosphere. (Some of these data may or may not also be found on CEDA.) \\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 11}}, {'id': 1753903424368210, 'score': 0.6869545, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_2_md', 'type': 'markdown', 'content': \"<a id='lectures'></a>\\n# Lecture on relevance of climate science, climate models and climate modelling\\n\\n\\n(see Powerpoint presentations)\\n\\n1. 01v1_Why_climate_data.pptx/pdf\\n2. 02v1_Building_climate_models.pptx/pdf\\n3. 03v1_Common_issues.pptx/pdf\\n   \\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 2}}]",
      "[{'id': 1753903424142956, 'score': 0.71736217, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_4_md', 'type': 'markdown', 'content': \"<a id='ESMValTool'></a>\\n\\n# Python environments to consider for working with climate data \\n\\n* ## Earth System Model Evaluation Tool (ESMValTool)\\n![esmvaltool](img/ESMValTool-logo-2.png)\\n\\nThis week, it should be possible to simply install packages as needed...\\n\\nHowever, if you anticipate possible future needs, you may want to invest a bit of effort to setup a specific python environment to work with climate data. If so, a good place to start is the `ESMValTool` project. \\n\\n\\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) is  a community-led, open source, set of software tools (build on python 3) developed to improve diagnosing and understanding climate models. While the focus has been on climate models, not observations, one cannot quantify model biases without also comparing the model results with observations. [ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) therefore also has some capability to analyze and manipulate large datasets. \\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) can work offline, but as the amount of climate data is so large, it is mostly designed to work with data centers that provide local access to the vast amount of data. One such initiative is the Earth System Grid Federation ([ESGF](https://esgf.llnl.gov)). ESMValTool provides functionality to work on HPC systems.\\n\\nWe will not use ESMValTool here specifically, but it will install other convenient tools and you may be curious to investigate ESMValTool capabilities on your own anyways. It is now used routinely for climate modelling research. \\n\\nAdditional information and help can be found at https://www.esmvaltoolorg, and on the [ESMValGroup](https://github.com/ESMValGroup) github page. The [ESMValTool tutorial](https://esmvalgroup.github.io/ESMValTool_Tutorial/) is a great resource to get started. \\n\\n\\n### OPTIONAL: Installing ESMValTool (NB: this often fails for students - installing this is not required for the course)\\n[Installation instructions](https://docs.esmvaltool.org/en/latest/quickstart/installation.html) differ by operating system and it is very much an experimental, in development, tool - keep this in mind! \\n\\n[Notes:ESMValTool 2.0 requires a Unix(-like) operating system and Python 3.7+. (Python 3.7, 3.8 and 3.9 are supported). On my laptop (Macbook pro 13'' M1 2020 with OS Monterey 12.0.1), I installed it in Nov 2021 with Python 3.9.7. ...but I installed it when 'conda' was still an installation option. ESMValTool developer have  changed installation methods to `mamba` recently. Do refer to online/official instructions). You will now be required to also [install `mamba`](https://docs.esmvaltool.org/en/latest/quickstart/installation.html#mamba-installation) first (...yet another package/dependency manager).] \\n\\nESMValTool can also work with Julia, R, NCL. Do check installation instructions for these extensions. \\n\\n[back to contents](##Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 4}}, {'id': 1753901956989969, 'score': 0.71506387, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_2', 'type': 'pdf', 'content': ' as well as errors stemming from the analytical procedure itself (e.g.calibration of analysis using synthetic data/models).Learning objectives of the Environmental Data module•Growing/important field –with likely career opportunities•Great playground to deliver learning objectives\\nUsing climate models: quantification/forecasting(impacts, adaptation, mitigation)\\nhttps://www.noaa.gov/education/resource-collections/climate/climate-change-impacts\\nUsing climate models: designscenarios(explore policy,', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 2}}, {'id': 1753903424509295, 'score': 0.71478057, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753903424243022, 'score': 0.7059052, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_10_md', 'type': 'markdown', 'content': \" * ### The Climate and Forecast (CF) Metadata Conventions (prominent in climate science)\\n \\nGiven the amount of data produced keeps increasing, data libraries are being developed. As in any library, certain sets of rules are required so that the data can be found later. Metadata are obviously a good way to ensure data can be catalogued and found by various search systems.\\n\\nMultiple types of conventions exist (see for example this [list of netCDF conventions from Unidata](https://www.unidata.ucar.edu/software/netcdf/conventions.html)). Ensuring that data files are produced in a way that follows conventions about content, vocabulary used and layout, allows for batch processing, easy extraction and automation! It is extremely useful (but should not prevent innovation).\\n\\nCEDA, as it focuses on climate and environmental data, relies extensively on the [Climate and Forecast (CF) Conventions](http://cfconventions.org). The CF Conventions are probably the most popular in climate science (it underpins the modelling effort of the IPCC). A detailed description of the latest release of the CF Conventions for netCDF can be found [here](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.9/cf-conventions.html). \\n\\nThe CF Conventions were designed specifically for the netCDF format but they can be applied widely. The netCDF format enables creation of self-describing datasets by design. CF Conventions aim to ensure that  files contain sufficient metadata that they are self-describing in the sense that each variable in the file has an associated description of what it represents, including physical units if appropriate, and that each value can be located in space (relative to earth-based coordinates) and time. (Absence of such information in early (historical) datasets has hindered climate change science for decades - how does one measure change, if one cannot locate the observations in time and space?)\\n\\nOne example of CF Conventions is to provide a list of **standard_names** for certain commonly-used variables. The [CF standard name table] (http://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html) will show what the names are and describe what they represent. \\n\\nTo illustrate, imagine you work with data at the earth surface and label your variable 'temperature'. What did you mean exactly? Surface temperature of the ocean/land, or air temperature? etc. CF conventions ensure that climate scientists name common variables in the same way. \\n\\nA [python package](https://pypi.org/project/cfunits/) called `cfunits` provides an interface to the CF Convention. This is useful to combine and compare variables and convert various units. By relying on a package, fewer user-errors are made.   \\n\\nThe CF Conventions are not fixed, they are evolving depending on needs and scientific progress. Although conventions are decided by a committee of experts, anyone can propose a change to the convention by engaging in the [discussion forum](https://cfconventions.org/discussion.html).\\n\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 10}}, {'id': 1753902702944729, 'score': 0.6992221, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753901957112878, 'score': 0.69918776, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_0', 'type': 'pdf', 'content': 'https://svs.gsfc.nasa.gov/30701Climate data and modelsEDSML MSc –Imperial College London –Environmental dataYves Plancherel-https://www.linkedin.com/in/yves-plancherel/\\nWhy discuss climate data and climate models?\\n1. Understand common data format and databasestructures specific to representative fields of environmental science2. Demonstrate technical competency in handling common data types routinely encountered in the environmental sciences and identify relevant open-source data repositories3. ', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 0}}, {'id': 1753901956747387, 'score': 0.6984925, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_1', 'type': 'pdf', 'content': 'Identify and design suitable data analysis strategies that consider data types, data distribution constraints, strength, benefits and limitations of statistical and modelling tools and environmental dynamics.4. Understand the limitation of available data and data analysis products. Understand sources of errors and demonstrate ability to comprehensively characterize uncertainties and interpret results in the context of these uncertainties, including measurement errors, environmental uncertainties', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 1}}, {'id': 1753901956917450, 'score': 0.69379467, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753903424143550, 'score': 0.6935719, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_11_md', 'type': 'markdown', 'content': \"<a id='NetCDF'></a>\\n\\n## Network Common Data Form (NetCDF)\\n\\n[NetCDF](https://www.unidata.ucar.edu/software/netcdf/) is one of the most common data format used to store climate data. NetCDF files allow the user to insert metadata in the data file by design, ensuring the data file is self-describing (amongst other properties).\\n\\n*NetCDF is a set of software libraries and machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.* \\n\\nThe netCDF format, which is a type of HDF format, is attractive because it is:\\n\\n* Self-Describing. A netCDF file includes information about the data it contains and metadata.\\n* Portable. A netCDF file can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\\n* Scalable. Small subsets of large datasets in various formats may be accessed efficiently through netCDF interfaces, even from remote servers.\\n* Appendable. Data may be appended to a properly structured netCDF file without copying the dataset or redefining its structure.\\n* Sharable. One writer and multiple readers may simultaneously access the same netCDF file.\\n* Archivable. Access to all earlier forms of netCDF data will be supported by current and future versions of the software.\\n\\n\\nThe NetCDF project is maintained by the Unidata program at the University Corporation for Atmospheric Research ([UCAR](https://www.ucar.edu)). [UCAR](https://www.ucar.edu) also manages [NCAR](https://ncar.ucar.edu), one of the first center to have developped climate models and is today one of the gold-standard on the topic. \\n\\nNCAR also developed [NCL](https://www.ncl.ucar.edu), an interpreted programming language designed specifically for scientific data analysis and visualization (we will not use NCL here, but the python package `ESMValTool` has build-in support for it). \\n\\n[NCAR](https://ncar.ucar.edu) has also developped the [climate data guide](https://climatedataguide.ucar.edu), a tool to search and access >200 data sets specific to the ocean, land and the atmosphere. (Some of these data may or may not also be found on CEDA.) \\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 11}}, {'id': 1753903424357433, 'score': 0.68906844, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_5_md', 'type': 'markdown', 'content': \"<a id='climatedata'></a>\\n\\n# Working with climate data and climate models\\n\\n### Earth System Grid Federation (ESGF)\\n\\n![esgf](img/ESGF_logo.png)\\n\\n\\n[ESGF](https://esgf.llnl.gov) is an open-source platform that provides distributed access to peta/exa-scale scientific data, **globally**. \\n\\nIt is an interagency and international effort led by the US Department of Energy (DOE), co-funded by National Aeronautics and Space Administration (NASA), National Oceanic and Atmospheric Administration (NOAA), the US National Science Foundation (NSF), and other international partners, such as the Max Planck Institute for Meteorology (MPI-M) German Climate Computing Centre (DKRZ), the Australian National University (ANU) National Computational Infrastructure (NCI), Institut Pierre-Simon Laplace (IPSL), and the **Centre for Environmental Data Analysis ([CEDA](https://www.ceda.ac.uk))** in the UK.\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 5}}]",
      "[{'id': 1753903424143550, 'score': 0.6823662, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_11_md', 'type': 'markdown', 'content': \"<a id='NetCDF'></a>\\n\\n## Network Common Data Form (NetCDF)\\n\\n[NetCDF](https://www.unidata.ucar.edu/software/netcdf/) is one of the most common data format used to store climate data. NetCDF files allow the user to insert metadata in the data file by design, ensuring the data file is self-describing (amongst other properties).\\n\\n*NetCDF is a set of software libraries and machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.* \\n\\nThe netCDF format, which is a type of HDF format, is attractive because it is:\\n\\n* Self-Describing. A netCDF file includes information about the data it contains and metadata.\\n* Portable. A netCDF file can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\\n* Scalable. Small subsets of large datasets in various formats may be accessed efficiently through netCDF interfaces, even from remote servers.\\n* Appendable. Data may be appended to a properly structured netCDF file without copying the dataset or redefining its structure.\\n* Sharable. One writer and multiple readers may simultaneously access the same netCDF file.\\n* Archivable. Access to all earlier forms of netCDF data will be supported by current and future versions of the software.\\n\\n\\nThe NetCDF project is maintained by the Unidata program at the University Corporation for Atmospheric Research ([UCAR](https://www.ucar.edu)). [UCAR](https://www.ucar.edu) also manages [NCAR](https://ncar.ucar.edu), one of the first center to have developped climate models and is today one of the gold-standard on the topic. \\n\\nNCAR also developed [NCL](https://www.ncl.ucar.edu), an interpreted programming language designed specifically for scientific data analysis and visualization (we will not use NCL here, but the python package `ESMValTool` has build-in support for it). \\n\\n[NCAR](https://ncar.ucar.edu) has also developped the [climate data guide](https://climatedataguide.ucar.edu), a tool to search and access >200 data sets specific to the ocean, land and the atmosphere. (Some of these data may or may not also be found on CEDA.) \\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 11}}, {'id': 1753903424407566, 'score': 0.6724614, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_15_md', 'type': 'markdown', 'content': '### A sidenote on remote data access\\n\\nNote that `Dataset` could also read a remote [OPeNDAP](https://www.opendap.org)-hosted dataset over http if a URL is provided instead of a filename. If you can access a file remotely, it may be best to do so, as it unburdens you from the cost of storage! However, you should also ensure that users will have continous access to the file for the duration of the project, and maybe later also if archiving of the results is required. \\n\\n[OPeNDAP](https://www.opendap.org) stands for Open-source Project for a Network Data Protocol and is a software for remote data retrieval, commonly used in Earth science. It allows one to access data via the internet, allowing one to retrieve data when needed, without having to necessarily download all the data locally, what facilitates real-time analysis. \\n\\nOther commonly encountered remote-access protocols are [THREDDS](https://www.unidata.ucar.edu/software/tds/current/) and [ERDDAP](https://upwell.pfeg.noaa.gov/erddap/index.html). \\n\\n[THREDDS](https://www.unidata.ucar.edu/software/tds/current/) stands for Thematic Real-time Environmental Distributed Data Services. The THREDDS Data Server ([TDS](https://docs.unidata.ucar.edu/tds/current/userguide/index.html)) is another Unidata service that provides remote access to real-time or archived datasets. It is a web server that provides metadata and data access for scientific datasets, using a variety of remote data access protocols, including OPeNDAP. The THREDDS data catalogue of meteorological data is available [here](https://thredds.ucar.edu/thredds/catalog.html). \\n\\n[ERDDAP](https://upwell.pfeg.noaa.gov/erddap/index.html) is also a data server by the National Oceanic and Atmospheric Administration (NOAA, USA) that acts as a middleman between the user and various other data servers. You can see a [list of datasets available through ERDDAP here](https://upwell.pfeg.noaa.gov/erddap/info/index.html?page=1&itemsPerPage=1000). ERDDAP provides a consistent way to download subsets of gridded and tabular data in common file formats. ERDDAP is  a  tool that facilitates user interactions so the user doesnt have to know about OPeNDAP or other remote access protocols (such as OPeNDAP).\\n\\n[back to contents](#Contents)\\n\\n---', 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 15}}, {'id': 1753903424228032, 'score': 0.6662594, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_43_md', 'type': 'markdown', 'content': '### The CDS Toolbox\\n\\nAn extention to the CDS API is the [CDS Toolbox](https://cds.climate.copernicus.eu/toolbox/doc/index.html). The Toolbox is a programming interface. It is free and available to everyone. It links raw data to an online computing facility, thereby removing the computing barrier for users worldwide. The Toolbox allows users to develop python scripts for the CDS and to run them online. The users than then simply download the maps, graph or secondary data without needing to incur the costs associated with storing and maintaining the large climate data archive locally, nor is it required to invest in a powerful computer. \\n\\n\\nThe Toolbox works hand-in-hand with the CDS API. \\n\\nThat is, one can issue commmands to the Toolbox via the CDS API, or develop a python script that does certain things, and then use the CDS API functionality to send it to CDS for evaluation, only to download the finished product locally. \\n\\nExamples of how to proceed are given [here](https://confluence.ecmwf.int/display/COPSRV/Call+a+service+with+the+CDS+API). \\n\\nNote, it is also possible to use the CDS Toolbox to plot data from other services (i.e. not originally stored on CDS), using the `remote` function instead of the `service` function. This is possible thanks to protocols such as OPeNDAP. Here is an example using data from UNIDATA. \\n\\nFor illustration of how the Toolbox can be used, the following piece of code, run locally, after the CDS API is properly configured and assuming one is connected to the internet, will produce, and then download to our `output/` directory, a map of global temperature on January 1st 2021 at 14:00.', 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 43}}, {'id': 1753903424509295, 'score': 0.66346824, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753903424262111, 'score': 0.66012394, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_38_md', 'type': 'markdown', 'content': \"<a id='reanalysis'></a>\\n\\n# Reanalysis products\\n\\n![C3S](img/c3s-logo.png)\\n![ECMWF](img/logo-ecmwf.png) \\n\\n[*ERA5 provides hourly estimates of a large number of atmospheric, land and oceanic climate variables. The data cover the Earth on a 30km grid and resolve the atmosphere using 137 levels from the surface up to a height of 80km. ERA5 includes information about uncertainties for all variables at reduced spatial and temporal resolutions.Quality-assured monthly updates of ERA5 (1979 to present) are published within 3 months of real time. Preliminary daily updates of the dataset are available to users within 5 days of real time.*](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5)\\n\\n[ERA5](https://confluence.ecmwf.int/display/CKB/ERA5) is a [family of datasets](https://confluence.ecmwf.int/display/CKB/The+family+of+ERA5+datasets). It currently comprises ERA5, ERA5.1 and ERA5-Land. ERA5 is the fifth generation ECMWF atmospheric reanalysis of the global climate covering the period from January 1950 to present. ERA5 is produced by the Copernicus Climate Change Service ([C3S](https://confluence.ecmwf.int/pages/viewpage.action?pageId=151530614)) at the European Center for Medium-Range Weather Forecasts ([ECMWF](https://www.ecmwf.int)) and made available via the [Climate Change Service](https://climate.copernicus.eu). \\n\\nImportantly, ERA5 is a [**reanalysis product**](https://www.youtube.com/watch?v=FAGobvUGl24), meaning a **model that assimilates data**. A model of the climate (weather) is run, and adjusted (following certain laws of physics and constraints) to fit [as many observations](https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation#ERA5:datadocumentation-Observations) as possible using a technique called 4D-var. One must realize that, even if assimimated prodcuts such as ERA5 are often used 'in lieu' of observations, they are **\\\\*not\\\\*** observations: they are a model product, but a product that is made to look as much like the data as possible given computational, mathematical, physical limitations of the model. \\n\\nERA5 is one of various [reanalysis products](https://reanalyses.org) available globally. Another well-known produce is the [NCEP/NCAR Reanalysis product](https://en.wikipedia.org/wiki/NCEP/NCAR_Reanalysis). [MERRA-2](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/), produced by NASA, is another. \\n\\nThe article by [Hersbach et al. 2020](https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.3803) discusses the ERA global Reanalysis prodcuct in more detail.\\n\\nWhile observations are only available in specific locations and at specific times, the reanalysis product provides a clever way to dynamically interpolate between these observations. ERA5 also comes as a gridded product, making it very convenient to use. In the model-world, one can access a complete/global picture every time-step, with a spatial resolution as high as computational limits allow. I re-emphasize that this is not the same as observations! ... but it is as close to observations as we can get if one is trying to work with a spatially and temporall interpolated product. \\n\\n**Grid geometry depends on data format**: Note that the grid geometry of the output data of ERA5 [depends on the format the data that are being downloaded](https://confluence.ecmwf.int/display/CKB/ERA5%3A+What+is+the+spatial+reference). Native GRIB format data are delivered on the model's native grid geometry (this is not a regular lat/lon grid!). On the other hand, data in NetCDF format are automatically interpolated and regridded to a regular lat/lon grid. While this is not very important for most application, one must remember that interpolated data in the NetCDF files are not the same as the original model output and this could have implication for the conservation properties of some variables. It can be easier/convenient to work with data interpolated on a regular lat/lon grid, however.  \\n\\n**Grid definition and wrap-around**: The gridded ERA5 archive is provided on a [-90;+90] latitude grid and a [0;+360] longitude grid, with decimal degrees, referenced to the Greenwich Prime Meridian. While latitude is generally not an issue, care must be taken when working with longitude as one must remember that 0 and 360 are the same point. One must account for the wrap-around issue: although the first column and last column of a datasets on the [0;+360] grid are far away from each other in terms of index, these points are geographically very close. Some software can automatically deal with this wrap-around and convert to [-180;+180] or other system as required, but this should not be taken for granted. \\n\\n\\n[back to contents](#Contents)\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 38}}, {'id': 1753903424243022, 'score': 0.6584284, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_10_md', 'type': 'markdown', 'content': \" * ### The Climate and Forecast (CF) Metadata Conventions (prominent in climate science)\\n \\nGiven the amount of data produced keeps increasing, data libraries are being developed. As in any library, certain sets of rules are required so that the data can be found later. Metadata are obviously a good way to ensure data can be catalogued and found by various search systems.\\n\\nMultiple types of conventions exist (see for example this [list of netCDF conventions from Unidata](https://www.unidata.ucar.edu/software/netcdf/conventions.html)). Ensuring that data files are produced in a way that follows conventions about content, vocabulary used and layout, allows for batch processing, easy extraction and automation! It is extremely useful (but should not prevent innovation).\\n\\nCEDA, as it focuses on climate and environmental data, relies extensively on the [Climate and Forecast (CF) Conventions](http://cfconventions.org). The CF Conventions are probably the most popular in climate science (it underpins the modelling effort of the IPCC). A detailed description of the latest release of the CF Conventions for netCDF can be found [here](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.9/cf-conventions.html). \\n\\nThe CF Conventions were designed specifically for the netCDF format but they can be applied widely. The netCDF format enables creation of self-describing datasets by design. CF Conventions aim to ensure that  files contain sufficient metadata that they are self-describing in the sense that each variable in the file has an associated description of what it represents, including physical units if appropriate, and that each value can be located in space (relative to earth-based coordinates) and time. (Absence of such information in early (historical) datasets has hindered climate change science for decades - how does one measure change, if one cannot locate the observations in time and space?)\\n\\nOne example of CF Conventions is to provide a list of **standard_names** for certain commonly-used variables. The [CF standard name table] (http://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html) will show what the names are and describe what they represent. \\n\\nTo illustrate, imagine you work with data at the earth surface and label your variable 'temperature'. What did you mean exactly? Surface temperature of the ocean/land, or air temperature? etc. CF conventions ensure that climate scientists name common variables in the same way. \\n\\nA [python package](https://pypi.org/project/cfunits/) called `cfunits` provides an interface to the CF Convention. This is useful to combine and compare variables and convert various units. By relying on a package, fewer user-errors are made.   \\n\\nThe CF Conventions are not fixed, they are evolving depending on needs and scientific progress. Although conventions are decided by a committee of experts, anyone can propose a change to the convention by engaging in the [discussion forum](https://cfconventions.org/discussion.html).\\n\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 10}}, {'id': 1753903424357433, 'score': 0.65216094, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_5_md', 'type': 'markdown', 'content': \"<a id='climatedata'></a>\\n\\n# Working with climate data and climate models\\n\\n### Earth System Grid Federation (ESGF)\\n\\n![esgf](img/ESGF_logo.png)\\n\\n\\n[ESGF](https://esgf.llnl.gov) is an open-source platform that provides distributed access to peta/exa-scale scientific data, **globally**. \\n\\nIt is an interagency and international effort led by the US Department of Energy (DOE), co-funded by National Aeronautics and Space Administration (NASA), National Oceanic and Atmospheric Administration (NOAA), the US National Science Foundation (NSF), and other international partners, such as the Max Planck Institute for Meteorology (MPI-M) German Climate Computing Centre (DKRZ), the Australian National University (ANU) National Computational Infrastructure (NCI), Institut Pierre-Simon Laplace (IPSL), and the **Centre for Environmental Data Analysis ([CEDA](https://www.ceda.ac.uk))** in the UK.\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 5}}, {'id': 1753903424142956, 'score': 0.64526, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_4_md', 'type': 'markdown', 'content': \"<a id='ESMValTool'></a>\\n\\n# Python environments to consider for working with climate data \\n\\n* ## Earth System Model Evaluation Tool (ESMValTool)\\n![esmvaltool](img/ESMValTool-logo-2.png)\\n\\nThis week, it should be possible to simply install packages as needed...\\n\\nHowever, if you anticipate possible future needs, you may want to invest a bit of effort to setup a specific python environment to work with climate data. If so, a good place to start is the `ESMValTool` project. \\n\\n\\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) is  a community-led, open source, set of software tools (build on python 3) developed to improve diagnosing and understanding climate models. While the focus has been on climate models, not observations, one cannot quantify model biases without also comparing the model results with observations. [ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) therefore also has some capability to analyze and manipulate large datasets. \\n\\n[ESMValTool](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/index.html) can work offline, but as the amount of climate data is so large, it is mostly designed to work with data centers that provide local access to the vast amount of data. One such initiative is the Earth System Grid Federation ([ESGF](https://esgf.llnl.gov)). ESMValTool provides functionality to work on HPC systems.\\n\\nWe will not use ESMValTool here specifically, but it will install other convenient tools and you may be curious to investigate ESMValTool capabilities on your own anyways. It is now used routinely for climate modelling research. \\n\\nAdditional information and help can be found at https://www.esmvaltoolorg, and on the [ESMValGroup](https://github.com/ESMValGroup) github page. The [ESMValTool tutorial](https://esmvalgroup.github.io/ESMValTool_Tutorial/) is a great resource to get started. \\n\\n\\n### OPTIONAL: Installing ESMValTool (NB: this often fails for students - installing this is not required for the course)\\n[Installation instructions](https://docs.esmvaltool.org/en/latest/quickstart/installation.html) differ by operating system and it is very much an experimental, in development, tool - keep this in mind! \\n\\n[Notes:ESMValTool 2.0 requires a Unix(-like) operating system and Python 3.7+. (Python 3.7, 3.8 and 3.9 are supported). On my laptop (Macbook pro 13'' M1 2020 with OS Monterey 12.0.1), I installed it in Nov 2021 with Python 3.9.7. ...but I installed it when 'conda' was still an installation option. ESMValTool developer have  changed installation methods to `mamba` recently. Do refer to online/official instructions). You will now be required to also [install `mamba`](https://docs.esmvaltool.org/en/latest/quickstart/installation.html#mamba-installation) first (...yet another package/dependency manager).] \\n\\nESMValTool can also work with Julia, R, NCL. Do check installation instructions for these extensions. \\n\\n[back to contents](##Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 4}}, {'id': 1753903424623019, 'score': 0.64165926, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_37_md', 'type': 'markdown', 'content': \"### Climate Data Operators (CDO)\\nThe Climate Data Operators ([CDO](https://code.mpimet.mpg.de/projects/cdo)) software is a collection of >600 operators for standard processing of climate and forecast model data. They are slighly less memory/speed efficient than NCO, but they do more (>600 vs 12!). CDO support the main data formats used in the field, such as GRIB and netCDF. \\n\\nThey too can be daisy-chained for specific applications. There are [many recipes available](https://code.mpimet.mpg.de/projects/cdo/embedded/cdo_eca.pdf) to calculate various climate indices and diagnostics, what makes them very attractive to evaluate gridded climate data or climate model output.\\n\\nThe [CDO user guide](https://code.mpimet.mpg.de/projects/cdo/embedded/index.html) provides details instructions and examples. \\n\\n[They are also very useful, but we don't have time to discuss them in detail here. You are encouraged to practice with CDO on your own time]\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 37}}, {'id': 1753903424804905, 'score': 0.6415795, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_42_code', 'type': 'code', 'content': \"#!/usr/bin/env python\\nimport cdsapi\\n \\nc = cdsapi.Client()\\n \\nc.retrieve(\\n    'reanalysis-era5-pressure-levels',\\n    {\\n        'product_type': 'reanalysis',\\n        'variable': 'temperature',\\n        'pressure_level': '1000',\\n        'year': '2021',\\n        'month': '01',\\n        'day': '01',\\n        'time': '12:00',\\n        'format': 'netcdf',                         # NetCDF\\n        'area'          : [60., -11., 34., 35.],    # Default area is global; provide [North, West, South, East] limits to select an area (here selecting Europe)\\n        'grid'          : [1.0, 1.0],               #  Default atmospheric resolution is 0.25 x 0.25; provie [Latitude/longitude] grid resolution to interpolate data to something else.           \\n    },\\n    'output/ERAtest_subarea_1deg1deg.nc')           # Output file. Adapt as you wish.\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 42}}]",
      "[{'id': 1753903424143550, 'score': 0.7401922, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_11_md', 'type': 'markdown', 'content': \"<a id='NetCDF'></a>\\n\\n## Network Common Data Form (NetCDF)\\n\\n[NetCDF](https://www.unidata.ucar.edu/software/netcdf/) is one of the most common data format used to store climate data. NetCDF files allow the user to insert metadata in the data file by design, ensuring the data file is self-describing (amongst other properties).\\n\\n*NetCDF is a set of software libraries and machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.* \\n\\nThe netCDF format, which is a type of HDF format, is attractive because it is:\\n\\n* Self-Describing. A netCDF file includes information about the data it contains and metadata.\\n* Portable. A netCDF file can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\\n* Scalable. Small subsets of large datasets in various formats may be accessed efficiently through netCDF interfaces, even from remote servers.\\n* Appendable. Data may be appended to a properly structured netCDF file without copying the dataset or redefining its structure.\\n* Sharable. One writer and multiple readers may simultaneously access the same netCDF file.\\n* Archivable. Access to all earlier forms of netCDF data will be supported by current and future versions of the software.\\n\\n\\nThe NetCDF project is maintained by the Unidata program at the University Corporation for Atmospheric Research ([UCAR](https://www.ucar.edu)). [UCAR](https://www.ucar.edu) also manages [NCAR](https://ncar.ucar.edu), one of the first center to have developped climate models and is today one of the gold-standard on the topic. \\n\\nNCAR also developed [NCL](https://www.ncl.ucar.edu), an interpreted programming language designed specifically for scientific data analysis and visualization (we will not use NCL here, but the python package `ESMValTool` has build-in support for it). \\n\\n[NCAR](https://ncar.ucar.edu) has also developped the [climate data guide](https://climatedataguide.ucar.edu), a tool to search and access >200 data sets specific to the ocean, land and the atmosphere. (Some of these data may or may not also be found on CEDA.) \\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 11}}, {'id': 1753903424243022, 'score': 0.71442, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_10_md', 'type': 'markdown', 'content': \" * ### The Climate and Forecast (CF) Metadata Conventions (prominent in climate science)\\n \\nGiven the amount of data produced keeps increasing, data libraries are being developed. As in any library, certain sets of rules are required so that the data can be found later. Metadata are obviously a good way to ensure data can be catalogued and found by various search systems.\\n\\nMultiple types of conventions exist (see for example this [list of netCDF conventions from Unidata](https://www.unidata.ucar.edu/software/netcdf/conventions.html)). Ensuring that data files are produced in a way that follows conventions about content, vocabulary used and layout, allows for batch processing, easy extraction and automation! It is extremely useful (but should not prevent innovation).\\n\\nCEDA, as it focuses on climate and environmental data, relies extensively on the [Climate and Forecast (CF) Conventions](http://cfconventions.org). The CF Conventions are probably the most popular in climate science (it underpins the modelling effort of the IPCC). A detailed description of the latest release of the CF Conventions for netCDF can be found [here](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.9/cf-conventions.html). \\n\\nThe CF Conventions were designed specifically for the netCDF format but they can be applied widely. The netCDF format enables creation of self-describing datasets by design. CF Conventions aim to ensure that  files contain sufficient metadata that they are self-describing in the sense that each variable in the file has an associated description of what it represents, including physical units if appropriate, and that each value can be located in space (relative to earth-based coordinates) and time. (Absence of such information in early (historical) datasets has hindered climate change science for decades - how does one measure change, if one cannot locate the observations in time and space?)\\n\\nOne example of CF Conventions is to provide a list of **standard_names** for certain commonly-used variables. The [CF standard name table] (http://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html) will show what the names are and describe what they represent. \\n\\nTo illustrate, imagine you work with data at the earth surface and label your variable 'temperature'. What did you mean exactly? Surface temperature of the ocean/land, or air temperature? etc. CF conventions ensure that climate scientists name common variables in the same way. \\n\\nA [python package](https://pypi.org/project/cfunits/) called `cfunits` provides an interface to the CF Convention. This is useful to combine and compare variables and convert various units. By relying on a package, fewer user-errors are made.   \\n\\nThe CF Conventions are not fixed, they are evolving depending on needs and scientific progress. Although conventions are decided by a committee of experts, anyone can propose a change to the convention by engaging in the [discussion forum](https://cfconventions.org/discussion.html).\\n\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 10}}, {'id': 1753903424509295, 'score': 0.7094548, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753901956989969, 'score': 0.6945855, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_2', 'type': 'pdf', 'content': ' as well as errors stemming from the analytical procedure itself (e.g.calibration of analysis using synthetic data/models).Learning objectives of the Environmental Data module•Growing/important field –with likely career opportunities•Great playground to deliver learning objectives\\nUsing climate models: quantification/forecasting(impacts, adaptation, mitigation)\\nhttps://www.noaa.gov/education/resource-collections/climate/climate-change-impacts\\nUsing climate models: designscenarios(explore policy,', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 2}}, {'id': 1753901957112878, 'score': 0.69392455, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_0', 'type': 'pdf', 'content': 'https://svs.gsfc.nasa.gov/30701Climate data and modelsEDSML MSc –Imperial College London –Environmental dataYves Plancherel-https://www.linkedin.com/in/yves-plancherel/\\nWhy discuss climate data and climate models?\\n1. Understand common data format and databasestructures specific to representative fields of environmental science2. Demonstrate technical competency in handling common data types routinely encountered in the environmental sciences and identify relevant open-source data repositories3. ', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 0}}, {'id': 1753903424623019, 'score': 0.6911695, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_37_md', 'type': 'markdown', 'content': \"### Climate Data Operators (CDO)\\nThe Climate Data Operators ([CDO](https://code.mpimet.mpg.de/projects/cdo)) software is a collection of >600 operators for standard processing of climate and forecast model data. They are slighly less memory/speed efficient than NCO, but they do more (>600 vs 12!). CDO support the main data formats used in the field, such as GRIB and netCDF. \\n\\nThey too can be daisy-chained for specific applications. There are [many recipes available](https://code.mpimet.mpg.de/projects/cdo/embedded/cdo_eca.pdf) to calculate various climate indices and diagnostics, what makes them very attractive to evaluate gridded climate data or climate model output.\\n\\nThe [CDO user guide](https://code.mpimet.mpg.de/projects/cdo/embedded/index.html) provides details instructions and examples. \\n\\n[They are also very useful, but we don't have time to discuss them in detail here. You are encouraged to practice with CDO on your own time]\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 37}}, {'id': 1753902300429530, 'score': 0.6891463, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902702794239, 'score': 0.6853688, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753903424357433, 'score': 0.68013996, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_5_md', 'type': 'markdown', 'content': \"<a id='climatedata'></a>\\n\\n# Working with climate data and climate models\\n\\n### Earth System Grid Federation (ESGF)\\n\\n![esgf](img/ESGF_logo.png)\\n\\n\\n[ESGF](https://esgf.llnl.gov) is an open-source platform that provides distributed access to peta/exa-scale scientific data, **globally**. \\n\\nIt is an interagency and international effort led by the US Department of Energy (DOE), co-funded by National Aeronautics and Space Administration (NASA), National Oceanic and Atmospheric Administration (NOAA), the US National Science Foundation (NSF), and other international partners, such as the Max Planck Institute for Meteorology (MPI-M) German Climate Computing Centre (DKRZ), the Australian National University (ANU) National Computational Infrastructure (NCI), Institut Pierre-Simon Laplace (IPSL), and the **Centre for Environmental Data Analysis ([CEDA](https://www.ceda.ac.uk))** in the UK.\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 5}}, {'id': 1753903424703434, 'score': 0.6797091, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_26_md', 'type': 'markdown', 'content': \"- **Attributes**: The last category of information required are 'attributes'. Attributes can be `global' or 'variable'-specific. 'Global' attributes are for the whole Dataset or the group. 'Variable' attributes only inform on a specific variable (or coordinate variable).  \\n\\n`Dataset.ncattrs` can be used to retrieve attributes from a NetCDF file. Alternatively, the `__dict__` attribute of a Dataset, Group or Variable will return the name/value pairs for all the attributes. \\n\\nLet's define some attribute to the time coordinate variable (or dimension):\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 26}}]"
    ],
    "response": "The code snippet provided appears to be a Jupyter Notebook, which is a web-based interactive computing environment for working with Python. The notebook contains various cells that display different types of content, including text, images, and PDFs.\n\nHere's a breakdown of the code snippet:\n\n1. **Header**: The first cell displays a header with the title \"01- Introduction to climate data and climate models\".\n2. **Contents**: The next cell displays a list of contents for the notebook, which includes sections on lectures, questions, ESMValTool, sources of climate data, CEDA, file formats, metadata, NetCDF, NCO, reanalysis products, and Climate Services UKCP18.\n3. **Learning outcomes**: The following cell displays a list of learning outcomes for the notebook, which include understanding the basics of climate modeling, knowing where to find and how to access climate data, understanding common file formats, and more.\n4. **PDFs**: The next few cells display PDFs related to climate data and models, including \"Why discuss climate data and climate models?\", \"Building climate models\", and \"Common issues\".\n5. **ESGF**: The cell after the PDFs displays information about the Earth System Grid Federation (ESGF), an open-source platform that provides distributed access to scientific data globally.\n6. **Attributes**: The final cell displays a section on attributes, which includes information on how to retrieve attributes from a NetCDF file using the `Dataset.ncattrs` method or the `__dict__` attribute of a Dataset, Group, or Variable.\n\nOverall, this code snippet appears to be an introduction to climate data and models, covering topics such as learning outcomes, PDFs, ESGF, and attributes.",
    "reference": "Climate data is crucial because it supports understanding environmental dynamics, evaluating the effects of climate change, and informs policy, adaptation, and mitigation strategies.",
    "iteration_scores": [
      {
        "iteration": 1,
        "decomposition": 8.0,
        "retrieval": 5.666666666666667,
        "generation": 7.0,
        "total": 6.888888888888889
      },
      {
        "iteration": 2,
        "decomposition": 8.0,
        "retrieval": 4.8,
        "generation": 8.4,
        "total": 7.066666666666667
      },
      {
        "iteration": 3,
        "decomposition": 8.0,
        "retrieval": 3.0,
        "generation": 3.0999999999999996,
        "total": 4.7
      }
    ]
  },
  {
    "user_input": "How would you use discretization to convert a climate model equation into a numerically solvable format?",
    "retrieved_contexts": [
      "[{'id': 1753902300472417, 'score': 0.6537592, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902299806645, 'score': 0.65255135, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902300119549, 'score': 0.63935065, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_5', 'type': 'pdf', 'content': 'added)•flows forward, then flows backwards•Ideally,shouldreturntoinitialvalues•Deviations are indicative of numerical issues\\nTesting the numerical core…when we don’t have an exact solution to compare to\\nThis highlights the problem of numerical diffusionEach schemewillhaveitsownweaknesses andstrengths (and conservation properties)\\nWhat does a numericalmodel need?summary•Need equations (+ parameterizations)–Output = function(input)•Need a starting point–Boundary conditions•Must define time and spa', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 5}}, {'id': 1753902299901317, 'score': 0.6319537, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_3', 'type': 'pdf', 'content': ' an extra equation(implicit scheme)\\nii+1\\n\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−Ci−12Δt=λCiCi+1=2λΔtCi+Ci−1Centered differenceRequires knowing more things from more points\\nii+1i-1\\nThe “dynamical/numerical core” of a model matters …a lot!•System of equation (partial differentials in 3D)•Discretizationand integrationscheme–These 3 are mathematically all valid but can produce very different answers when implemented…Ci+1=Ci1+λΔt()Forward difference(aka Forw', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 3}}, {'id': 1753903968314666, 'score': 0.62380475, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_7_md', 'type': 'markdown', 'content': \"One can then use the arrays **X** and **Y** to directly evaluate functions over the entire grid, for example.\\n\\n**Note**: When working with model output, you may see that the latitudes an longitudes may be supplied either as vectors (**x,y**) or as two arrays (**X,Y**). This generally depends on whether the data are supplied on a regular grid (fixed latitudes and longtiude steps), or not. The native model grids are rarely regular (they can be curved and the resolution typically changes regionally, so providing vectors of latitudes and longitudes simply wouldn't make any sense). \", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 7}}, {'id': 1753902703475561, 'score': 0.6087189, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_11', 'type': 'pdf', 'content': 'uction, what does “right” even mean?•What do we do if one model can represent a variable better but another variable worst?•A model can reproduce the mean state well but not the variability. Is it a “good” model?•What if model solution shows spatial and temporal patterns well, but is consistently offset?•Embrace/accept that sometimes the best we can do is to provide a probabilistic answer to questions\\nDifferent variablesDifferent modelsError relative to the multi-model meanLess than meanMore tha', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 11}}]",
      "[{'id': 1753902299806645, 'score': 0.8042548, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902300472417, 'score': 0.7818416, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902300206271, 'score': 0.74173254, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}, {'id': 1753902300429530, 'score': 0.74096376, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902703503123, 'score': 0.7051431, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753901956917450, 'score': 0.7015265, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753903424509295, 'score': 0.6970422, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753902702944729, 'score': 0.6921416, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753902703274403, 'score': 0.686095, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753903424623019, 'score': 0.6837703, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_37_md', 'type': 'markdown', 'content': \"### Climate Data Operators (CDO)\\nThe Climate Data Operators ([CDO](https://code.mpimet.mpg.de/projects/cdo)) software is a collection of >600 operators for standard processing of climate and forecast model data. They are slighly less memory/speed efficient than NCO, but they do more (>600 vs 12!). CDO support the main data formats used in the field, such as GRIB and netCDF. \\n\\nThey too can be daisy-chained for specific applications. There are [many recipes available](https://code.mpimet.mpg.de/projects/cdo/embedded/cdo_eca.pdf) to calculate various climate indices and diagnostics, what makes them very attractive to evaluate gridded climate data or climate model output.\\n\\nThe [CDO user guide](https://code.mpimet.mpg.de/projects/cdo/embedded/index.html) provides details instructions and examples. \\n\\n[They are also very useful, but we don't have time to discuss them in detail here. You are encouraged to practice with CDO on your own time]\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 37}}]",
      "[{'id': 1753902299806645, 'score': 0.6714009, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902300472417, 'score': 0.66593874, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902300119549, 'score': 0.63242835, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_5', 'type': 'pdf', 'content': 'added)•flows forward, then flows backwards•Ideally,shouldreturntoinitialvalues•Deviations are indicative of numerical issues\\nTesting the numerical core…when we don’t have an exact solution to compare to\\nThis highlights the problem of numerical diffusionEach schemewillhaveitsownweaknesses andstrengths (and conservation properties)\\nWhat does a numericalmodel need?summary•Need equations (+ parameterizations)–Output = function(input)•Need a starting point–Boundary conditions•Must define time and spa', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 5}}, {'id': 1753902299901317, 'score': 0.6321685, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_3', 'type': 'pdf', 'content': ' an extra equation(implicit scheme)\\nii+1\\n\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−Ci−12Δt=λCiCi+1=2λΔtCi+Ci−1Centered differenceRequires knowing more things from more points\\nii+1i-1\\nThe “dynamical/numerical core” of a model matters …a lot!•System of equation (partial differentials in 3D)•Discretizationand integrationscheme–These 3 are mathematically all valid but can produce very different answers when implemented…Ci+1=Ci1+λΔt()Forward difference(aka Forw', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 3}}, {'id': 1753903968314666, 'score': 0.6216644, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_7_md', 'type': 'markdown', 'content': \"One can then use the arrays **X** and **Y** to directly evaluate functions over the entire grid, for example.\\n\\n**Note**: When working with model output, you may see that the latitudes an longitudes may be supplied either as vectors (**x,y**) or as two arrays (**X,Y**). This generally depends on whether the data are supplied on a regular grid (fixed latitudes and longtiude steps), or not. The native model grids are rarely regular (they can be curved and the resolution typically changes regionally, so providing vectors of latitudes and longitudes simply wouldn't make any sense). \", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 7}}, {'id': 1753903967945585, 'score': 0.61854994, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_10_md', 'type': 'markdown', 'content': '[`interpn`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interpn.html) performs N-D interpolation of gridded data. Here is an example: ', 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 10}}, {'id': 1753903968044356, 'score': 0.6147343, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_4_md', 'type': 'markdown', 'content': \"\\n\\nThere are two types of interpolation problems: \\n1. interpolation from [`gridded data`](http://uk.mathworks.com/help/matlab/math/interpolating-gridded-data.html)\\n2. interolation from [`scattered data`](http://uk.mathworks.com/help/matlab/math/interpolating-scattered-data.html).\\n\\nInterpolation techniques designed for scattered data can of course also be used for gridded data.  However, functions specific for gridded data cannot typically be used for scattered data. This is because functions for gridded data make a priori assumptions about the regular spacing and arrangements of the control points to maximize computing efficiency.\\n\\nOrder in the data relates to computational efficiency because the computer doesn't have to look for the data in its memory and sort them in the sequence they are needed for the calculation, the data are already conveniently all next to one-another. In that case, the computer can very efficiently calculate differences between neighboring points, such as $x(i+1)-x(i)$, with these differences having meaning (e.g. a finite difference). This is not the case in scattered datasets where there is no obvious connection between the i$^{th}$ data point and the i$^{th}$+1 or i$^{th}$-1 sample. Extra computational steps are needed when dealing with scattered data.\\n\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 4}}, {'id': 1753902703274403, 'score': 0.61295384, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753903968040088, 'score': 0.612491, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_18_md', 'type': 'markdown', 'content': \"Now let's explore how the interpolation depends on the number of sample points. Decrease the number of points from 1000 to 100. Also see how the area that is interpolated over is limited by the convex hull of the data. \\n\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 18}}, {'id': 1753903968777554, 'score': 0.60145795, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_23_md', 'type': 'markdown', 'content': '#### Mathematical formulation (only the basic setup of the problem, not the solution)\\n\\nThe general problem is to compute an estimate $\\\\hat{F}(\\\\vec{x}_0,t)$ of the true field $F(\\\\vec{x}_0,t)$ at query position $\\\\vec{x}_0$ from a finite number of scattered observations $f(\\\\vec{x}_n,t)$ taken at locations $\\\\vec{x}_n$, with $n=1,2,...,N$.\\n\\nIf we consider a snap-shot in time, i.e. dropping the time index $t$, the generalized kriging problem can be stated as\\n\\n\\\\begin{equation}\\n\\\\hat{F}(\\\\vec{x}_0)=\\\\overline{F(\\\\vec{x})}+\\\\sum\\\\limits_{i=1}^Nb(x_i)(f(x_i)-\\\\overline{f(x_i)})\\n\\\\end{equation}\\n\\nwhere the overbars denote the expectation value (i.e. the mean) and the $b(x_i)$ are yet unspecified weighting coefficients for each data point $x_i$, subject to $\\\\sum\\\\limits_{i=1}^Nb(x_i)=1$.\\n\\nThe generalized kriging problem equation above means that to predict the value of the field $\\\\hat{F}(\\\\vec{x}_0)$ at a query location $\\\\vec{x}_0$, a good guess is to start with the mean (or some known structure) of the overall field $\\\\overline{F(\\\\vec{x})}$, to which we add corrections. For any given query point $\\\\vec{x}_0$, the necessary correction is calcuated as a weighted sum of contributions from the available samples $x_i$. The big question is what values should the weight corresponding to each sample have? Answering this question is not easy - it is basically the whole point of kriging. The answer will depend on any additional constraints that one applies on these weights and on any additional properties one wishes the field $F$ or $D$ to have (stationarity of various moments, isotropy, etc.). Different assumptions/requirements results in different types of kriging: **simple kriging**, **ordinary kriging**, **universal kriging**, etc. In all cases, though, the weights $b(x_i)$ are obtained by using least-squares optimization and minimizing the error defined by the difference between the true field and the prediction.\\n\\nA full mathematical description is beyond the scope here, but we will just point out that implementation of krigging in practice usually requires the user to specify a `variogram`.\\n', 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 23}}]",
      "[{'id': 1753902300119549, 'score': 0.6683048, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_5', 'type': 'pdf', 'content': 'added)•flows forward, then flows backwards•Ideally,shouldreturntoinitialvalues•Deviations are indicative of numerical issues\\nTesting the numerical core…when we don’t have an exact solution to compare to\\nThis highlights the problem of numerical diffusionEach schemewillhaveitsownweaknesses andstrengths (and conservation properties)\\nWhat does a numericalmodel need?summary•Need equations (+ parameterizations)–Output = function(input)•Need a starting point–Boundary conditions•Must define time and spa', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 5}}, {'id': 1753902300472417, 'score': 0.6433396, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902299806645, 'score': 0.61911553, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902703274403, 'score': 0.61737067, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753902299901317, 'score': 0.6144435, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_3', 'type': 'pdf', 'content': ' an extra equation(implicit scheme)\\nii+1\\n\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−Ci−12Δt=λCiCi+1=2λΔtCi+Ci−1Centered differenceRequires knowing more things from more points\\nii+1i-1\\nThe “dynamical/numerical core” of a model matters …a lot!•System of equation (partial differentials in 3D)•Discretizationand integrationscheme–These 3 are mathematically all valid but can produce very different answers when implemented…Ci+1=Ci1+λΔt()Forward difference(aka Forw', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 3}}, {'id': 1753903968044356, 'score': 0.602317, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_4_md', 'type': 'markdown', 'content': \"\\n\\nThere are two types of interpolation problems: \\n1. interpolation from [`gridded data`](http://uk.mathworks.com/help/matlab/math/interpolating-gridded-data.html)\\n2. interolation from [`scattered data`](http://uk.mathworks.com/help/matlab/math/interpolating-scattered-data.html).\\n\\nInterpolation techniques designed for scattered data can of course also be used for gridded data.  However, functions specific for gridded data cannot typically be used for scattered data. This is because functions for gridded data make a priori assumptions about the regular spacing and arrangements of the control points to maximize computing efficiency.\\n\\nOrder in the data relates to computational efficiency because the computer doesn't have to look for the data in its memory and sort them in the sequence they are needed for the calculation, the data are already conveniently all next to one-another. In that case, the computer can very efficiently calculate differences between neighboring points, such as $x(i+1)-x(i)$, with these differences having meaning (e.g. a finite difference). This is not the case in scattered datasets where there is no obvious connection between the i$^{th}$ data point and the i$^{th}$+1 or i$^{th}$-1 sample. Extra computational steps are needed when dealing with scattered data.\\n\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 4}}]",
      "To assist with your request, I need a bit more information. Could you please provide the equation you'd like rewritten and the specific discrete values or terms you'd like to use for the replacement?",
      "[{'id': 1753902703475561, 'score': 0.609803, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_11', 'type': 'pdf', 'content': 'uction, what does “right” even mean?•What do we do if one model can represent a variable better but another variable worst?•A model can reproduce the mean state well but not the variability. Is it a “good” model?•What if model solution shows spatial and temporal patterns well, but is consistently offset?•Embrace/accept that sometimes the best we can do is to provide a probabilistic answer to questions\\nDifferent variablesDifferent modelsError relative to the multi-model meanLess than meanMore tha', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 11}}]",
      "[{'id': 1753903968109184, 'score': 0.64586437, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_16_md', 'type': 'markdown', 'content': 'Python has a function to do scattered interpolation (interpolate unstructured data) called [`scipy.interpolate.griddata`](https://docs.scipy.org/doc/scipy/reference/reference/generated/scipy.interpolate.griddata.html#scipy.interpolate.griddata). This function essentially performs a Delauney triangulation of the data, and then interpolates within the triangles. There are 3 options to interpolate: nearest, linear, cubic. \\n', 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 16}}, {'id': 1753903968774894, 'score': 0.64244443, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_20_code', 'type': 'code', 'content': \"import numpy as np\\nfrom scipy.interpolate import griddata\\n\\n# create some random sample coordinates\\nz = np.random.rand(100, 100)\\nz.shape = (100, 100)\\nx, y = np.arange(-5, 5, 0.1), np.arange(-5, 5, 0.1)\\n\\nxx, yy = np.meshgrid(x, y, indexing='ij')\\n\\nnewx, newy = np.arange(-2, 2, 0.1), np.arange(-2, 2, 0.1)\\n\\ngriddata((xx.ravel(), yy.ravel()), z.ravel(), (newx[None, :], newy[:, None]))\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 20}}, {'id': 1753903967945585, 'score': 0.63881147, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_10_md', 'type': 'markdown', 'content': '[`interpn`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interpn.html) performs N-D interpolation of gridded data. Here is an example: ', 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 10}}, {'id': 1753903968846380, 'score': 0.63688767, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_5_md', 'type': 'markdown', 'content': \"<a id='gridded'></a>\\n## Gridded data\\n\\nBy definition, gridded data exist on a `grid`! **A grid is defined by an ordered sequence of coordinates**. \\n\\nIf there are, say, 7 values on the x-axis and 7 values on the y-axis, a full grid will contain a set of $7\\\\times 7=49$ coordinates. Given vectors of **x** and **y** values, Python `numpy` has a function called [`numpy.meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) that automatically creates the arrays **X** and **Y** that contain the coordinates of all grid points given the vectors **x** and **y**. \\n\\nFor example: \", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 5}}, {'id': 1753903968044356, 'score': 0.6364745, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_4_md', 'type': 'markdown', 'content': \"\\n\\nThere are two types of interpolation problems: \\n1. interpolation from [`gridded data`](http://uk.mathworks.com/help/matlab/math/interpolating-gridded-data.html)\\n2. interolation from [`scattered data`](http://uk.mathworks.com/help/matlab/math/interpolating-scattered-data.html).\\n\\nInterpolation techniques designed for scattered data can of course also be used for gridded data.  However, functions specific for gridded data cannot typically be used for scattered data. This is because functions for gridded data make a priori assumptions about the regular spacing and arrangements of the control points to maximize computing efficiency.\\n\\nOrder in the data relates to computational efficiency because the computer doesn't have to look for the data in its memory and sort them in the sequence they are needed for the calculation, the data are already conveniently all next to one-another. In that case, the computer can very efficiently calculate differences between neighboring points, such as $x(i+1)-x(i)$, with these differences having meaning (e.g. a finite difference). This is not the case in scattered datasets where there is no obvious connection between the i$^{th}$ data point and the i$^{th}$+1 or i$^{th}$-1 sample. Extra computational steps are needed when dealing with scattered data.\\n\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 4}}, {'id': 1753903968314666, 'score': 0.6301741, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_7_md', 'type': 'markdown', 'content': \"One can then use the arrays **X** and **Y** to directly evaluate functions over the entire grid, for example.\\n\\n**Note**: When working with model output, you may see that the latitudes an longitudes may be supplied either as vectors (**x,y**) or as two arrays (**X,Y**). This generally depends on whether the data are supplied on a regular grid (fixed latitudes and longtiude steps), or not. The native model grids are rarely regular (they can be curved and the resolution typically changes regionally, so providing vectors of latitudes and longitudes simply wouldn't make any sense). \", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 7}}, {'id': 1753902703274403, 'score': 0.62937284, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753903968040088, 'score': 0.6206387, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_18_md', 'type': 'markdown', 'content': \"Now let's explore how the interpolation depends on the number of sample points. Decrease the number of points from 1000 to 100. Also see how the area that is interpolated over is limited by the convex hull of the data. \\n\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 18}}, {'id': 1753903968333993, 'score': 0.60367733, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_6_code', 'type': 'code', 'content': \"import numpy as np\\nnx, ny = (7,7)\\nx = np.linspace(-3, 3, nx) # define a vector of x-axis coordinates\\ny = np.linspace(-3, 3, ny) # define a vector of y-axis coordinates\\nprint('x =', x)\\nprint('y =', y)\\n\\nX, Y = np.meshgrid(x, y) # define a matrix/array with X and Y of coordinates\\n\\nprint('grid X =', X)\\nprint('grid Y =', Y)\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 6}}]",
      "[{'id': 1753903968109184, 'score': 0.7381997, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_16_md', 'type': 'markdown', 'content': 'Python has a function to do scattered interpolation (interpolate unstructured data) called [`scipy.interpolate.griddata`](https://docs.scipy.org/doc/scipy/reference/reference/generated/scipy.interpolate.griddata.html#scipy.interpolate.griddata). This function essentially performs a Delauney triangulation of the data, and then interpolates within the triangles. There are 3 options to interpolate: nearest, linear, cubic. \\n', 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 16}}, {'id': 1753903967945585, 'score': 0.73709214, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_10_md', 'type': 'markdown', 'content': '[`interpn`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interpn.html) performs N-D interpolation of gridded data. Here is an example: ', 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 10}}, {'id': 1753903968040088, 'score': 0.7320763, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_18_md', 'type': 'markdown', 'content': \"Now let's explore how the interpolation depends on the number of sample points. Decrease the number of points from 1000 to 100. Also see how the area that is interpolated over is limited by the convex hull of the data. \\n\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 18}}, {'id': 1753903968044356, 'score': 0.7253332, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_4_md', 'type': 'markdown', 'content': \"\\n\\nThere are two types of interpolation problems: \\n1. interpolation from [`gridded data`](http://uk.mathworks.com/help/matlab/math/interpolating-gridded-data.html)\\n2. interolation from [`scattered data`](http://uk.mathworks.com/help/matlab/math/interpolating-scattered-data.html).\\n\\nInterpolation techniques designed for scattered data can of course also be used for gridded data.  However, functions specific for gridded data cannot typically be used for scattered data. This is because functions for gridded data make a priori assumptions about the regular spacing and arrangements of the control points to maximize computing efficiency.\\n\\nOrder in the data relates to computational efficiency because the computer doesn't have to look for the data in its memory and sort them in the sequence they are needed for the calculation, the data are already conveniently all next to one-another. In that case, the computer can very efficiently calculate differences between neighboring points, such as $x(i+1)-x(i)$, with these differences having meaning (e.g. a finite difference). This is not the case in scattered datasets where there is no obvious connection between the i$^{th}$ data point and the i$^{th}$+1 or i$^{th}$-1 sample. Extra computational steps are needed when dealing with scattered data.\\n\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 4}}, {'id': 1753903968774894, 'score': 0.7113448, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_20_code', 'type': 'code', 'content': \"import numpy as np\\nfrom scipy.interpolate import griddata\\n\\n# create some random sample coordinates\\nz = np.random.rand(100, 100)\\nz.shape = (100, 100)\\nx, y = np.arange(-5, 5, 0.1), np.arange(-5, 5, 0.1)\\n\\nxx, yy = np.meshgrid(x, y, indexing='ij')\\n\\nnewx, newy = np.arange(-2, 2, 0.1), np.arange(-2, 2, 0.1)\\n\\ngriddata((xx.ravel(), yy.ravel()), z.ravel(), (newx[None, :], newy[:, None]))\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 20}}, {'id': 1753903968314666, 'score': 0.691077, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_7_md', 'type': 'markdown', 'content': \"One can then use the arrays **X** and **Y** to directly evaluate functions over the entire grid, for example.\\n\\n**Note**: When working with model output, you may see that the latitudes an longitudes may be supplied either as vectors (**x,y**) or as two arrays (**X,Y**). This generally depends on whether the data are supplied on a regular grid (fixed latitudes and longtiude steps), or not. The native model grids are rarely regular (they can be curved and the resolution typically changes regionally, so providing vectors of latitudes and longitudes simply wouldn't make any sense). \", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 7}}, {'id': 1753903968752811, 'score': 0.6720524, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_21_md', 'type': 'markdown', 'content': \"<a id='fitting'></a>\\n# Surface fitting\\n\\nThe interpolation techniques described above work very well when the space is relatively well-sampled, when one does not want to extrapolate beyond the convex hull and in the absence of variability or uncertainties associated the control points. If these conditions are not met, a better approach to interpreting spatial data may be **to fit a surface across the collection of samples** rather than to force a surface to pass exactly through each control point. This process is sometimes called optimal interpolation because it involves mininizing misfit errors.\\n\\nAn optimally interpolated surface will tend to be smoother than the original data field. \\n\\nThe contoured values at locations where samples exist won't equal to the data point at that location due to the noise associated with each measurement. The contoured estimate will tend to either over or underestimate the true value, within a tolerance controlled by the noise associated with the measurements. \\n\\nThe shape of the fitted surface will depend strongly on the data available: their locations, their uncertainties, as well as subjective choices made during the analysis (i.e. definition of the so-called 'covariance matrix').\\n\\nWe will here look at a technique called **kriging**, pioneered by a South African mining engineer called Danie G. Krige (1919-2013) and further formalized by geologist and mathematician Georges Matheron (1930-2000), who, together with Jean Serra, is often considered to be the founder of geostatistics.\\n\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 21}}, {'id': 1753903968636934, 'score': 0.6716894, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_11_code', 'type': 'code', 'content': \"from scipy.interpolate import interpn\\n\\n# let's create a function to create synthetic values of z\\ndef value_func_3d(x, y, z):\\n     return 2 * x + 3 * y - z\\n\\n# define a 3D grid\\nx = np.linspace(0, 4, 5)\\ny = np.linspace(0, 5, 6)\\nz = np.linspace(0, 6, 7)\\npoints = (x, y, z)\\n\\n# evalulate the function to get 'values' on that 3D grid\\nvalues = value_func_3d(*np.meshgrid(*points, indexing='ij'))\\n\\n# Now use interpolation\\npoint = np.array([2.21, 3.12, 1.15]) # create a 3D 'query' point\\nprint(interpn(points, values, point)) # user interpn and see the value of z here\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 11}}, {'id': 1753903968384950, 'score': 0.6695488, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_17_code', 'type': 'code', 'content': \"def func(x, y):\\n    #return  (x+y) * np.exp(-6.0*(x*x+y*y))\\n    return x*(1-x)*np.cos(4*np.pi*x) * np.sin(4*np.pi*y**2)**2\\n    \\ngrid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]\\n\\nNPOINTS=1000\\nrng = np.random.default_rng()\\npoints = rng.random((NPOINTS, 2))\\nvalues = func(points[:,0], points[:,1])\\n\\nfrom scipy.interpolate import griddata\\ngrid_z0 = griddata(points, values, (grid_x, grid_y), method='nearest')\\ngrid_z1 = griddata(points, values, (grid_x, grid_y), method='linear')\\ngrid_z2 = griddata(points, values, (grid_x, grid_y), method='cubic')\\n\\nimport matplotlib.pyplot as plt\\nplt.subplot(221)\\nplt.imshow(func(grid_x, grid_y).T, extent=(0,1,0,1), origin='lower')\\nplt.plot(points[:,0], points[:,1], 'k.', ms=1)\\nplt.title('Original')\\nplt.subplot(222)\\nplt.imshow(grid_z0.T, extent=(0,1,0,1), origin='lower')\\nplt.title('Nearest')\\nplt.subplot(223)\\nplt.imshow(grid_z1.T, extent=(0,1,0,1), origin='lower')\\nplt.title('Linear')\\nplt.subplot(224)\\nplt.imshow(grid_z2.T, extent=(0,1,0,1), origin='lower') \\nplt.title('Cubic')\\nplt.gcf().set_size_inches(6, 6)\\nplt.show()\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 17}}, {'id': 1753903968928160, 'score': 0.66608965, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_2_md', 'type': 'markdown', 'content': \"<a id='surface'></a>\\n## Surface interpolation\\n\\nJust as it was the case for the 1D case (remember `interp1d`), 2D interpolation can be used to fill in the space between existing `control` data points and predict values for the field at given `query` points. Like the 1D case, the interpolated surface will pass exactly through every control points.\\n\\nLet's look at an example of how `interp1d` is used:\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 2}}]"
    ],
    "response": "The code snippet provided in cell 20 uses the `griddata` function from the `scipy.interpolate` module to perform surface interpolation. The function takes four arguments:\n\n1. `points`: a tuple of arrays representing the x, y coordinates of the control points.\n2. `values`: an array representing the corresponding z values.\n3. `(x, y)`: a tuple of arrays representing the x and y coordinates of the grid points where the interpolated surface should be evaluated.\n4. `method`: a string specifying the interpolation method to use.\n\nIn this case, the code uses the `griddata` function with the following arguments:\n\n* `points`: a tuple of two arrays representing the x and y coordinates of 100 random control points.\n* `values`: an array representing the corresponding z values for these control points.\n* `(x, y)`: a tuple of two arrays representing the x and y coordinates of a grid with 100x200 points.\n* `method`: `'nearest'`, which means that the interpolated surface will pass exactly through every control point.\n\nThe code then uses the `griddata` function to perform the interpolation and stores the result in the `grid_z0` variable. The same process is repeated for linear and cubic interpolation methods, storing the results in `grid_z1` and `grid_z2`, respectively.\n\nHere's a simplified version of the code with comments:\n```python\nimport numpy as np\nfrom scipy.interpolate import griddata\n\n# Create some random control points\nNPOINTS = 100\nrng = np.random.default_rng()\npoints = rng.random((NPOINTS, 2))\nvalues = func(points[:,0], points[:,1])  # Define a function to generate z values\n\n# Perform interpolation for different methods\ngrid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]\ngrid_z0 = griddata(points, values, (grid_x, grid_y), method='nearest')\ngrid_z1 = griddata(points, values, (grid_x, grid_y), method='linear')\ngrid_z2 = griddata(points, values, (grid_x, grid_y), method='cubic')\n\n# Plot the results\nimport matplotlib.pyplot as plt\n\nplt.subplot(221)\nplt.imshow(func(grid_x, grid_y).T, extent=(0,1,0,1), origin='lower')\nplt.plot(points[:,0], points[:,1], 'k.', ms=1)\nplt.title('Original')\n\nplt.subplot(222)\nplt.imshow(grid_z0.T, extent=(0,1,0,1), origin='lower')\nplt.title('Nearest')\n\nplt.subplot(223)\nplt.imshow(grid_z1.T, extent=(0,1,0,1), origin='lower')\nplt.title('Linear')\n\nplt.subplot(224)\nplt.imshow(grid_z2.T, extent=(0,1,0,1), origin='lower')\nplt.title('Cubic')\n\nplt.gcf().set_size_inches(6, 6)\nplt.show()\n```\nNote that the `func` function is not defined in this code snippet, so you'll need to define it yourself. The `func` function should take two arguments (x and y) and return a value representing the z coordinate for each control point.",
    "reference": "By approximating derivatives with finite differences (e.g., forward, backward, or centered), allowing numerical integration across time and space.",
    "iteration_scores": [
      {
        "iteration": 1,
        "decomposition": 8.0,
        "retrieval": 4.375,
        "generation": 1.0,
        "total": 4.458333333333333
      },
      {
        "iteration": 2,
        "decomposition": 7.0,
        "retrieval": 4.4,
        "generation": 7.0,
        "total": 6.133333333333333
      },
      {
        "iteration": 3,
        "decomposition": 7.0,
        "retrieval": 5.75,
        "generation": 5.0,
        "total": 5.916666666666667
      }
    ]
  },
  {
    "user_input": "How do discretization schemes (e.g., forward Euler, backward Euler, centered difference) influence the accuracy and stability of climate models?",
    "retrieved_contexts": [
      "[{'id': 1753902299806645, 'score': 0.7883618, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902300472417, 'score': 0.7748477, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902300429530, 'score': 0.7226726, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902300206271, 'score': 0.71502835, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}, {'id': 1753902703274403, 'score': 0.69058424, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753903424623019, 'score': 0.67015445, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_37_md', 'type': 'markdown', 'content': \"### Climate Data Operators (CDO)\\nThe Climate Data Operators ([CDO](https://code.mpimet.mpg.de/projects/cdo)) software is a collection of >600 operators for standard processing of climate and forecast model data. They are slighly less memory/speed efficient than NCO, but they do more (>600 vs 12!). CDO support the main data formats used in the field, such as GRIB and netCDF. \\n\\nThey too can be daisy-chained for specific applications. There are [many recipes available](https://code.mpimet.mpg.de/projects/cdo/embedded/cdo_eca.pdf) to calculate various climate indices and diagnostics, what makes them very attractive to evaluate gridded climate data or climate model output.\\n\\nThe [CDO user guide](https://code.mpimet.mpg.de/projects/cdo/embedded/index.html) provides details instructions and examples. \\n\\n[They are also very useful, but we don't have time to discuss them in detail here. You are encouraged to practice with CDO on your own time]\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 37}}, {'id': 1753902702794239, 'score': 0.6664176, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902299901317, 'score': 0.66571075, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_3', 'type': 'pdf', 'content': ' an extra equation(implicit scheme)\\nii+1\\n\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−Ci−12Δt=λCiCi+1=2λΔtCi+Ci−1Centered differenceRequires knowing more things from more points\\nii+1i-1\\nThe “dynamical/numerical core” of a model matters …a lot!•System of equation (partial differentials in 3D)•Discretizationand integrationscheme–These 3 are mathematically all valid but can produce very different answers when implemented…Ci+1=Ci1+λΔt()Forward difference(aka Forw', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 3}}, {'id': 1753903424509295, 'score': 0.66331625, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753901956917450, 'score': 0.6618515, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}]",
      "[{'id': 1753902299806645, 'score': 0.7450026, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902300472417, 'score': 0.705966, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902703503123, 'score': 0.70283234, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753901956917450, 'score': 0.6923529, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902300429530, 'score': 0.6862992, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902702662417, 'score': 0.6843579, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_10', 'type': 'pdf', 'content': 'ls that are ‘fitted’ to data•Some model parameters are tuned to fit–Question is what to fit/how? (Data assimilation, 4DVAR)–Provide best gridded high-resolution spatio-temporal product available … but:•they are still model results–Fitting a bad/wrong model still is a bad results•they only exist for the period when data exist–so cannot be used for forecasting–But extremely useful to understand past/current climate patterns/variability\\nAre models ever “right”?•Since models are incomplete by constr', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 10}}, {'id': 1753902702794239, 'score': 0.6806258, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902702944729, 'score': 0.6648649, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753903424509295, 'score': 0.6639845, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753902703274403, 'score': 0.6596545, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}]",
      "[{'id': 1753902299806645, 'score': 0.7302813, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902300429530, 'score': 0.71765566, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902300472417, 'score': 0.712119, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753901956917450, 'score': 0.71019447, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902703503123, 'score': 0.69210666, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753902702794239, 'score': 0.68700594, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902702662417, 'score': 0.6749939, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_10', 'type': 'pdf', 'content': 'ls that are ‘fitted’ to data•Some model parameters are tuned to fit–Question is what to fit/how? (Data assimilation, 4DVAR)–Provide best gridded high-resolution spatio-temporal product available … but:•they are still model results–Fitting a bad/wrong model still is a bad results•they only exist for the period when data exist–so cannot be used for forecasting–But extremely useful to understand past/current climate patterns/variability\\nAre models ever “right”?•Since models are incomplete by constr', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 10}}, {'id': 1753902703274403, 'score': 0.6666036, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753902702944729, 'score': 0.6651239, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753902300206271, 'score': 0.65169895, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}]",
      "[{'id': 1753902300472417, 'score': 0.73430467, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902299806645, 'score': 0.7294472, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902300429530, 'score': 0.70177597, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753901956917450, 'score': 0.6988471, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902703274403, 'score': 0.6935868, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753902702794239, 'score': 0.67257, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753903424623019, 'score': 0.6636977, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_37_md', 'type': 'markdown', 'content': \"### Climate Data Operators (CDO)\\nThe Climate Data Operators ([CDO](https://code.mpimet.mpg.de/projects/cdo)) software is a collection of >600 operators for standard processing of climate and forecast model data. They are slighly less memory/speed efficient than NCO, but they do more (>600 vs 12!). CDO support the main data formats used in the field, such as GRIB and netCDF. \\n\\nThey too can be daisy-chained for specific applications. There are [many recipes available](https://code.mpimet.mpg.de/projects/cdo/embedded/cdo_eca.pdf) to calculate various climate indices and diagnostics, what makes them very attractive to evaluate gridded climate data or climate model output.\\n\\nThe [CDO user guide](https://code.mpimet.mpg.de/projects/cdo/embedded/index.html) provides details instructions and examples. \\n\\n[They are also very useful, but we don't have time to discuss them in detail here. You are encouraged to practice with CDO on your own time]\\n\\n[back to contents](#Contents)\\n\\n---\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 37}}, {'id': 1753902300206271, 'score': 0.6549017, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}, {'id': 1753902702697836, 'score': 0.6483792, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_5', 'type': 'pdf', 'content': 'ent become stronger (strong exchange, although on shorter spatial scales, e.g.air-sea heat fluxes)•Better agreement with the way data are collected (i.e.what observations mean)–Averaging over space/time and variabilityhttps://www.gfdl.noaa.gov/climate-modeling/\\nGulf Stream\\nLabrador Sea~100km cells~10km cells\\nOcean resolution: 2 casesresolving eddies (the ocean’ storms)\\nFigure 6.1. Surface-Current Speed in Two Simulations of the Southern Ocean in Low-and High-Resolution Ocean Models.[From Fig. 6 ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 5}}, {'id': 1753903424509295, 'score': 0.644001, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}]",
      "[{'id': 1753902299806645, 'score': 0.7592273, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902300472417, 'score': 0.6928302, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902300119549, 'score': 0.6455085, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_5', 'type': 'pdf', 'content': 'added)•flows forward, then flows backwards•Ideally,shouldreturntoinitialvalues•Deviations are indicative of numerical issues\\nTesting the numerical core…when we don’t have an exact solution to compare to\\nThis highlights the problem of numerical diffusionEach schemewillhaveitsownweaknesses andstrengths (and conservation properties)\\nWhat does a numericalmodel need?summary•Need equations (+ parameterizations)–Output = function(input)•Need a starting point–Boundary conditions•Must define time and spa', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 5}}, {'id': 1753903424509295, 'score': 0.6432738, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753902703503123, 'score': 0.64288116, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753902300429530, 'score': 0.642792, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902299594208, 'score': 0.64252937, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_4', 'type': 'pdf', 'content': 'ard Euler)Ci+1=Ci11−λΔt=1Backward difference(aka backward Euler)Ci+1=2λΔtCi+Ci−1Centered differenceetc…\\nCf=CoeλtExact solutionDt=0.05Dt=0.5l=-0.9l=0.9l=0.9l=-0.9Dt=0.05ExactForwardBackwardCentered\\nExactForwardBackwardCenteredDt=0.5\\nTesting the numerical core…when we don’t have an exact solution to compare to\\nIdealized simulations~ numerical equivalent of calibration in a lab\\nu(x,y)=sin2(πx)sin(2πy)cos(πt/5)v(x,y)=−sin2(πy)sin(2πx)cos(πt/5)Example: •Purely advective system (no explicit diffusion ', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 4}}, {'id': 1753902703274403, 'score': 0.6385711, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753902702794239, 'score': 0.63205224, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902300206271, 'score': 0.6234609, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}]",
      "[{'id': 1753902703274403, 'score': 0.7110523, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753902300119549, 'score': 0.6939125, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_5', 'type': 'pdf', 'content': 'added)•flows forward, then flows backwards•Ideally,shouldreturntoinitialvalues•Deviations are indicative of numerical issues\\nTesting the numerical core…when we don’t have an exact solution to compare to\\nThis highlights the problem of numerical diffusionEach schemewillhaveitsownweaknesses andstrengths (and conservation properties)\\nWhat does a numericalmodel need?summary•Need equations (+ parameterizations)–Output = function(input)•Need a starting point–Boundary conditions•Must define time and spa', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 5}}, {'id': 1753902300472417, 'score': 0.6766299, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902299806645, 'score': 0.6650282, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902299901317, 'score': 0.6492775, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_3', 'type': 'pdf', 'content': ' an extra equation(implicit scheme)\\nii+1\\n\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−Ci−12Δt=λCiCi+1=2λΔtCi+Ci−1Centered differenceRequires knowing more things from more points\\nii+1i-1\\nThe “dynamical/numerical core” of a model matters …a lot!•System of equation (partial differentials in 3D)•Discretizationand integrationscheme–These 3 are mathematically all valid but can produce very different answers when implemented…Ci+1=Ci1+λΔt()Forward difference(aka Forw', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 3}}, {'id': 1753902703299772, 'score': 0.6459242, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_3', 'type': 'pdf', 'content': 'l sense of incomplete/uncertain results and design meaningful experiments(experimental design is key)\\nModel resolutionIncreasing spatial resolution…also means increasing temporal resolution to maintain numerical stability(i.e.decrease time step)Huge cost of resolution:2x increase in spatial resolution in all dimensions means 23=8x more computations23=8x more memory23=8x more timeWith decreased time-step>16x slower and more demanding\\nBenefits of improving resolution?•Better numerical accuracy in ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 3}}, {'id': 1753903968314666, 'score': 0.6388791, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_7_md', 'type': 'markdown', 'content': \"One can then use the arrays **X** and **Y** to directly evaluate functions over the entire grid, for example.\\n\\n**Note**: When working with model output, you may see that the latitudes an longitudes may be supplied either as vectors (**x,y**) or as two arrays (**X,Y**). This generally depends on whether the data are supplied on a regular grid (fixed latitudes and longtiude steps), or not. The native model grids are rarely regular (they can be curved and the resolution typically changes regionally, so providing vectors of latitudes and longitudes simply wouldn't make any sense). \", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 7}}, {'id': 1753902300429530, 'score': 0.6235648, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902703226725, 'score': 0.6158155, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_13', 'type': 'pdf', 'content': ' model do it all?Processes operate on various time/space scales\\nHigher resolution•(more data)•(local extremes)•(shorter simulation)•(no/few ensembles)Lower resolution•(fewer data)•(longer simulation)•(many ensembles)\\n\\nTake home messages•Models will always be imperfect (accept this!)–the challenge is to make them useful by keeping them as simple as possible in spite oftheir limitations •very difficult in practice, requires deep scientific knowledge•Understanding of the question and of the tools a', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 13}}, {'id': 1753902299521429, 'score': 0.6124661, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_8', 'type': 'pdf', 'content': 'id box covers ocean+land+sea-ice–Properties must be conserved–Characteristic time-scales in each module differ affecting the time-step of integration needed\\nModel complexity : need vsgreed and the need for speed\\n\\nModel complexity vsresolutionLate 1960s: UNIVAC 1108 (0.5MB of memory!)\\nSyukuro“Suki” Manabe(Nobel prize physics 2021)\\nhttps://en.wikipedia.org/wiki/Syukuro_ManabeA master at simplifying problem to their essence\\nCray XC304920 nodes x 12 cores = 118080 CPUsEach node as 64GB memoryThe UK’', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 8}}]",
      "[{'id': 1753902300119549, 'score': 0.657003, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_5', 'type': 'pdf', 'content': 'added)•flows forward, then flows backwards•Ideally,shouldreturntoinitialvalues•Deviations are indicative of numerical issues\\nTesting the numerical core…when we don’t have an exact solution to compare to\\nThis highlights the problem of numerical diffusionEach schemewillhaveitsownweaknesses andstrengths (and conservation properties)\\nWhat does a numericalmodel need?summary•Need equations (+ parameterizations)–Output = function(input)•Need a starting point–Boundary conditions•Must define time and spa', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 5}}, {'id': 1753902300472417, 'score': 0.6311426, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902299806645, 'score': 0.6122729, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902299901317, 'score': 0.606053, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_3', 'type': 'pdf', 'content': ' an extra equation(implicit scheme)\\nii+1\\n\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−Ci−12Δt=λCiCi+1=2λΔtCi+Ci−1Centered differenceRequires knowing more things from more points\\nii+1i-1\\nThe “dynamical/numerical core” of a model matters …a lot!•System of equation (partial differentials in 3D)•Discretizationand integrationscheme–These 3 are mathematically all valid but can produce very different answers when implemented…Ci+1=Ci1+λΔt()Forward difference(aka Forw', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 3}}]",
      "[{'id': 1753902300472417, 'score': 0.6261188, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753903968040088, 'score': 0.6126102, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_18_md', 'type': 'markdown', 'content': \"Now let's explore how the interpolation depends on the number of sample points. Decrease the number of points from 1000 to 100. Also see how the area that is interpolated over is limited by the convex hull of the data. \\n\", 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 18}}, {'id': 1753902299806645, 'score': 0.6096346, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902299901317, 'score': 0.6053659, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_3', 'type': 'pdf', 'content': ' an extra equation(implicit scheme)\\nii+1\\n\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−Ci−12Δt=λCiCi+1=2λΔtCi+Ci−1Centered differenceRequires knowing more things from more points\\nii+1i-1\\nThe “dynamical/numerical core” of a model matters …a lot!•System of equation (partial differentials in 3D)•Discretizationand integrationscheme–These 3 are mathematically all valid but can produce very different answers when implemented…Ci+1=Ci1+λΔt()Forward difference(aka Forw', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 3}}, {'id': 1753903967945585, 'score': 0.60267437, 'payload': {'original_id': 'uploads\\\\intro_to_spatialanalysis.ipynb_cell_10_md', 'type': 'markdown', 'content': '[`interpn`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interpn.html) performs N-D interpolation of gridded data. Here is an example: ', 'source_document': 'uploads\\\\intro_to_spatialanalysis.ipynb', 'cell_number': 10}}]"
    ],
    "response": "The provided text appears to be a collection of contexts related to climate modeling and numerical methods. However, without more specific information or context about what you're trying to accomplish or what kind of answer you're looking for, it's difficult to provide a precise solution.\n\nThat being said, I can try to help you identify some common themes or takeaways from the provided contexts:\n\n1. **Climate modeling**: Many of the contexts discuss climate modeling and the importance of numerical methods in simulating complex systems.\n2. **Numerical methods**: Several contexts highlight various numerical methods used in climate modeling, such as discretization, interpolation, and integration.\n3. **Discretization**: Discretization is a common theme, with contexts discussing different approaches to discretizing spatial and temporal domains.\n4. **Interpolation**: Interpolation is another important concept, with contexts exploring different interpolation techniques for gridded data.\n\nIf you could provide more context or clarify what you're trying to accomplish, I'd be happy to try and assist you further!",
    "reference": "Each scheme handles numerical integration differently, affecting model stability and accuracy. Forward Euler is simple but less stable, backward Euler is more stable but computationally demanding, and centered difference is more accurate but requires more data points. These differences lead to varied results even for the same equations.",
    "iteration_scores": [
      {
        "iteration": 1,
        "decomposition": 8.0,
        "retrieval": 6.142857142857143,
        "generation": 5.0,
        "total": 6.3809523809523805
      },
      {
        "iteration": 2,
        "decomposition": 7.0,
        "retrieval": 6.111111111111111,
        "generation": 1.0,
        "total": 4.703703703703703
      },
      {
        "iteration": 3,
        "decomposition": 7.0,
        "retrieval": 6.0,
        "generation": 8.0,
        "total": 7.0
      }
    ]
  },
  {
    "user_input": "To what extent do you agree with the proposition that 'all models are wrong, but some are useful' in the context of climate modeling?",
    "retrieved_contexts": [
      "[{'id': 1753902703503123, 'score': 0.745178, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753902300429530, 'score': 0.72225523, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753901956917450, 'score': 0.7221209, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902702794239, 'score': 0.71029603, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902702922525, 'score': 0.70524716, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_0', 'type': 'pdf', 'content': 'Are climate models any good or useful at all?\\nhttps://www.gfdl.noaa.gov/visualizations-hurricanes/\\nData or model?\\nCommon misconceptions about modeling1.The goal of modeling is to reproduce data2.If a model doesn’t fit the data, the model is useless (…and modeler also)3.Since modelers don’t measure anything, they don’t know anything about data or care about them4.Measurement(s) of “X” can be used to better constrain climate models5.Process “W” is not explicitly implemented in the model,hence the ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 0}}, {'id': 1753902702662417, 'score': 0.7028013, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_10', 'type': 'pdf', 'content': 'ls that are ‘fitted’ to data•Some model parameters are tuned to fit–Question is what to fit/how? (Data assimilation, 4DVAR)–Provide best gridded high-resolution spatio-temporal product available … but:•they are still model results–Fitting a bad/wrong model still is a bad results•they only exist for the period when data exist–so cannot be used for forecasting–But extremely useful to understand past/current climate patterns/variability\\nAre models ever “right”?•Since models are incomplete by constr', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 10}}, {'id': 1753902702944729, 'score': 0.697713, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753902299806645, 'score': 0.6893523, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902300472417, 'score': 0.6798401, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753903424509295, 'score': 0.67309237, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}]",
      "[{'id': 1753902703503123, 'score': 0.7501188, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753901956917450, 'score': 0.72120744, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902702662417, 'score': 0.7166443, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_10', 'type': 'pdf', 'content': 'ls that are ‘fitted’ to data•Some model parameters are tuned to fit–Question is what to fit/how? (Data assimilation, 4DVAR)–Provide best gridded high-resolution spatio-temporal product available … but:•they are still model results–Fitting a bad/wrong model still is a bad results•they only exist for the period when data exist–so cannot be used for forecasting–But extremely useful to understand past/current climate patterns/variability\\nAre models ever “right”?•Since models are incomplete by constr', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 10}}, {'id': 1753902702922525, 'score': 0.69416696, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_0', 'type': 'pdf', 'content': 'Are climate models any good or useful at all?\\nhttps://www.gfdl.noaa.gov/visualizations-hurricanes/\\nData or model?\\nCommon misconceptions about modeling1.The goal of modeling is to reproduce data2.If a model doesn’t fit the data, the model is useless (…and modeler also)3.Since modelers don’t measure anything, they don’t know anything about data or care about them4.Measurement(s) of “X” can be used to better constrain climate models5.Process “W” is not explicitly implemented in the model,hence the ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 0}}, {'id': 1753902300429530, 'score': 0.6920663, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753901956989969, 'score': 0.6736095, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_2', 'type': 'pdf', 'content': ' as well as errors stemming from the analytical procedure itself (e.g.calibration of analysis using synthetic data/models).Learning objectives of the Environmental Data module•Growing/important field –with likely career opportunities•Great playground to deliver learning objectives\\nUsing climate models: quantification/forecasting(impacts, adaptation, mitigation)\\nhttps://www.noaa.gov/education/resource-collections/climate/climate-change-impacts\\nUsing climate models: designscenarios(explore policy,', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 2}}, {'id': 1753902299806645, 'score': 0.6697519, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902702794239, 'score': 0.6688564, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902702944729, 'score': 0.6608045, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753902703475561, 'score': 0.65377456, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_11', 'type': 'pdf', 'content': 'uction, what does “right” even mean?•What do we do if one model can represent a variable better but another variable worst?•A model can reproduce the mean state well but not the variability. Is it a “good” model?•What if model solution shows spatial and temporal patterns well, but is consistently offset?•Embrace/accept that sometimes the best we can do is to provide a probabilistic answer to questions\\nDifferent variablesDifferent modelsError relative to the multi-model meanLess than meanMore tha', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 11}}]",
      "[{'id': 1753902703272079, 'score': 0.67148906, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_14', 'type': 'pdf', 'content': 'vailable–The skill of the analyst is to know how far to push the interpretation and to select the correct model/simulations for the right question (exploit experimental design)•Main sources of uncertainties to consider•Numericsand choice of equations/implementation•Resolution•Parameterizations•Boundary conditions and forcing•Internal dynamics•Influence of uncertainties on final conclusions of analysis must be considered\\n\\n', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 14}}, {'id': 1753902703475561, 'score': 0.65030116, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_11', 'type': 'pdf', 'content': 'uction, what does “right” even mean?•What do we do if one model can represent a variable better but another variable worst?•A model can reproduce the mean state well but not the variability. Is it a “good” model?•What if model solution shows spatial and temporal patterns well, but is consistently offset?•Embrace/accept that sometimes the best we can do is to provide a probabilistic answer to questions\\nDifferent variablesDifferent modelsError relative to the multi-model meanLess than meanMore tha', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 11}}, {'id': 1753901956747387, 'score': 0.6391398, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_1', 'type': 'pdf', 'content': 'Identify and design suitable data analysis strategies that consider data types, data distribution constraints, strength, benefits and limitations of statistical and modelling tools and environmental dynamics.4. Understand the limitation of available data and data analysis products. Understand sources of errors and demonstrate ability to comprehensively characterize uncertainties and interpret results in the context of these uncertainties, including measurement errors, environmental uncertainties', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 1}}, {'id': 1753901956917450, 'score': 0.63750404, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753907767620194, 'score': 0.6198547, 'payload': {'original_id': 'uploads\\\\intro_to_timeseriesanalysis-IC-X9CYXD36RX.ipynb_cell_23_md', 'type': 'markdown', 'content': \"<a id='timedomain'></a>\\n# Modeling time series data in the time domain\\n\\nOne of the tenet of time series analyis, or statistical forecasting of time series, is that: \\n\\n$\\nData = Signal + Noise\\n$\\n\\nMany approaches to time series analysis therefore try to decompose the data into an interpretable, signal, part and into uninterpretable residuals, which ideally are white noise. The signal can be additive, with trends, periods, and errors, e.g. $X_t=T_t+S_t+E_t$, or multiplicative, e.g. $X_t=T_t \\\\cdot S_t \\\\cdot E_t$, where the amplitude of variations of the data could be changing through time. \\n\\nThere are many types of models for time series data, each of which can take various forms and represent different stochastic processes. However, three broad classes are very common and of practical importance: \\n1.  the autoregressive (AR) models, \\n2.  the integrated (I) models, and \\n3.  the moving average (MA) models. \\n   \\nThese three types of models all depend linearly on previous data points (other classes of models exist), and use that information to make a forecast into the future. One is generally interested in [developing these models to forecast](https://medium.com/wegaw/time-series-forecasting-in-python-from-zero-to-neural-networks-in-only-a-month-8e12d6a6e2f4), statistically, the (possibly future) behaviour of the data. Another useful application is to simulate the behaviour of observed random processes (e.g. to use as input to other models, or propagate errors).\\n\\nCombinations of ideas underlying the AR and MA models produce  **autoregressive moving average ([ARMA](https://en.wikipedia.org/wiki/Autoregressive–moving-average_model)) models**, while combination of all three types yields the **autoregressive integrated moving average ([ARIMA](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average)) models** . The **autoregressive fractionally integrated moving average model ([ARFIMA](https://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_average))**  generalizes all of this by allowing non-integer values of the 'differencing parameter'.\\n\\n\", 'source_document': 'uploads\\\\intro_to_timeseriesanalysis-IC-X9CYXD36RX.ipynb', 'cell_number': 23}}, {'id': 1753905536922100, 'score': 0.6198547, 'payload': {'original_id': 'uploads\\\\intro_to_timeseriesanalysis.ipynb_cell_23_md', 'type': 'markdown', 'content': \"<a id='timedomain'></a>\\n# Modeling time series data in the time domain\\n\\nOne of the tenet of time series analyis, or statistical forecasting of time series, is that: \\n\\n$\\nData = Signal + Noise\\n$\\n\\nMany approaches to time series analysis therefore try to decompose the data into an interpretable, signal, part and into uninterpretable residuals, which ideally are white noise. The signal can be additive, with trends, periods, and errors, e.g. $X_t=T_t+S_t+E_t$, or multiplicative, e.g. $X_t=T_t \\\\cdot S_t \\\\cdot E_t$, where the amplitude of variations of the data could be changing through time. \\n\\nThere are many types of models for time series data, each of which can take various forms and represent different stochastic processes. However, three broad classes are very common and of practical importance: \\n1.  the autoregressive (AR) models, \\n2.  the integrated (I) models, and \\n3.  the moving average (MA) models. \\n   \\nThese three types of models all depend linearly on previous data points (other classes of models exist), and use that information to make a forecast into the future. One is generally interested in [developing these models to forecast](https://medium.com/wegaw/time-series-forecasting-in-python-from-zero-to-neural-networks-in-only-a-month-8e12d6a6e2f4), statistically, the (possibly future) behaviour of the data. Another useful application is to simulate the behaviour of observed random processes (e.g. to use as input to other models, or propagate errors).\\n\\nCombinations of ideas underlying the AR and MA models produce  **autoregressive moving average ([ARMA](https://en.wikipedia.org/wiki/Autoregressive–moving-average_model)) models**, while combination of all three types yields the **autoregressive integrated moving average ([ARIMA](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average)) models** . The **autoregressive fractionally integrated moving average model ([ARFIMA](https://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_average))**  generalizes all of this by allowing non-integer values of the 'differencing parameter'.\\n\\n\", 'source_document': 'uploads\\\\intro_to_timeseriesanalysis.ipynb', 'cell_number': 23}}, {'id': 1753902702794239, 'score': 0.6135045, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902702662417, 'score': 0.6050478, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_10', 'type': 'pdf', 'content': 'ls that are ‘fitted’ to data•Some model parameters are tuned to fit–Question is what to fit/how? (Data assimilation, 4DVAR)–Provide best gridded high-resolution spatio-temporal product available … but:•they are still model results–Fitting a bad/wrong model still is a bad results•they only exist for the period when data exist–so cannot be used for forecasting–But extremely useful to understand past/current climate patterns/variability\\nAre models ever “right”?•Since models are incomplete by constr', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 10}}, {'id': 1753902703222464, 'score': 0.60481197, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_12', 'type': 'pdf', 'content': 'n meanModel performance and deciding which is the best model?Which is the best “Metric” -a judgment call?\\nInternal variability vs “forced” response?Ensemble simulations\\nRun 1, 2, 3 are ‘ensemble’ runsToday, 100s of ensemble runs can be generatedThat’s a lot of data!\\nAveraged surface temperature anomaly\\nWhat model for what process, for what analysis?Choosing the best model product for the jobIf simple works, go simple! (less data to process) –not everything has to be coupled all the time!\\nCan one', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 12}}, {'id': 1753902703226725, 'score': 0.60346913, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_13', 'type': 'pdf', 'content': ' model do it all?Processes operate on various time/space scales\\nHigher resolution•(more data)•(local extremes)•(shorter simulation)•(no/few ensembles)Lower resolution•(fewer data)•(longer simulation)•(many ensembles)\\n\\nTake home messages•Models will always be imperfect (accept this!)–the challenge is to make them useful by keeping them as simple as possible in spite oftheir limitations •very difficult in practice, requires deep scientific knowledge•Understanding of the question and of the tools a', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 13}}]",
      "[{'id': 1753901956917450, 'score': 0.67633873, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902702794239, 'score': 0.64489365, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902702944729, 'score': 0.6433077, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753902703503123, 'score': 0.63769317, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753902702662417, 'score': 0.63757133, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_10', 'type': 'pdf', 'content': 'ls that are ‘fitted’ to data•Some model parameters are tuned to fit–Question is what to fit/how? (Data assimilation, 4DVAR)–Provide best gridded high-resolution spatio-temporal product available … but:•they are still model results–Fitting a bad/wrong model still is a bad results•they only exist for the period when data exist–so cannot be used for forecasting–But extremely useful to understand past/current climate patterns/variability\\nAre models ever “right”?•Since models are incomplete by constr', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 10}}, {'id': 1753901956989969, 'score': 0.62934166, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_2', 'type': 'pdf', 'content': ' as well as errors stemming from the analytical procedure itself (e.g.calibration of analysis using synthetic data/models).Learning objectives of the Environmental Data module•Growing/important field –with likely career opportunities•Great playground to deliver learning objectives\\nUsing climate models: quantification/forecasting(impacts, adaptation, mitigation)\\nhttps://www.noaa.gov/education/resource-collections/climate/climate-change-impacts\\nUsing climate models: designscenarios(explore policy,', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 2}}, {'id': 1753902300429530, 'score': 0.6284912, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902702697836, 'score': 0.62425077, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_5', 'type': 'pdf', 'content': 'ent become stronger (strong exchange, although on shorter spatial scales, e.g.air-sea heat fluxes)•Better agreement with the way data are collected (i.e.what observations mean)–Averaging over space/time and variabilityhttps://www.gfdl.noaa.gov/climate-modeling/\\nGulf Stream\\nLabrador Sea~100km cells~10km cells\\nOcean resolution: 2 casesresolving eddies (the ocean’ storms)\\nFigure 6.1. Surface-Current Speed in Two Simulations of the Southern Ocean in Low-and High-Resolution Ocean Models.[From Fig. 6 ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 5}}, {'id': 1753902300472417, 'score': 0.6230095, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_1', 'type': 'pdf', 'content': 'ng physics)What are they for climate?\\nWhat does a model need?A very simple analytical exampleMany equations cannot be solved analytically…What do we have to do to solve them numerically?\\nii+1i+2…i-1i-2…Applies to time + 3D space\\nDiscretization\\nii+1i+2…i-1i-2…Applies to time + 3D spacedCdt=limΔt→0C(t+Δt)−C(t)ΔtdCdt≈C(t+Δt)−C(t)Δt,Δt>0ContinuumDiscrete(Taylor series expansion)\\nInpractice, this implies choices of Dx, Dy, Dz, Dt, size of the stencil, numerical stability, computational ability/costs,', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 1}}, {'id': 1753902299806645, 'score': 0.62257063, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}]",
      "[{'id': 1753902300206271, 'score': 0.7282068, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_0', 'type': 'pdf', 'content': 'Climate models –what are they?\\n…and different grids for different parts of the model:atmosphere, ocean, land, ice,…\\n\\nA bit of review: What do we need to make a model?(Any model, not necessarily a climate one)\\nWhat does a model need?A very simple analytical exampledCdt=λRequires equations (hypotheses about underlying physics)\\nWhat does a model need?A very simple analytical exampledCdt=λdCCoCf∫=λdttotf∫Cf=λtf−to()−CoRequires initial &boundary conditionsRequires equations (hypotheses about underlyi', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 0}}, {'id': 1753902702944729, 'score': 0.7206346, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753902300429530, 'score': 0.71998125, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753902703503123, 'score': 0.7187567, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753902702922525, 'score': 0.7059723, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_0', 'type': 'pdf', 'content': 'Are climate models any good or useful at all?\\nhttps://www.gfdl.noaa.gov/visualizations-hurricanes/\\nData or model?\\nCommon misconceptions about modeling1.The goal of modeling is to reproduce data2.If a model doesn’t fit the data, the model is useless (…and modeler also)3.Since modelers don’t measure anything, they don’t know anything about data or care about them4.Measurement(s) of “X” can be used to better constrain climate models5.Process “W” is not explicitly implemented in the model,hence the ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 0}}, {'id': 1753902702662417, 'score': 0.70247513, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_10', 'type': 'pdf', 'content': 'ls that are ‘fitted’ to data•Some model parameters are tuned to fit–Question is what to fit/how? (Data assimilation, 4DVAR)–Provide best gridded high-resolution spatio-temporal product available … but:•they are still model results–Fitting a bad/wrong model still is a bad results•they only exist for the period when data exist–so cannot be used for forecasting–But extremely useful to understand past/current climate patterns/variability\\nAre models ever “right”?•Since models are incomplete by constr', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 10}}, {'id': 1753902702794239, 'score': 0.7010748, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753901956917450, 'score': 0.6986832, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753903424509295, 'score': 0.68971735, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753901957112878, 'score': 0.6801769, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_0', 'type': 'pdf', 'content': 'https://svs.gsfc.nasa.gov/30701Climate data and modelsEDSML MSc –Imperial College London –Environmental dataYves Plancherel-https://www.linkedin.com/in/yves-plancherel/\\nWhy discuss climate data and climate models?\\n1. Understand common data format and databasestructures specific to representative fields of environmental science2. Demonstrate technical competency in handling common data types routinely encountered in the environmental sciences and identify relevant open-source data repositories3. ', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 0}}]",
      "[{'id': 1753902300429530, 'score': 0.7317457, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_6', 'type': 'pdf', 'content': 'ce scales of interest–Integration time step–Spatial resolution of the grid–Duration of model run–Decisions about time/space scales also translate into “filtering” the equations •(parts of the equations can be neglected and the equations simplified –some physics can be neglected/simplified)\\nWhy model climate?\\n\\nWeather and climate –bridging the gap\\n\\n\\nWhat are coupledclimatemodels?\\n\\nA few key major coupling mechanisms between the ocean and the atmosphere\\nThe “coupler” is the heart of climate models', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 6}}, {'id': 1753901956917450, 'score': 0.7017508, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902702697836, 'score': 0.7016113, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_5', 'type': 'pdf', 'content': 'ent become stronger (strong exchange, although on shorter spatial scales, e.g.air-sea heat fluxes)•Better agreement with the way data are collected (i.e.what observations mean)–Averaging over space/time and variabilityhttps://www.gfdl.noaa.gov/climate-modeling/\\nGulf Stream\\nLabrador Sea~100km cells~10km cells\\nOcean resolution: 2 casesresolving eddies (the ocean’ storms)\\nFigure 6.1. Surface-Current Speed in Two Simulations of the Southern Ocean in Low-and High-Resolution Ocean Models.[From Fig. 6 ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 5}}, {'id': 1753903424509295, 'score': 0.6848904, 'payload': {'original_id': 'uploads\\\\intro_to_climatedata.ipynb_cell_1_md', 'type': 'markdown', 'content': \"---\\n\\n# 01- Introduction to climate data and climate models\\n\\n---\\n\\n<a id='Contents'></a>\\n## Contents\\n- [Lectures](#lectures)\\n- [Question](#question)\\n- [ESMValTool](#ESMValTool)\\n- [Sources of climate data](#climatedata)\\n- [CEDA](#CEDA)\\n- [File formats](#fileformat)\\n- [Metadata](#metadata)\\n- [NetCDF](#NetCDF)\\n- [NCO](#NCO)\\n- [Reanalysis products](#reanalysis)\\n- [Climate services UKCP18](#ukcp18)\\n  \\n## Learning outcomes\\n1. Understand the basics of climate modelling\\n2. Know where to find and how to access climate data (ESGF, CEDA)\\n3. Understand common file formats\\n4. Understand the importance of metadata and understand CF conventions\\n5. Understand the NetCDF file format and know how to read, create and maniputate NetCDF data\\n6. Become familiar with other key tools used to manipulate netCDF data (NCO, CDO)\\n7. Know how to access ERA5 reanalysis products\\n8. Climate Services and UKCP18 and ability to access that data\\n\\n---\\n\", 'source_document': 'uploads\\\\intro_to_climatedata.ipynb', 'cell_number': 1}}, {'id': 1753902703274403, 'score': 0.68402636, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_4', 'type': 'pdf', 'content': 'solving dynamical equations–Smaller discretization steps•Better representation of topography/bathymetry (mountains, islands, seamounts…)–Grid-boxes have vertical walls (depends on coordinate system)•Explicit inclusion of subgrid-scale processes–Parameterizing vs. resolving (e.g.eddies, overflows, etc)•Property gradients can be larger –Affects pressure gradients (i.e.velocity of currents)–Model becomes more advective and less diffusive, maybe more turbulent–Exchange-processes that depend on gradi', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 4}}, {'id': 1753902702794239, 'score': 0.6836573, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753902702944729, 'score': 0.682418, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_9', 'type': 'pdf', 'content': 'task. It requires understanding the model well and the data well–A trend towards “Observational System Simulation Experiments” (OSSE)–data assimilation (e.g.4DVAR)\\nThe role of observationsin modeling\\nhttp://www.climate.be/textbook/pdf/Chapter_3.pdf\\nModelsvs observations•There are data that are ’just’ observations•There are models that are ‘just’ models•There are models that are ‘assimilated with data’–Often called ‘Reanalysis Products’•(also used in weather forecasting, obviously)–These are mode', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 9}}, {'id': 1753902299806645, 'score': 0.680072, 'payload': {'original_id': 'uploads\\\\02v1_Building_climate_models_copy.pdf_chunk_2', 'type': 'pdf', 'content': ' problem under study, etc.\\nWhat does a model need?A very simple numerical exampledCdt=λCCi+1−Citi+1−ti=λCiCi+1=Ci1+λΔt()dCdt=limΔt→0C(t+Δt)−C(t)ΔtRequires discretization of derivativesand numerical integration to step forward from tito tf=NDTForward difference(aka Forward Euler)[climatemodelsusemuchmorecomplex schemes]\\nii+1\\nWhat does a model need?Discretization needed to implement numericallydCdt=λCCi+1−CiΔt=λCi+1Ci+1=λΔtCi+1+CiCi+1=Ci11−λΔtBackward difference(aka backward Euler)Requires solving', 'source_document': 'uploads\\\\02v1_Building_climate_models_copy.pdf', 'chunk_number': 2}}, {'id': 1753902703503123, 'score': 0.67523056, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_1', 'type': 'pdf', 'content': 'model cannot model the effect of “Z” on climate as “W” has or may have an (unquantified) effect of the “Z” and may effectCO2or T, etc. … therefore climate models are useless\\nSome better propositions1.All models are “wrong” and “incomplete”(modeling with the sole goal of fitting data can be futile)(state-or-the-art models have many free parameters, uniqueness of the fit/solution is not always guaranteed –fit for wrong reason possible)2.Models have the merit of being internally consistent and poss', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 1}}, {'id': 1753902702662417, 'score': 0.670116, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_10', 'type': 'pdf', 'content': 'ls that are ‘fitted’ to data•Some model parameters are tuned to fit–Question is what to fit/how? (Data assimilation, 4DVAR)–Provide best gridded high-resolution spatio-temporal product available … but:•they are still model results–Fitting a bad/wrong model still is a bad results•they only exist for the period when data exist–so cannot be used for forecasting–But extremely useful to understand past/current climate patterns/variability\\nAre models ever “right”?•Since models are incomplete by constr', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 10}}]",
      "[{'id': 1753902703222464, 'score': 0.76282185, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_12', 'type': 'pdf', 'content': 'n meanModel performance and deciding which is the best model?Which is the best “Metric” -a judgment call?\\nInternal variability vs “forced” response?Ensemble simulations\\nRun 1, 2, 3 are ‘ensemble’ runsToday, 100s of ensemble runs can be generatedThat’s a lot of data!\\nAveraged surface temperature anomaly\\nWhat model for what process, for what analysis?Choosing the best model product for the jobIf simple works, go simple! (less data to process) –not everything has to be coupled all the time!\\nCan one', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 12}}, {'id': 1753902703226725, 'score': 0.7398776, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_13', 'type': 'pdf', 'content': ' model do it all?Processes operate on various time/space scales\\nHigher resolution•(more data)•(local extremes)•(shorter simulation)•(no/few ensembles)Lower resolution•(fewer data)•(longer simulation)•(many ensembles)\\n\\nTake home messages•Models will always be imperfect (accept this!)–the challenge is to make them useful by keeping them as simple as possible in spite oftheir limitations •very difficult in practice, requires deep scientific knowledge•Understanding of the question and of the tools a', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 13}}, {'id': 1753901956917450, 'score': 0.6731472, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_3', 'type': 'pdf', 'content': ' technology options)\\n\\nUsing climate models: variability(temporal, spatial)\\nImportance of experimental design!Control+ experiment\\nUsing climate models: uncertainties and sensitivities\\nMIP = Model Intercomparison Project\\nEyring et al. 2016\\nUsing climate models: uncertainties and sensitivities\\nhttps://en.wikipedia.org/wiki/Climate_ensembleDifferent experimentswith many ensembles!Each one trying to account for sensitivity due to a source of error Real world data: we only have one Earth, ONE realizat', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 3}}, {'id': 1753902703475561, 'score': 0.6691356, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_11', 'type': 'pdf', 'content': 'uction, what does “right” even mean?•What do we do if one model can represent a variable better but another variable worst?•A model can reproduce the mean state well but not the variability. Is it a “good” model?•What if model solution shows spatial and temporal patterns well, but is consistently offset?•Embrace/accept that sometimes the best we can do is to provide a probabilistic answer to questions\\nDifferent variablesDifferent modelsError relative to the multi-model meanLess than meanMore tha', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 11}}, {'id': 1753901956747387, 'score': 0.6372555, 'payload': {'original_id': 'uploads\\\\01v1_Why_climate_data.pdf_chunk_1', 'type': 'pdf', 'content': 'Identify and design suitable data analysis strategies that consider data types, data distribution constraints, strength, benefits and limitations of statistical and modelling tools and environmental dynamics.4. Understand the limitation of available data and data analysis products. Understand sources of errors and demonstrate ability to comprehensively characterize uncertainties and interpret results in the context of these uncertainties, including measurement errors, environmental uncertainties', 'source_document': 'uploads\\\\01v1_Why_climate_data.pdf', 'chunk_number': 1}}, {'id': 1753902703272079, 'score': 0.62692153, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_14', 'type': 'pdf', 'content': 'vailable–The skill of the analyst is to know how far to push the interpretation and to select the correct model/simulations for the right question (exploit experimental design)•Main sources of uncertainties to consider•Numericsand choice of equations/implementation•Resolution•Parameterizations•Boundary conditions and forcing•Internal dynamics•Influence of uncertainties on final conclusions of analysis must be considered\\n\\n', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 14}}, {'id': 1753907768115431, 'score': 0.62304795, 'payload': {'original_id': 'uploads\\\\intro_to_timeseriesanalysis-IC-X9CYXD36RX.ipynb_cell_32_md', 'type': 'markdown', 'content': \"<a id='markov'></a>\\n## Markov Chains\\n\\nAnother way to model time series are Markov Chains. These are particularly useful when a process can take on a finite number of states, with varying probabilities. \\n\\nA system consisting of mutually exclusive states and probabilistic transitions between them is called a [Markov chain](https://en.wikipedia.org/wiki/Markov_chain) (after the Russian mathematician Andrey Markov).\\n\\nThey are often linked to a technique called [`Markov Chain Monte Carlo`](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo), which are a class of algorithms for sampling from a probability distribution. This is very useful for numerical error propagation. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by recording states from the chain. The [`Metropolis-Hastings algorightm`](https://en.wikipedia.org/wiki/Metropolis–Hastings_algorithm) is also key to certain non-linear global optimization algorithms, such as [`simulated annealing`](https://en.wikipedia.org/wiki/Simulated_annealing). \\n\\nOne widely used analogy to explain Markov Chains is the 'drunken sailor' moving between his ship to the local pub (...the sailor being so drunk that he can move forwards, backwards, or not move at all):\\n\\n> [A drunken sailor moves from a tavern to his ship. The distance between the tavern and the ship is N steps. With each intermediate step, the sailor has chance **f** of stepping forward, chance **b** of stepping backward, and chance of **1-f-b** of standing still. Where does the sailor end up at the end of the day?](https://medium.com/pragmatic-programmers/what-shall-we-do-with-a-drunken-sailor-c57d9b61339d)\\n\\n\\nTo illustrate, assume there are 4 steps (N=4) between the ship and the tavern.\\n\\n![drunkensailor](img/drunkensailor.png)\\n\\nIn this case, the system comprising the sailor, the tavern, and the path with steps between the two can be in one of the N+1=5 **states** S[i]: \\n1. the sailor is in the tavern; \\n2. the sailor is 1 step away from the tavern; \\n3. the sailor is halfway from the tavern (i.e. 2 steps from anything); \\n4. the sailor is 1 step away from the ship;  \\n5. the sailor is on the ship. \\n   \\nThe probability of being in each state is **p[i]**, and the sum of all probabilities is 1 (the sailor must be at least somewhere).\\n\\nThere are also the probabilities **q[i,j]** of **moving** from the state S[i] to the state S[j]. For instance, if we were to set q[0,0], this could mean that the sailor **is** (S[i]) in the tavern, and **going** to the tavern (S[j]), so he has not actually gone anywhere in this case, but the quantity q[i,j] let's us represent the probability of each move happeneing. In this case, from the tavern, the sailor cannot go backwards, only forwrads towards the ship, so q[0,0]=1-f (i.e. the probability of staying in the tavern is equal to the probability of *not* moving forward).\\n\\nImagine, we start with the state that the sailor **is** in the tavern, so we can say p[0]=1, and set all other p[i]=0. \\n\\nFrom that starting point, we can now imagine what happens during the next step, i.e. the sailor can either move one step forward (i.e. out of the tavern, i.e. p[0] would decrease and p[1] would increase), or stay in the tavern. Whatever happens, though, the drunken sailor has **no memory** of what he did last time...as he is drunk, so each new move is independent of the last move, in a memoryless fashion. \\n\\nThe fact that moves are memoryless does not mean that probabilities of being a state cannot be calculated between steps though. During the second step, the probability of being in step 2, p[2] will depend on wether the sailor was in p[1] or p[0] after step 1, and this depends on the probabilities of moving (q[i,j], which ultimately depends on probabilities **f** and **b** or moving forward and backwards, and on the probabilities of being somewhere (p[i]). \\n\\nTo calculate the probabilities of the sailor being in any given state at a given time step, we simply need to keep track of all probabilities of getting there (q) from each current state (p), and sum them. \\n\\n$\\np’[i] = sum(p[j] · q[j,i])\\n$\\n\\nFor example, for the mid-way state, N=2, equidistant between the ship and the tavern, the probability of being there, i.e. in the new state p'[2] from any previous state 'p', can be represented by:\\n\\n$\\np'[2] = q[0,2] · p[0] + q[1,2]· p[1] + q[2,2]· p[2] + q[3,2]· p[3] + q[4,2]· p[4]\\n$\\n\\nand given our knowledge of the probabilities, we can simplify this as: \\n\\n$\\np’[2] = 0 · p[0] + f · p[1] + (1-f-b) · p[2] + b · p[3] + 0 · p[4]\\n$\\n\\nWe get get to N=2 by moving from step 1 forward, moving from step 3 backwards, or not moving from step 2. We cannot get to step 2 directly from step 0 or 4 (the tavern or the ship) as this would requires two steps (the sailor can only make one step at a time). \\n\\nWe can apply the same logic and calculate the probablilites of being anywhere. For example, the probability of being in step 1, p'[1] would be: \\n\\n$\\np'[1]=q[0,1] · p[0] + q[1,1]· p[1] + q[2,1]· p[2] + q[3,1]· p[3] + q[4,1]· p[4] \\\\\\\\\\np’[1] = f · p[0] + (1-f-b) · p[1] + b · p[2] + 0 · p[3] + 0 · p[4]  \\n$\\n\\nThe 'ps' and the 'qs' for all cases can be quantified and arranged into matrices **'P'** and **'Q'**, such that $P' = P · Q$. **P** is the state matrix, while **Q** is called the **transition** matrix. In the case of N=4, we see that the matrices P and Q are 5x5, or N+1 x N+1. A Markovian system is one where all we know is the current state and transition probabilities, but we don't know (or keep track) of what the previous states were (they don't affect the transition probabilities).\\n\\n\\nMarkovian systems ultimately become stationary in the sense that the distribution of the probabilities of being in each state converge towards stable distributions. When that happens,  $P = P’ = P’’ = P’’’ = ... = π$, that is the probability matrix that sets the probability of being in each state no longer evolves with each new iteration (i.e. the distribution of the probabilities describing the likelihood of being in each state p[i] doesn't change anymore with more iterations). When that happens, since p'[i]=p, we can write $\\\\pi=P=P'$ and so\\n\\n$\\n\\\\pi = \\\\pi \\\\cdot Q\\n$\\n\\nSince this represents a linear system, one could solve it for $\\\\pi$ and we see that $\\\\pi=eig(Q)$, so the probabilities of being in each state, given many steps through the random walk of the drunk sailor, are given by the eigenvalues of the transition matrix. Deriving this is beyond the scope of this introduction, but explanations can be found [here](https://en.wikipedia.org/wiki/Markov_chain). \\n\\nHere is a python example, assuming the drunken sailor is slightly more likely to go forward (f=0.7) than backward (b=0.2)...so maybe the sailor is not completely drunk yet. \", 'source_document': 'uploads\\\\intro_to_timeseriesanalysis-IC-X9CYXD36RX.ipynb', 'cell_number': 32}}, {'id': 1753905536642173, 'score': 0.62304795, 'payload': {'original_id': 'uploads\\\\intro_to_timeseriesanalysis.ipynb_cell_31_md', 'type': 'markdown', 'content': \"<a id='markov'></a>\\n## Markov Chains\\n\\nAnother way to model time series are Markov Chains. These are particularly useful when a process can take on a finite number of states, with varying probabilities. \\n\\nA system consisting of mutually exclusive states and probabilistic transitions between them is called a [Markov chain](https://en.wikipedia.org/wiki/Markov_chain) (after the Russian mathematician Andrey Markov).\\n\\nThey are often linked to a technique called [`Markov Chain Monte Carlo`](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo), which are a class of algorithms for sampling from a probability distribution. This is very useful for numerical error propagation. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by recording states from the chain. The [`Metropolis-Hastings algorightm`](https://en.wikipedia.org/wiki/Metropolis–Hastings_algorithm) is also key to certain non-linear global optimization algorithms, such as [`simulated annealing`](https://en.wikipedia.org/wiki/Simulated_annealing). \\n\\nOne widely used analogy to explain Markov Chains is the 'drunken sailor' moving between his ship to the local pub (...the sailor being so drunk that he can move forwards, backwards, or not move at all):\\n\\n> [A drunken sailor moves from a tavern to his ship. The distance between the tavern and the ship is N steps. With each intermediate step, the sailor has chance **f** of stepping forward, chance **b** of stepping backward, and chance of **1-f-b** of standing still. Where does the sailor end up at the end of the day?](https://medium.com/pragmatic-programmers/what-shall-we-do-with-a-drunken-sailor-c57d9b61339d)\\n\\n\\nTo illustrate, assume there are 4 steps (N=4) between the ship and the tavern.\\n\\n![drunkensailor](img/drunkensailor.png)\\n\\nIn this case, the system comprising the sailor, the tavern, and the path with steps between the two can be in one of the N+1=5 **states** S[i]: \\n1. the sailor is in the tavern; \\n2. the sailor is 1 step away from the tavern; \\n3. the sailor is halfway from the tavern (i.e. 2 steps from anything); \\n4. the sailor is 1 step away from the ship;  \\n5. the sailor is on the ship. \\n   \\nThe probability of being in each state is **p[i]**, and the sum of all probabilities is 1 (the sailor must be at least somewhere).\\n\\nThere are also the probabilities **q[i,j]** of **moving** from the state S[i] to the state S[j]. For instance, if we were to set q[0,0], this could mean that the sailor **is** (S[i]) in the tavern, and **going** to the tavern (S[j]), so he has not actually gone anywhere in this case, but the quantity q[i,j] let's us represent the probability of each move happeneing. In this case, from the tavern, the sailor cannot go backwards, only forwrads towards the ship, so q[0,0]=1-f (i.e. the probability of staying in the tavern is equal to the probability of *not* moving forward).\\n\\nImagine, we start with the state that the sailor **is** in the tavern, so we can say p[0]=1, and set all other p[i]=0. \\n\\nFrom that starting point, we can now imagine what happens during the next step, i.e. the sailor can either move one step forward (i.e. out of the tavern, i.e. p[0] would decrease and p[1] would increase), or stay in the tavern. Whatever happens, though, the drunken sailor has **no memory** of what he did last time...as he is drunk, so each new move is independent of the last move, in a memoryless fashion. \\n\\nThe fact that moves are memoryless does not mean that probabilities of being a state cannot be calculated between steps though. During the second step, the probability of being in step 2, p[2] will depend on wether the sailor was in p[1] or p[0] after step 1, and this depends on the probabilities of moving (q[i,j], which ultimately depends on probabilities **f** and **b** or moving forward and backwards, and on the probabilities of being somewhere (p[i]). \\n\\nTo calculate the probabilities of the sailor being in any given state at a given time step, we simply need to keep track of all probabilities of getting there (q) from each current state (p), and sum them. \\n\\n$\\np’[i] = sum(p[j] · q[j,i])\\n$\\n\\nFor example, for the mid-way state, N=2, equidistant between the ship and the tavern, the probability of being there, i.e. in the new state p'[2] from any previous state 'p', can be represented by:\\n\\n$\\np'[2] = q[0,2] · p[0] + q[1,2]· p[1] + q[2,2]· p[2] + q[3,2]· p[3] + q[4,2]· p[4]\\n$\\n\\nand given our knowledge of the probabilities, we can simplify this as: \\n\\n$\\np’[2] = 0 · p[0] + f · p[1] + (1-f-b) · p[2] + b · p[3] + 0 · p[4]\\n$\\n\\nWe get get to N=2 by moving from step 1 forward, moving from step 3 backwards, or not moving from step 2. We cannot get to step 2 directly from step 0 or 4 (the tavern or the ship) as this would requires two steps (the sailor can only make one step at a time). \\n\\nWe can apply the same logic and calculate the probablilites of being anywhere. For example, the probability of being in step 1, p'[1] would be: \\n\\n$\\np'[1]=q[0,1] · p[0] + q[1,1]· p[1] + q[2,1]· p[2] + q[3,1]· p[3] + q[4,1]· p[4] \\\\\\\\\\np’[1] = f · p[0] + (1-f-b) · p[1] + b · p[2] + 0 · p[3] + 0 · p[4]  \\n$\\n\\nThe 'ps' and the 'qs' for all cases can be quantified and arranged into matrices **'P'** and **'Q'**, such that $P' = P · Q$. **P** is the state matrix, while **Q** is called the **transition** matrix. In the case of N=4, we see that the matrices P and Q are 5x5, or N+1 x N+1. A Markovian system is one where all we know is the current state and transition probabilities, but we don't know (or keep track) of what the previous states were (they don't affect the transition probabilities).\\n\\n\\nMarkovian systems ultimately become stationary in the sense that the distribution of the probabilities of being in each state converge towards stable distributions. When that happens,  $P = P’ = P’’ = P’’’ = ... = π$, that is the probability matrix that sets the probability of being in each state no longer evolves with each new iteration (i.e. the distribution of the probabilities describing the likelihood of being in each state p[i] doesn't change anymore with more iterations). When that happens, since p'[i]=p, we can write $\\\\pi=P=P'$ and so\\n\\n$\\n\\\\pi = \\\\pi \\\\cdot Q\\n$\\n\\nSince this represents a linear system, one could solve it for $\\\\pi$ and we see that $\\\\pi=eig(Q)$, so the probabilities of being in each state, given many steps through the random walk of the drunk sailor, are given by the eigenvalues of the transition matrix. Deriving this is beyond the scope of this introduction, but explanations can be found [here](https://en.wikipedia.org/wiki/Markov_chain). \\n\\nHere is a python example, assuming the drunken sailor is slightly more likely to go forward (f=0.7) than backward (b=0.2)...so maybe the sailor is not completely drunk yet. \", 'source_document': 'uploads\\\\intro_to_timeseriesanalysis.ipynb', 'cell_number': 31}}, {'id': 1753902702794239, 'score': 0.61999786, 'payload': {'original_id': 'uploads\\\\03v1_Common_issues.pdf_chunk_8', 'type': 'pdf', 'content': 'cool and warm the climateThe microphysics responsible for cloud formation is not well understoodThe grid cells in models are much much bigger than time/space scales relevant for cloud physicsÞMagnitude/location of rain events is hard to predict wellÞThat information is useful though!\\nComparing models with data•What is a data point? Observation vs model result•Are model solutions at a point similar toa data point (i.e.observational sample)?–Spatially?–Temporally?•Using data well is not a trivial ', 'source_document': 'uploads\\\\03v1_Common_issues.pdf', 'chunk_number': 8}}, {'id': 1753907767620194, 'score': 0.6167785, 'payload': {'original_id': 'uploads\\\\intro_to_timeseriesanalysis-IC-X9CYXD36RX.ipynb_cell_23_md', 'type': 'markdown', 'content': \"<a id='timedomain'></a>\\n# Modeling time series data in the time domain\\n\\nOne of the tenet of time series analyis, or statistical forecasting of time series, is that: \\n\\n$\\nData = Signal + Noise\\n$\\n\\nMany approaches to time series analysis therefore try to decompose the data into an interpretable, signal, part and into uninterpretable residuals, which ideally are white noise. The signal can be additive, with trends, periods, and errors, e.g. $X_t=T_t+S_t+E_t$, or multiplicative, e.g. $X_t=T_t \\\\cdot S_t \\\\cdot E_t$, where the amplitude of variations of the data could be changing through time. \\n\\nThere are many types of models for time series data, each of which can take various forms and represent different stochastic processes. However, three broad classes are very common and of practical importance: \\n1.  the autoregressive (AR) models, \\n2.  the integrated (I) models, and \\n3.  the moving average (MA) models. \\n   \\nThese three types of models all depend linearly on previous data points (other classes of models exist), and use that information to make a forecast into the future. One is generally interested in [developing these models to forecast](https://medium.com/wegaw/time-series-forecasting-in-python-from-zero-to-neural-networks-in-only-a-month-8e12d6a6e2f4), statistically, the (possibly future) behaviour of the data. Another useful application is to simulate the behaviour of observed random processes (e.g. to use as input to other models, or propagate errors).\\n\\nCombinations of ideas underlying the AR and MA models produce  **autoregressive moving average ([ARMA](https://en.wikipedia.org/wiki/Autoregressive–moving-average_model)) models**, while combination of all three types yields the **autoregressive integrated moving average ([ARIMA](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average)) models** . The **autoregressive fractionally integrated moving average model ([ARFIMA](https://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_average))**  generalizes all of this by allowing non-integer values of the 'differencing parameter'.\\n\\n\", 'source_document': 'uploads\\\\intro_to_timeseriesanalysis-IC-X9CYXD36RX.ipynb', 'cell_number': 23}}]"
    ],
    "response": "This is a Python code snippet that implements a Markov chain model for time series forecasting. The code defines a function `markov_chain` that takes in a list of time steps and a transition matrix, and returns the probability distribution at each time step.\n\n```python\nimport numpy as np\n\ndef markov_chain(time_steps, transition_matrix):\n    \"\"\"\n    Compute the probability distribution at each time step using a Markov chain model.\n\n    Parameters:\n    - time_steps (list): List of time steps.\n    - transition_matrix (numpy array): Transition matrix.\n\n    Returns:\n    - probabilities (numpy array): Probability distribution at each time step.\n    \"\"\"\n    # Initialize the probability distribution with all zeros\n    probabilities = np.zeros((len(time_steps), len(transition_matrix)))\n\n    # Set the initial probability distribution to 1 at the first time step\n    probabilities[0] = 1\n\n    # Compute the probability distribution at each time step using the transition matrix\n    for t in range(1, len(time_steps)):\n        probabilities[t] = np.dot(probabilities[t-1], transition_matrix)\n\n    return probabilities\n```\n\nThis code can be used to forecast future values of a time series by applying the Markov chain model to the observed data. The `transition_matrix` parameter represents the probability distribution at each time step, and is typically estimated from historical data.\n\nFor example, suppose we want to forecast the next value in a time series using a Markov chain model with a transition matrix that represents the probabilities of moving forward or backward one time step. We can define the transition matrix as follows:\n\n```python\ntransition_matrix = np.array([[0.7, 0.3], [0.4, 0.6]])\n```\n\nThis means that if we are currently at state `i`, there is a probability of `0.7` of moving forward to state `j`, and a probability of `0.3` of moving backward to state `k`.\n\nWe can then use the `markov_chain` function to compute the probability distribution at each time step:\n\n```python\ntime_steps = [1, 2, 3, 4]\nprobabilities = markov_chain(time_steps, transition_matrix)\nprint(probabilities)\n```\n\nThis will output the probability distribution at each time step, which can be used to make predictions about future values in the time series.",
    "reference": "Agreeing is reasonable because climate models are inherently simplifications with assumptions and limitations, but they are internally consistent and help test hypotheses, forecast trends, and support policy decisions.",
    "iteration_scores": [
      {
        "iteration": 1,
        "decomposition": 8.0,
        "retrieval": 6.0,
        "generation": 5.3999999999999995,
        "total": 6.466666666666666
      },
      {
        "iteration": 2,
        "decomposition": 7.0,
        "retrieval": 6.0,
        "generation": 8.299999999999999,
        "total": 7.099999999999999
      },
      {
        "iteration": 3,
        "decomposition": 8.0,
        "retrieval": 5.285714285714286,
        "generation": 1.0,
        "total": 4.761904761904762
      }
    ]
  }
]
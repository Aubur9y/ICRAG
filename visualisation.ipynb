{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:35:31.501766Z",
     "start_time": "2025-07-20T13:35:31.498324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa_pairs = [\n",
    "    {\n",
    "        \"user_input\": \"What is the forward problem?\",\n",
    "        \"reference\": \"The forward problem can be thought of as: given x what is y?\"\n",
    "    },\n",
    "    {\n",
    "        \"user_input\": \"\"\"\n",
    "        How are over-determined and under-determined systems both addressed using optimisation techniques, and how do their respective solution strategies differ?\n",
    "        \"\"\",\n",
    "        \"reference\": \"\"\"\n",
    "        Over-determined systems, where there are more equations than unknowns (m>n), are typically addressed using the Least Squares method. This involves finding the solution that minimizes the sum of the squared differences between the observed and predicted values—effectively projecting the observation vector onto the column space of the matrix.\n",
    "        Under-determined systems, where there are fewer equations than unknowns (m<n), require finding a solution that satisfies the equations but also minimizes the norm of the solution vector—this is called the Minimum Norm Solution. This choice imposes an additional optimisation criterion because the solution space is not unique.\n",
    "        Both scenarios transform the inversion problem into an optimisation one: least squares minimizes residuals, while the minimum norm approach selects the \"smallest\" solution from an infinite set.\n",
    "        \"\"\"\n",
    "    }\n",
    "]"
   ],
   "id": "d8db31f3dfdcfa9f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-20T13:35:31.520257Z",
     "start_time": "2025-07-20T13:35:31.517235Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "from ragas import evaluate, EvaluationDataset\n",
    "from pipeline.orchestrator_agent_wise_feedback import pipeline\n",
    "\n",
    "sys.path.append(os.path.abspath(\"tests\"))"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:39:37.122496Z",
     "start_time": "2025-07-20T13:35:31.529672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = [faithfulness, answer_relevancy, context_precision, context_recall]\n",
    "\n",
    "results = []\n",
    "\n",
    "for qa_pair in qa_pairs:\n",
    "    question = qa_pair[\"user_input\"]\n",
    "    answer = qa_pair[\"reference\"]\n",
    "    result = pipeline(question)\n",
    "    ragas_result = {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": result.get(\"contexts\"),\n",
    "        \"response\": result.get(\"answers\"),\n",
    "        \"reference\": answer,\n",
    "    }\n",
    "\n",
    "    results.append(ragas_result)\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_list(results)\n",
    "ragas_results = evaluate(evaluation_dataset, metrics=metrics)"
   ],
   "id": "e44a8a1598ba9424",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 1 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem in physics engineering\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem example\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"solving the forward problem steps in an example\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"difference between forward problem and inverse problem\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"iterative nature of solving forward problems numerical methods\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"initial conditions in mathematics and physics\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 1.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 1 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 4.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 6.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 6.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 2 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem in structural mechanics\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem example calculating displacements under a given load\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"mathematical formulation of the forward problem\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"forward problem definition\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem key takeaways\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 9.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 2 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 5.80\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 6.60\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 3 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem in structural mechanics\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"unique solutions concept implications\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem cantilever beam displacement under load example\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"mathematical formulation of the forward problem governing equations boundary conditions initial conditions\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"contrast forward and inverse problem in mathematics\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 5.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 3 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 3.60\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 6.20\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 1 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"least squares solution over-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"existence and uniqueness of solutions for under-determined systems constraints\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"solving general solution under-determined system constraint equations\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"over-determined systems in linear algebra definition\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"over-determined vs under-determined systems solutions\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"different system types and examples\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 8.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 1 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 4.33\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 6.44\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 2 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"normal equations approach for solving under-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"least-squares solution over-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"existence and uniqueness of solutions for under-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"over-determined linear algebra definition\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"solution strategies for over-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:No tools used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 7.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 2 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 6.17\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 7.06\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 3 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"normal equations under-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"least-squares solution for over-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"over-determined systems of linear equations definition\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"least-squares solution properties limitations\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"constraints regularization techniques ill-conditioned systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"key differences in solution approaches based on system type and desired solution characteristics\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 6.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 3 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 4.67\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 6.56\n",
      "Evaluating: 100%|██████████| 8/8 [00:28<00:00,  3.60s/it]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:43:10.795665Z",
     "start_time": "2025-07-20T13:39:37.161181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_aw = []\n",
    "\n",
    "for qa_pair in qa_pairs:\n",
    "    question = qa_pair[\"user_input\"]\n",
    "    answer = qa_pair[\"reference\"]\n",
    "    result = pipeline(question)\n",
    "    ragas_result = {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": result.get(\"contexts\"),\n",
    "        \"response\": result.get(\"answers\"),\n",
    "        \"reference\": answer,\n",
    "    }\n",
    "\n",
    "    results_aw.append(ragas_result)\n",
    "\n",
    "evaluation_dataset_aw = EvaluationDataset.from_list(results_aw)\n",
    "ragas_results_aw = evaluate(evaluation_dataset_aw, metrics=metrics)"
   ],
   "id": "5aa40b6ecac03b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 1 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem example heat conduction\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem numerical simulation Finite Element Analysis\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"role of discretization and approximation in solving the forward problem\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"mathematical formulation of the forward problem governing equations boundary conditions\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"forward problem in mathematics and science\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 1.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 1 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 3.20\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 6.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 5.40\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 2 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem definition in physics engineering finance\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"core steps in solving the forward problem\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem example\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"challenges or assumptions associated with the forward problem\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem resources for further learning\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 1.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 2 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 6.60\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 6.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 6.87\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 3 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"forward problem definition in physics engineering biology\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"inputs required to solve forward problem\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:No tools used.\n",
      "INFO:agents.brain_agent:No tools used.\n",
      "INFO:agents.brain_agent:No tools used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 2.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 3 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 3.80\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 5.93\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 1 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"methods for solving over-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"properties of solutions in over-determined systems existence uniqueness error representation\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"methods for solving under-determined systems least squares trial-and-error iterative methods\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"over-determined systems mathematical definition\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"properties of solutions in under-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"system type implications for practical applications error handling model selection\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"over-determined systems solution methodologies properties\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 12.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 1 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 4.43\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 6.81\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 2 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"existence and uniqueness of solutions for under-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"methods to obtain solutions in under-determined systems Gaussian elimination least squares minimum norm\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"least-squares solution for over-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"over-determined system in linear algebra\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"over-determined systems solution approaches\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"examples of solution process for both types of systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 7.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 2 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 6.17\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 7.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 7.06\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:=== Pipeline Iteration 3 ===\n",
      "INFO:agents.decomposition_agent:User query detected, processing...\n",
      "INFO:agents.decomposition_agent:Rewriting query...\n",
      "INFO:agents.decomposition_agent:Choosing the best rewrite\n",
      "INFO:agents.decomposition_agent:Decomposing into sub-tasks...\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"existence and uniqueness of solutions for under-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"iterative methods for over-determined systems gradient descent Levenberg-Marquardt\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"least-squares solution over-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\": \"over-determined systems linear algebra\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"choice of optimization method over-determined under-determined systems\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n",
      "INFO:agents.brain_agent:Tool decision: use tool 'vector_search', arguments: {\"query\":\"convergence properties of numerical methods\"}\n",
      "INFO:agents.brain_agent:Executing tool: vector_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for DecisionAgent: 5.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline.orchestrator_agent_wise_feedback:Iteration 3 scores:\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Decomposition: 8.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Retrieval avg: 5.33\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Generation: 6.00\n",
      "INFO:pipeline.orchestrator_agent_wise_feedback:Total: 6.44\n",
      "Evaluating: 100%|██████████| 8/8 [00:19<00:00,  2.40s/it]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:44:31.923324Z",
     "start_time": "2025-07-20T13:44:31.919730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(ragas_results)\n",
    "print(ragas_results_aw)"
   ],
   "id": "7c06a42073901a61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9643, 'answer_relevancy': 0.9230, 'context_precision': 1.0000, 'context_recall': 1.0000}\n",
      "{'faithfulness': 1.0000, 'answer_relevancy': 0.9402, 'context_precision': 0.9167, 'context_recall': 1.0000}\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:49:00.178529Z",
     "start_time": "2025-07-20T13:49:00.174508Z"
    }
   },
   "cell_type": "code",
   "source": "print(results_aw)",
   "id": "c373b06ff57d0761",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_input': 'What is the forward problem?', 'retrieved_contexts': ['[{\\'id\\': 8, \\'score\\': 0.727762, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_8_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'- The <a class=\"definition\" href=\"#definitions\" id=\"forwardproblem\">forward problem</a> can be thought of as: given $x$ what is $y$?\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 8}}]', \"I need more context or specifics about the steps you're referring to in order to provide an explanation of the output. Could you please specify the steps or the process you have in mind?\", '[{\\'id\\': 8, \\'score\\': 0.7539221, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_8_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'- The <a class=\"definition\" href=\"#definitions\" id=\"forwardproblem\">forward problem</a> can be thought of as: given $x$ what is $y$?\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 8}}, {\\'id\\': 22, \\'score\\': 0.71916467, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_22_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'#### Parameter estimation, Curve Fitting and Regression <a class=\"tocSkip\"></a>\\\\nNote that in the forward model $F$ that predicts some observed data $\\\\\\\\boldsymbol{Y}$, we are not typically inverting for all inputs to the function. We could divide the inputs to the model into two sets (vectors): \\\\n\\\\n$$\\\\\\\\boldsymbol{Y} = F(\\\\\\\\boldsymbol{X} ;  \\\\\\\\boldsymbol{m}) $$\\\\n\\\\nwhere the $\\\\\\\\boldsymbol{m}$ are the quantities we want to invert for, and assume that $\\\\\\\\boldsymbol{X}$ are fixed inputs that we already know to some degree. In which case we can consider the inversion problem\\\\n\\\\n$$\\\\n\\\\\\\\text{find }\\\\\\\\boldsymbol m\\\\\\\\text{ such that }\\\\n\\\\\\\\tilde F(\\\\\\\\boldsymbol m) = F(\\\\\\\\boldsymbol{X} ;  \\\\\\\\boldsymbol{m}) = \\\\\\\\boldsymbol{Y}\\\\n$$\\\\n\\\\nin which $\\\\\\\\tilde F$ is the same model (function) $F$ but with fixed input $\\\\\\\\boldsymbol{X}$.\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 22}}, {\\'id\\': 71, \\'score\\': 0.7063304, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_71_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'# Solving Equi-Determined Problems\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 71}}, {\\'id\\': 10, \\'score\\': 0.7034157, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_10_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'The first is usually relatively well-defined: given some inputs $x$ we have a model that generates some predictions $y$. The process of going from inputs $x$ to outcomes $y$ is described as a function $f$ which consists of a series of mathematical operations, or combination of algorithms, that we can perform step by step. The entire model can however become very complex and expensive to evaluate.\\\\n\\\\nThis inversion problem may have no general solution, and its solution may be trivial, easy, difficult or impossible depending upon the form of $f$ and the value of $y$.  \\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 10}}]', 'I need a specific input or problem to provide a tailored outline of the mathematical or logical steps necessary to transform the inputs into the desired output. Could you please specify the inputs and the desired output?', 'Certainly! Let\\'s consider a scenario where a user has a series of sub-tasks that need to be addressed. Here\\'s an illustrated example:\\n\\n### Task Example:\\nA user wants to learn about the health benefits of meditation and find recent articles on its effects on stress reduction.\\n\\n### Sub-Tasks:\\n1. \\'What are the health benefits of meditation?\\'\\n2. \\'Find recent articles about meditation\\'s effects on stress reduction.\\'\\n\\n### Decision Process:\\n\\n1. **For the first sub-task: \\'What are the health benefits of meditation?\\'**\\n   - Since this is a knowledge-based query, I will use the **functions.vector_search** tool to look for internal documents that outline the health benefits associated with meditation.\\n\\n2. **For the second sub-task: \\'Find recent articles about meditation\\'s effects on stress reduction.\\'**\\n   - This requires current information; thus, I will use the **functions.web_search** tool to look for the latest articles discussing how meditation impacts stress levels.\\n\\n### Implementation:\\nNow, let\\'s execute the queries using the tools identified for each sub-task.\\n\\n```json\\n{\\n  \"tool_uses\": [\\n    {\\n      \"recipient_name\": \"functions.vector_search\",\\n      \"parameters\": {\\n        \"query\": \"health benefits of meditation\"\\n      }\\n    },\\n    {\\n      \"recipient_name\": \"functions.web_search\",\\n      \"parameters\": {\\n        \"query\": \"recent articles on meditation and stress reduction\"\\n      }\\n    }\\n  ]\\n}\\n```\\n\\n### Result Interpretation:\\n- The output from the first tool will provide relevant health benefits related to meditation retrieved from the internal database.\\n- The output from the second tool will yield the latest articles, allowing the user to stay informed about recent findings on meditation\\'s impact on stress.\\n\\nThis structured approach assures that each sub-task is treated independently while utilizing the most appropriate tools for retrieving information effectively.'], 'response': 'The forward problem can be understood as predicting the output (y) given an input (x) [Context 1]. This process involves defining a function or model that maps the input (x) to the output (y) [Context 4]. Such a model consists of mathematical operations or algorithms that, when executed, give the predicted result. The complexity of these operations can range from simple calculations to highly intricate and computationally expensive models [Context 4]. Understanding the forward problem is foundational in fields like parameter estimation or regression, where assumptions about input values are critical, and the forward model predicts observed data [Context 2]. \\n\\nIn summary, directly addressing the query, the forward problem involves using a defined model to determine the output based on given inputs. The process and its complexity depend on the nature of the inputs, the function, and the model used.', 'reference': 'The forward problem can be thought of as: given x what is y?'}, {'user_input': '\\n        How are over-determined and under-determined systems both addressed using optimisation techniques, and how do their respective solution strategies differ?\\n        ', 'retrieved_contexts': [\"[{'id': 68, 'score': 0.71785784, 'payload': {'original_id': 'uploads\\\\\\\\L1_Introduction.ipynb_cell_68_md', 'type': 'markdown', 'content': '## Mixed determined\\\\nAn under-determined system only guarantees existence of a solution, and an over-determined system only guarantees uniqueness if the matrix is full-rank. We will also call this purely under-determined and purely over-determined respectively. If the matrices are not full-rank, but rank-deficient, this is often called mixed-determined, in which case neither existence nor uniqueness are guaranteed. This term also applies to the rank-deficient equi-determined case.\\\\n\\\\nMixed determined cases often involve situations where some unknowns (or linear combinations of unknowns) are described by too many equations, and some unknowns by too few equations. In a sense they can thus be described as a combination of (purely) over-determined and under-determined.\\\\n\\\\nMany, large, real-world, inversion problems are likely to be mixed-determined.  In practice it can also be very difficult to discover if a large system is mixed determined or not, and so in practical problems we will often proceed by assuming that the problem is mixed-determined, employing an iterative numerical approach.', 'source_document': 'uploads\\\\\\\\L1_Introduction.ipynb', 'cell_number': 68}}]\", '[{\\'id\\': 110, \\'score\\': 0.73267484, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_110_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'# Over-Determined problems ($m\\\\\\\\gt n$) and the Least Squares Solution\\\\n\\\\nIn over-determined problems, there are more independent equations than unknowns.  That is, in the system  \\\\n\\\\n$$\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\, \\\\\\\\boldsymbol{x} = \\\\\\\\boldsymbol{b}$$\\\\n\\\\n$m \\\\\\\\gt n$  where $\\\\\\\\underline{\\\\\\\\mathbf A}$ is an $m\\\\\\\\times n$ matrix.\\\\n\\\\n<img src=\"./latex/matrix-tall.png\" width=\"300x\" />\\\\n<br/>\\\\n\\\\nThe inverse of $\\\\\\\\underline{\\\\\\\\mathbf A}$ is not defined, and in general there is no solution $\\\\\\\\boldsymbol{x}$ that will exactly satisfy this relation \\\\n\\\\nBUT we can find an $\\\\\\\\boldsymbol{x}$ if the data $\\\\\\\\boldsymbol{b}$ lies in the range of $\\\\\\\\underline{\\\\\\\\mathbf A}$ but this won\\\\\\'t generally be the case. \\\\n\\\\n<br/> \\\\n\\\\nA useful solution can still be found in the general case, and we\\\\\\'ve already seen how:\\\\n\\\\nInstead of solving our original problem, we instead solve the related equation (residual form)\\\\n\\\\n$$\\\\n\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\boldsymbol{x} - \\\\\\\\boldsymbol{b} = 0,\\\\n$$\\\\nwhere we aim to find the $\\\\\\\\boldsymbol{x}$ that minimises the left-hand side. For a least-squares solution, this minimisation occurs over\\\\n\\\\n$$\\\\n\\\\\\\\frac{1}{2}\\\\\\\\|\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\mathbf{x} - \\\\\\\\mathbf{b}\\\\\\\\|^2 = \\\\\\\\frac{1}{2}(\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\mathbf{x} - \\\\\\\\mathbf{b})^\\\\\\\\top (\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\mathbf{x} - \\\\\\\\mathbf{b}) =  \\\\\\\\frac{1}{2}(\\\\\\\\mathbf{x}^\\\\\\\\top\\\\\\\\underline{\\\\\\\\mathbf A}^\\\\\\\\top\\\\\\\\underline{\\\\\\\\mathbf A} \\\\\\\\mathbf{x} - 2 \\\\\\\\mathbf{b}^\\\\\\\\top\\\\\\\\underline{\\\\\\\\mathbf A} \\\\\\\\mathbf{x} + \\\\\\\\mathbf{b}^\\\\\\\\top \\\\\\\\mathbf{b}).\\\\n\\\\n$$\\\\n\\\\n\\\\nTo achieve that, we can take the derivative of this least-squares formulation with respect to $\\\\\\\\boldsymbol{x}$ and set it to $\\\\\\\\boldsymbol{0}$:\\\\n\\\\n$$\\\\\\\\frac{1}{2}(2\\\\\\\\underline{\\\\\\\\mathbf A}^T \\\\\\\\,\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\, \\\\\\\\boldsymbol{x} - 2\\\\\\\\underline{\\\\\\\\mathbf A}^T \\\\\\\\,\\\\\\\\boldsymbol{b}) = \\\\\\\\mathbf{0},$$\\\\n\\\\nyielding\\\\n\\\\n$$\\\\\\\\underline{\\\\\\\\mathbf A}^T \\\\\\\\,\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\, \\\\\\\\boldsymbol{x} = \\\\\\\\underline{\\\\\\\\mathbf A}^T \\\\\\\\,\\\\\\\\boldsymbol{b}$$\\\\n\\\\n(More on differentiation of inner products in the homework and upcoming lectures).\\\\n\\\\nThis relation is called the <a class=\"definition\" href=\"#definitions\" id=\"normalequation\">normal equation</a>.\\\\n\\\\n<br/>\\\\n\\\\nThe $n\\\\\\\\times n$ matrix $\\\\\\\\underline{\\\\\\\\mathbf A}^T \\\\\\\\,\\\\\\\\underline{\\\\\\\\mathbf A}$ is now square and symmetric, and  provided that it is not singular, the solution to the normal equation will be \\\\n \\\\n$$\\\\\\\\boldsymbol{x} = (\\\\\\\\underline{\\\\\\\\mathbf A}^T \\\\\\\\,\\\\\\\\underline{\\\\\\\\mathbf A})^{-1}\\\\\\\\underline{\\\\\\\\mathbf A}^T \\\\\\\\,\\\\\\\\boldsymbol{b}$$\\\\n\\\\nThis approach generates the <a class=\"definition\" href=\"#definitions\" id=\"leastsquaressolution\">least squares solution</a> to the problem.\\\\n\\\\nWe\\\\\\'ve seen examples of this already in both the linear system case as well as in terms of linear regression (fitting a polynomial to data).\\\\n\\\\n<!-- We will leave the derivation of the fact that the normal equation indeed provides the least squares solution to tomorrow, where we will see how to write it as an example of broader class of quadratic optimisation problems. -->\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 110}}, {\\'id\\': 28, \\'score\\': 0.7162194, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_28_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'Given some data, we will see that we end up with a ***linear*** problem to solve, even though our model is nonlinear in the inputs $X$.\\\\n\\\\nYou can think of $X$ as locations we evaluate our model at in order to compare against or match to data, while $\\\\\\\\boldsymbol{a}$ are unknown input parameters to our model that describe in some sense the governing \"physics\".\\\\n\\\\n\\\\nFor the inversion problem we are assuming we know the $X$\\\\\\'s (e.g. maybe these are the locations our data is collected at) and the $y$\\\\\\'s (the observations of the output of our problem/model at these locations), and we want to find $\\\\\\\\boldsymbol{a}$ (i.e. the parameters that govern our model).\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 28}}, {\\'id\\': 117, \\'score\\': 0.70913225, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_117_md\\', \\'type\\': \\'markdown\\', \\'content\\': \"## Possible solution methods\\\\n\\\\nIn  this  problem,  $\\\\\\\\underline{\\\\\\\\mathbf A}$  is  not  square  so  that  $\\\\\\\\underline{\\\\\\\\mathbf A}^{-1}$ does not exist,  and  both  $\\\\\\\\underline{\\\\\\\\mathbf A}^T\\\\\\\\underline{\\\\\\\\mathbf A}$ and $\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\underline{\\\\\\\\mathbf A}^T$ are singular matrices, so that none of the methods that we have used so far will work.  \\\\n\\\\nSo what can we do?  There are two principal options that we will discuss in tomorrow\\'s lecture:\\\\n\\\\n\\\\n1. we can use the ***generalised inverse*** $A^+$, also known as the pseudo-inverse or the ***Moore-Penrose inverse***, or\\\\n\\\\n\\\\n2. we can use some form of ***regularisation*** to the model of which ***damped least-squares*** is the most straightforward.   \\\\n\\\\n\\\\nThe generalised inverse is  preferable in  small problems, especially  when we would like to analyse the quality of the results carefully, while regularised least-squares and related methods are preferable for large problems when the generalised inverse is prohibitively expensive, or when linearised inversion is being used in order to solve a non-linear problem by iteration.\", \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 117}}, {\\'id\\': 23, \\'score\\': 0.70339936, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_23_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'In other applications however, the known inputs $\\\\\\\\boldsymbol{X}$ might be variable, and we might have a series of observations $i=1,\\\\\\\\dots N$ with for each known value $\\\\\\\\boldsymbol{X}_i$ for the input $\\\\\\\\boldsymbol{X}$, we have an observed output $\\\\\\\\boldsymbol{Y}_i$. Now the inversion takes the form\\\\n\\\\n$$\\\\n\\\\\\\\text{find }\\\\\\\\boldsymbol m\\\\\\\\text{ such that }\\\\nF(\\\\\\\\boldsymbol{X}_i ;  \\\\\\\\boldsymbol{m}) \\\\\\\\approx \\\\\\\\boldsymbol{Y}_i \\\\\\\\text{ for all } i=1, \\\\\\\\dots N\\\\n$$\\\\n\\\\nHere $F$ could be a sophisticated model based on complex physical laws, that once the values for $\\\\\\\\boldsymbol{m}$ have been found, can be thought of as a way of predicting $\\\\\\\\boldsymbol Y$ for each input $\\\\\\\\boldsymbol X$, not only for the given set of inputs $\\\\\\\\boldsymbol X_i$ with known observations $\\\\\\\\boldsymbol{Y}_i$, but for any value of $\\\\\\\\boldsymbol X$. The (initially) unknown values $\\\\\\\\boldsymbol{m}$ can then be thought of as parameters or coefficients in the model, and the inversion for $\\\\\\\\boldsymbol{m}$ as a process to improve the model by finding optimal parameter values - a process refered to as parameter estimation.\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 23}}, {\\'id\\': 4, \\'score\\': 0.700283, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_4_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'## Summary <a class=\"tocSkip\"></a>\\\\nIn today\\\\\\'s lecture we will first briefly discuss the role of Inversion and Optimisation in science and engineering. We will start with the inversion of linear systems. For this we first need to revise some of the key concepts of Linear Algebra that you\\\\\\'ve already encountered in _Computational Mathematics_. We will extend these to linear systems with fewer, or more equations than unknowns, i.e. based on non-square matrices. We will spend some time on the technique of Gaussian Elimination, and the LU decomposition which are central to direct methods of solving linear systems. For over-determined systems (more equations than unknowns) we look at the Least Squares method, and for under-determined (fewer equations than unknowns) we look at the minimum norm solution. We will finish our treatment of non-square systems in tomorrow\\\\\\'s lecture with the Singular Value Decomposition and the generalized inverse.\\\\n    \\\\n### Important concepts: <a class=\"tocSkip\"></a>\\\\n* the role of inversion and optimisation in science and engineering, data science, and machine learning and the relation between inversion and optimisation\\\\n* the various ways to look at the rank of a matrix and its relation to the dimension of its null space, its range, and the space of solutions\\\\n* conditions for the existence and uniqueness of solutions\\\\n* the classification in equi-determined, under-determined, over-determined and mixed-determined\\\\n* Gaussian Elimination, back substitution, pivotting and LU decomposition and its role in solving linear systems, but also determining the rank or the nullspace of a matrix\\\\n* obtaining a least-squares solution to over-determined systems (using the normal equation)\\\\n* obtaining a minimum-norm solution to under-determined systems\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 4}}]', '[{\\'id\\': 66, \\'score\\': 0.7598529, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_66_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'* If $m=n$, we call the linear system <a class=\"definition\" href=\"#definitions\" id=\"equidetermined\">equi-determined</a>. If the matrix is *full-rank*, we have $\\\\\\\\mathrm{rank}(\\\\\\\\underline{\\\\\\\\mathbf A})=m=n$: a solution exists for any right-handside, and that solution is unique. If the matrix is *rank-deficient* then a solution only exists for some right-hand side vectors, and the solution is also not unique.\\\\n\\\\n* If $m\\\\\\\\lt n$ we call the linear system <a class=\"definition\" href=\"#definitions\" id=\"underdetermined\">under-determined</a>: we have fewer equations than entries in $\\\\\\\\boldsymbol{x}$. If the matrix is *full-rank*, $\\\\\\\\mathrm{rank}(\\\\\\\\underline{\\\\\\\\mathbf A})=m$, solutions exist for any right-hand side, but the solutions will not be unique since $\\\\\\\\mathrm{rank}(\\\\\\\\underline{\\\\\\\\mathbf A})\\\\\\\\lt n$. The *rank-deficient* case makes things worse: no guaranteed existance and solutions (if they do exist) are non-unique.\\\\n\\\\n* If $m\\\\\\\\gt n$ we call the linear system <a class=\"definition\" href=\"#definitions\" id=\"overdetermined\">over-determined</a>: we have more equations than entries in $\\\\\\\\boldsymbol{x}$. Even if the matrix is full-rank, we still have $\\\\\\\\mathrm{rank}(\\\\\\\\underline{\\\\\\\\mathbf A})=n < m$, thus we do not get a solution for every right-hand side vector. If a solution does exist however, it will be unique. Again *rank-deficient* makes things worse: solutions are not guaranteed to exist, and if they do exist they are not unique.\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 66}}, {\\'id\\': 69, \\'score\\': 0.73784983, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_69_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'#### Mixed determined - Example 1 <a class=\"tocSkip\"></a>\\\\n\\\\nConsider the following problem:\\\\n\\\\n$$\\\\n\\\\\\\\begin{pmatrix}\\\\n1 & 0 & 0 \\\\\\\\\\\\\\\\\\\\n1 & 0 & 0 \\\\\\\\\\\\\\\\\\\\n0 & 2 & 2 \\\\\\\\\\\\\\\\\\\\n0 & 3 & 3\\\\n\\\\\\\\end{pmatrix}\\\\n\\\\\\\\begin{pmatrix}\\\\nx_1\\\\\\\\\\\\\\\\\\\\nx_2\\\\\\\\\\\\\\\\\\\\nx_3\\\\n\\\\\\\\end{pmatrix}\\\\n=\\\\n\\\\\\\\begin{pmatrix}\\\\n1\\\\\\\\\\\\\\\\\\\\n2\\\\\\\\\\\\\\\\\\\\n2\\\\\\\\\\\\\\\\\\\\n3\\\\n\\\\\\\\end{pmatrix}.\\\\n$$\\\\n\\\\nFor this problem, $x_1$ is over-determined since there is no possible value of $x_1$ that can exactly fit both of the first two equations in this system - the first two equations/constraints are inconsistent:\\\\n\\\\n* The first equation says: $x_1 = 1$\\\\n\\\\n* The second equation says: $x_1 = 2$\\\\n\\\\n\\\\nThe problem is also under-determined because the last two equations are not independent. In the particular case as written here the final two equations actually boil down to one equation for two unknowns. Dividing the third equation by 2 and the fourth equation by 3 we get:\\\\n\\\\n$x_2 + x_3 = 1$\\\\n\\\\nThus, there are infinitely many solutions for $x_2$ and $x_3$ that can fit the last two equations exactly.  \\\\n\\\\nThis problem is therefore clearly ***mixed-determined***.\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 69}}, {\\'id\\': 68, \\'score\\': 0.7269135, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_68_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'## Mixed determined\\\\nAn under-determined system only guarantees existence of a solution, and an over-determined system only guarantees uniqueness if the matrix is full-rank. We will also call this purely under-determined and purely over-determined respectively. If the matrices are not full-rank, but rank-deficient, this is often called mixed-determined, in which case neither existence nor uniqueness are guaranteed. This term also applies to the rank-deficient equi-determined case.\\\\n\\\\nMixed determined cases often involve situations where some unknowns (or linear combinations of unknowns) are described by too many equations, and some unknowns by too few equations. In a sense they can thus be described as a combination of (purely) over-determined and under-determined.\\\\n\\\\nMany, large, real-world, inversion problems are likely to be mixed-determined.  In practice it can also be very difficult to discover if a large system is mixed determined or not, and so in practical problems we will often proceed by assuming that the problem is mixed-determined, employing an iterative numerical approach.\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 68}}, {\\'id\\': 113, \\'score\\': 0.72066075, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_113_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'# Under-Determined Problems ($m\\\\\\\\lt n$) and the Minimum Norm Solution\\\\n\\\\nIn under-determined problems,  there are fewer  equations than unknowns, and so  $m$  is  less than $n$.  \\\\n\\\\n<img src=\"./latex/matrix-fat.png\" width=\"400x\"/>\\\\n\\\\nNow the equations do not uniquely define a solution. \\\\n\\\\nHowever, in this case too there is still a useful solution to be found.  \\\\n\\\\nWhen $m\\\\\\\\lt n$,  the  matrix  $\\\\\\\\underline{\\\\\\\\mathbf A}^T\\\\\\\\underline{\\\\\\\\mathbf A}$ will  be  singular (cf. the rank of matrix products),  so  we  cannot  proceed  as  for  the  over-determined case.  \\\\n\\\\nHowever, the similar $m \\\\\\\\times m$ matrix $\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\underline{\\\\\\\\mathbf A}^T$ will not be singular if the equations are independent and consistent - if $\\\\\\\\underline{\\\\\\\\mathbf A}$ is full rank.  \\\\n\\\\nWe can therefore construct the solution\\\\n\\\\n$$\\\\\\\\boldsymbol{x} = \\\\\\\\underline{\\\\\\\\mathbf A}^T(\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\underline{\\\\\\\\mathbf A}^T)^{-1}\\\\\\\\boldsymbol{b}$$\\\\n\\\\nwhere this time the matrix $\\\\\\\\underline{\\\\\\\\mathbf A}^T(\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\underline{\\\\\\\\mathbf A}^T)^{-1}$ can be regarded as a type of inverse to $\\\\\\\\underline{\\\\\\\\mathbf A}$ since\\\\n\\\\n$$\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\left( \\\\\\\\underline{\\\\\\\\mathbf A}^T (\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\underline{\\\\\\\\mathbf A}^T)^{-1} \\\\\\\\right) = \\\\\\\\underline{\\\\\\\\mathbf I}$$\\\\n\\\\nwhich also means that $\\\\\\\\boldsymbol{x}$ is indeed a solution:\\\\n\\\\n$$\\\\n\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\boldsymbol{x} = \\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\left( \\\\\\\\underline{\\\\\\\\mathbf A}^T (\\\\\\\\underline{\\\\\\\\mathbf A}\\\\\\\\underline{\\\\\\\\mathbf A}^T)^{-1} \\\\\\\\right)\\\\\\\\boldsymbol{b} =\\\\n\\\\\\\\boldsymbol{b}\\\\n$$\\\\n\\\\n\\\\n- This inverse is called the <a class=\"definition\" href=\"#definitions\" id=\"rightinverse\">right  inverse</a> of $A$, or the ***minimum-norm  inverse***. \\\\n\\\\n- The minimum-norm inverse generates a perfect fit to the data.  \\\\n\\\\n- This however is not the only exact solution.  \\\\n\\\\n- This problem has a null space since we have fewer equations than unknowns, and an  infinite  number  of  solutions  will  satisfy the data equally well.    \\\\n\\\\n- The  <a class=\"definition\" href=\"#definitions\" id=\"minimumnormsolution\">minimum-norm solution</a> is the solution that both fits the data exactly, and having satisfied that constraint then minimises the $L^2$   norm of the model. That  is, subject  to  first  fitting the data, it then also minimises $\\\\\\\\boldsymbol{x}^T\\\\\\\\boldsymbol{x}$.\\\\n- Derivation of the minimal norm solution can be found [here](https://see.stanford.edu/materials/lsoeldsee263/08-min-norm.pdf) and is left here for curiosity (we will return to this discussion in lecture 10)\\\\n\\\\nThis is in fact our first example of a constrained optimisation problem. We define a function, in this case $f(\\\\\\\\boldsymbol{x})=\\\\\\\\boldsymbol{x}^T \\\\\\\\boldsymbol{x}$, and search for the minimum of $f(\\\\\\\\boldsymbol{x})$ with the constraint that $\\\\\\\\boldsymbol{x}$ should satisfy the $\\\\\\\\underline{\\\\\\\\mathbf{A}}\\\\\\\\boldsymbol{x}=\\\\\\\\boldsymbol{b}$. We will come back to constrained optimisation in lecture 10, and proof that the right-inverse solution indeed minimises the L2-norm of $\\\\\\\\boldsymbol{x}$.\\\\n\\\\nThe latter condition makes the model parameter vector as \"short\" as possible (thinking of $\\\\\\\\boldsymbol{x}$ as a vector) given that it must also match the data.  This  is  a  minimum  model parameter vector that  has  nothing  within  it  that  can  be  left  out  without degrading the fit to the data.  However, we can choose to add to it any linear combination from the null space and it will still explain the data exactly. \\\\n\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 113}}, {\\'id\\': 53, \\'score\\': 0.7201521, \\'payload\\': {\\'original_id\\': \\'uploads\\\\\\\\L1_Introduction.ipynb_cell_53_md\\', \\'type\\': \\'markdown\\', \\'content\\': \\'Returning to our linear inverse problem, where we aim to find  $\\\\\\\\boldsymbol{x}$  from a set of observations  $\\\\\\\\boldsymbol{b}$ :\\\\n\\\\n\\\\n$$\\\\\\\\underline{\\\\\\\\mathbf{A}} \\\\\\\\boldsymbol{x} = \\\\\\\\boldsymbol{b},$$\\\\n\\\\n\\\\nwe can immediately observe that the system has a solution only if the right-hand side vector  $\\\\\\\\boldsymbol{b}$  lies in the span of the column vectors of  $\\\\\\\\underline{\\\\\\\\mathbf{A}}$ . This is because the matrix-vector product  $\\\\\\\\underline{\\\\\\\\mathbf{A}} \\\\\\\\boldsymbol{x}$  can only produce vectors that are linear combinations of the columns of  $\\\\\\\\underline{\\\\\\\\mathbf{A}}$ as seen above. If  $\\\\\\\\boldsymbol{b}$  is not in this span, the system does not have a solution.\\\\n\\\\nRank\\\\n\\\\nThe span of the column vectors of  $\\\\\\\\underline{\\\\\\\\mathbf{A}}$  determines the set of all possible vectors that the matrix  $\\\\\\\\underline{\\\\\\\\mathbf{A}}$  can map to through this linear combination. This subspace is also referred to as the range (or column space) of the matrix.\\\\n\\\\nThe dimension of the range $k^*$, which corresponds to the number of linearly independent columns in  $\\\\\\\\underline{\\\\\\\\mathbf{A}}$ , is called the rank of the matrix, noted by $\\\\\\\\mathrm{rank}(\\\\\\\\underline{\\\\\\\\mathbf{A}})$.\\\\n\\\\nThe system is solvable for any arbitrary right-hand side vector  $\\\\\\\\boldsymbol{b}$  only if the range of  $\\\\\\\\underline{\\\\\\\\mathbf{A}}$  spans all of  $\\\\\\\\mathbb{R}^m $, meaning that every possible vector in  $\\\\\\\\mathbb{R}^m$  can be expressed as a linear combination of the column vectors of  $\\\\\\\\underline{\\\\\\\\mathbf{A}}$ . This occurs when  $\\\\\\\\mathrm{rank}(\\\\\\\\underline{\\\\\\\\mathbf{A}}) = m$ , which implies that  $\\\\\\\\underline{\\\\\\\\mathbf{A}}$  has full column rank and no columns are linearly dependent.\\', \\'source_document\\': \\'uploads\\\\\\\\L1_Introduction.ipynb\\', \\'cell_number\\': 53}}]', \"[{'id': 68, 'score': 0.71390605, 'payload': {'original_id': 'uploads\\\\\\\\L1_Introduction.ipynb_cell_68_md', 'type': 'markdown', 'content': '## Mixed determined\\\\nAn under-determined system only guarantees existence of a solution, and an over-determined system only guarantees uniqueness if the matrix is full-rank. We will also call this purely under-determined and purely over-determined respectively. If the matrices are not full-rank, but rank-deficient, this is often called mixed-determined, in which case neither existence nor uniqueness are guaranteed. This term also applies to the rank-deficient equi-determined case.\\\\n\\\\nMixed determined cases often involve situations where some unknowns (or linear combinations of unknowns) are described by too many equations, and some unknowns by too few equations. In a sense they can thus be described as a combination of (purely) over-determined and under-determined.\\\\n\\\\nMany, large, real-world, inversion problems are likely to be mixed-determined.  In practice it can also be very difficult to discover if a large system is mixed determined or not, and so in practical problems we will often proceed by assuming that the problem is mixed-determined, employing an iterative numerical approach.', 'source_document': 'uploads\\\\\\\\L1_Introduction.ipynb', 'cell_number': 68}}, {'id': 10, 'score': 0.701535, 'payload': {'original_id': 'uploads\\\\\\\\L1_Introduction.ipynb_cell_10_md', 'type': 'markdown', 'content': 'The first is usually relatively well-defined: given some inputs $x$ we have a model that generates some predictions $y$. The process of going from inputs $x$ to outcomes $y$ is described as a function $f$ which consists of a series of mathematical operations, or combination of algorithms, that we can perform step by step. The entire model can however become very complex and expensive to evaluate.\\\\n\\\\nThis inversion problem may have no general solution, and its solution may be trivial, easy, difficult or impossible depending upon the form of $f$ and the value of $y$.  ', 'source_document': 'uploads\\\\\\\\L1_Introduction.ipynb', 'cell_number': 10}}]\"], 'response': 'Optimization methods handle over-determined and under-determined systems differently due to the nature of their constraints and potential solutions.\\n\\nFor over-determined systems, where there are more equations than unknowns, the solution approach commonly involves minimizing the residuals, as a direct solution may not exist. The least squares method is often used in this scenario. In this approach, the objective is to find the solution that minimizes the sum of the squares of the residuals, which measures the difference between the observed and calculated values [Context 110]. This involves solving the normal equation, which provides a least squares solution, generating the best possible solution in terms of minimizing these differences [Context 110].\\n\\nUnder-determined systems have fewer equations than unknowns, leading to potentially infinite solutions. A common approach here is to use a minimum norm solution, which selects among the infinite possibilities the solution with the smallest L2 norm (essentially, the smallest vector length) [Context 113]. This method ensures that the solution not only satisfies the equations but is also ‘minimal’ in a particular mathematical sense, which can be particularly useful when seeking a stable or regularized solution [Context 113].\\n\\nIn practice, mixed-determined systems, which feature characteristics of both over-determined and under-determined systems, can arise and may require iterative numerical methods for resolution due to their complexity [Context 68].', 'reference': '\\n        Over-determined systems, where there are more equations than unknowns (m>n), are typically addressed using the Least Squares method. This involves finding the solution that minimizes the sum of the squared differences between the observed and predicted values—effectively projecting the observation vector onto the column space of the matrix.\\n        Under-determined systems, where there are fewer equations than unknowns (m<n), require finding a solution that satisfies the equations but also minimizes the norm of the solution vector—this is called the Minimum Norm Solution. This choice imposes an additional optimisation criterion because the solution space is not unique.\\n        Both scenarios transform the inversion problem into an optimisation one: least squares minimizes residuals, while the minimum norm approach selects the \"smallest\" solution from an infinite set.\\n        '}]\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
